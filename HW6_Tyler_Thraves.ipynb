{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7HFpsMIqSbcHbZnFWPpcI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7ff9dcfdc02a486583610199a6f21473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00a57644c51d44cdb97be1de315836d6",
              "IPY_MODEL_5de9c590f64241b2a2daeb99739efc37",
              "IPY_MODEL_6b4a8333c96f4127954a357de51cc2af"
            ],
            "layout": "IPY_MODEL_420192a98c73440cac6663bd09912e8c"
          }
        },
        "00a57644c51d44cdb97be1de315836d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b453be9edf80445a95fc33566c5cf611",
            "placeholder": "​",
            "style": "IPY_MODEL_949ec59c2fda42ebacb95cbfa3654f9a",
            "value": "Map: 100%"
          }
        },
        "5de9c590f64241b2a2daeb99739efc37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb6c926005c74eba8a29a56c40ffde9f",
            "max": 9000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0bb1cfb13d344a9845774ca8ca37497",
            "value": 9000
          }
        },
        "6b4a8333c96f4127954a357de51cc2af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72db0fdc36404e9797d6f054c4bfc933",
            "placeholder": "​",
            "style": "IPY_MODEL_ebe93421b78c43a095956cc755d4509e",
            "value": " 9000/9000 [00:37&lt;00:00, 253.32 examples/s]"
          }
        },
        "420192a98c73440cac6663bd09912e8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b453be9edf80445a95fc33566c5cf611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "949ec59c2fda42ebacb95cbfa3654f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb6c926005c74eba8a29a56c40ffde9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0bb1cfb13d344a9845774ca8ca37497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72db0fdc36404e9797d6f054c4bfc933": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebe93421b78c43a095956cc755d4509e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a0b3269f307454d802bfb2236468713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90c5151e743d4f5ba439e2b361fe70aa",
              "IPY_MODEL_47949ae984e447c1a634aacbd05c7cf6",
              "IPY_MODEL_d94b4733d69b437e9b83df40e6d5c9ce"
            ],
            "layout": "IPY_MODEL_9fdb6122a13c42558d99da3d2bd29442"
          }
        },
        "90c5151e743d4f5ba439e2b361fe70aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4cd56f8b11844dc88c57da6f9c26cdd",
            "placeholder": "​",
            "style": "IPY_MODEL_4c0557d29baf4fadb06657c04b87ab3c",
            "value": "Map: 100%"
          }
        },
        "47949ae984e447c1a634aacbd05c7cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4a3115b14a54a179bedb53cb3b64a6d",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8b35701e02b4746ad8ded64568321ca",
            "value": 1000
          }
        },
        "d94b4733d69b437e9b83df40e6d5c9ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79193289ddf0426e925b4dc010e60574",
            "placeholder": "​",
            "style": "IPY_MODEL_bc962a3c5cce4ccb9722b82390e3e761",
            "value": " 1000/1000 [00:03&lt;00:00, 267.77 examples/s]"
          }
        },
        "9fdb6122a13c42558d99da3d2bd29442": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4cd56f8b11844dc88c57da6f9c26cdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c0557d29baf4fadb06657c04b87ab3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4a3115b14a54a179bedb53cb3b64a6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b35701e02b4746ad8ded64568321ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79193289ddf0426e925b4dc010e60574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc962a3c5cce4ccb9722b82390e3e761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thravt/AIProjectsHomework/blob/main/HW6_Tyler_Thraves.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 1: Transformers\n",
        "Task 1 (30 points): In this task you should work with the Facebook BART model\n",
        "(https://huggingface.co/docs/transformers/en/model_doc/bart) to provide text summarization\n",
        "of news articles. Text summarization in Natural Language Processing (NLP) is a technique that\n",
        "breaks down long texts into sentences or paragraphs, while retaining the text's meaning and\n",
        "extracting important information. Pick any one dataset of your choice.**"
      ],
      "metadata": {
        "id": "epD19VYPSgIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Provide a description of the dataset you selected. Split your data into train-test set with\n",
        "a (90-10) split.**"
      ],
      "metadata": {
        "id": "rckB8mUhTn7T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'll be using xsum from HuggingFace. I was originally going to use multi-news, but the length of the summaries and descriptions was so large, it crashed in the padding process due to low ram."
      ],
      "metadata": {
        "id": "XCv_QZ6BTwzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "4RpKjgqIdHoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YQjTGCldcMz9",
        "outputId": "1f49cb47-9085-48fa-b991-a18df55bdf92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "awcuEFdQcGOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('xsum', split='train')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDzQuT7UcqkI",
        "outputId": "af5fd64d-9ee5-43dd-b932-acead42d086d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)\n",
        "print(dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WzB7c2Mc5cE",
        "outputId": "cda564ef-dfb5-4efc-ead7-fa2cb613d936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['document', 'summary', 'id'],\n",
            "    num_rows: 204045\n",
            "})\n",
            "{'document': 'The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed.\\nRepair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water.\\nTrains on the west coast mainline face disruption due to damage at the Lamington Viaduct.\\nMany businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town.\\nFirst Minister Nicola Sturgeon visited the area to inspect the damage.\\nThe waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare.\\nJeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\\nHowever, she said more preventative work could have been carried out to ensure the retaining wall did not fail.\\n\"It is difficult but I do think there is so much publicity for Dumfries and the Nith - and I totally appreciate that - but it is almost like we\\'re neglected or forgotten,\" she said.\\n\"That may not be true but it is perhaps my perspective over the last few days.\\n\"Why were you not ready to help us a bit more when the warning and the alarm alerts had gone out?\"\\nMeanwhile, a flood alert remains in place across the Borders because of the constant rain.\\nPeebles was badly hit by problems, sparking calls to introduce more defences in the area.\\nScottish Borders Council has put a list on its website of the roads worst affected and drivers have been urged not to ignore closure signs.\\nThe Labour Party\\'s deputy Scottish leader Alex Rowley was in Hawick on Monday to see the situation first hand.\\nHe said it was important to get the flood protection plan right but backed calls to speed up the process.\\n\"I was quite taken aback by the amount of damage that has been done,\" he said.\\n\"Obviously it is heart-breaking for people who have been forced out of their homes and the impact on businesses.\"\\nHe said it was important that \"immediate steps\" were taken to protect the areas most vulnerable and a clear timetable put in place for flood prevention plans.\\nHave you been affected by flooding in Dumfries and Galloway or the Borders? Tell us about your experience of the situation and how it was handled. Email us on selkirk.news@bbc.co.uk or dumfries@bbc.co.uk.', 'summary': 'Clean-up operations are continuing across the Scottish Borders and Dumfries and Galloway after flooding caused by Storm Frank.', 'id': '35232142'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 0\n",
        "for i in range (204045):\n",
        "  maxlen = max(maxlen, len(dataset[i]['summary'].split()))\n",
        "print(maxlen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0WljreNeTKp",
        "outputId": "041ba561-52da-4b8c-e987-6fb057d795b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 0\n",
        "for i in range (204045):\n",
        "  maxlen = max(maxlen, len(dataset[i]['document'].split()))\n",
        "print(maxlen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHUmDnXZihi-",
        "outputId": "1ab4fb50-f376-44a8-b6ee-8317e04c9bce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I keep running out of RAM, so in a bid to reduce the RAM usage, I'll take it down to 10000 data points, which should still be enough for a good test."
      ],
      "metadata": {
        "id": "2RQH28Kgsu2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainingdata = dataset.select(range(10000))"
      ],
      "metadata": {
        "id": "KbhfXrxqs_ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainingdata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i_Yf-e_tJ6O",
        "outputId": "a0359274-518e-4906-a9a3-51d93abaa32d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['document', 'summary', 'id'],\n",
            "    num_rows: 10000\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitdata = trainingdata.train_test_split(test_size=0.1)"
      ],
      "metadata": {
        "id": "hzUEjoLtenHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Load the model from Hugging Face’s Transformers library and write its training script.**"
      ],
      "metadata": {
        "id": "kieO54BuT2js"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shold be easy enough."
      ],
      "metadata": {
        "id": "XDZTs-EGUdiW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I checked the notebook on the BART documentation for a guide to work with."
      ],
      "metadata": {
        "id": "vMGn4iZ8iL-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets evaluate transformers rouge-score nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMhcy5twjICr",
        "outputId": "a08b419b-d61d-4f37-abe3-13591b8c9e18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n"
      ],
      "metadata": {
        "id": "yA6BsM9sUcwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm getting input length errors, so I will have to truncate to match the example notebook. Looking more closely at the documentation it seems I was going over the maximum embedding size."
      ],
      "metadata": {
        "id": "9cSuvXF5E4h2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = 1024\n",
        "max_target_length = 128\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [doc for doc in examples[\"document\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, padding=True)\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    labels = tokenizer(text_target=examples[\"summary\"], max_length=max_target_length, truncation=True, padding=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "JLXKWk0YiURi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_function(splitdata['train'][:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zdAJue_oizKe",
        "outputId": "149a7236-663c-4a09-cbfd-aefdb210fe84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[0, 38268, 27742, 17034, 6, 5659, 6, 362, 5, 418, 31, 988, 17351, 4405, 11, 902, 1824, 6, 584, 24, 74, 28, 28360, 14, 1035, 4, 50118, 1708, 24, 21, 129, 1835, 71, 249, 880, 41, 803, 5, 220, 76, 4, 50118, 133, 320, 3299, 11, 381, 3624, 2596, 122, 2419, 145, 2322, 160, 5, 1131, 5124, 4, 50118, 133, 1679, 174, 69, 89, 21, 410, 5, 4354, 115, 109, 7, 15392, 69, 55, 87, 5, 285, 28689, 9, 17902, 5, 22, 18880, 6999, 9, 2416, 845, 50118, 2515, 2641, 3526, 30, 2134, 9, 69, 774, 4, 50118, 133, 1679, 174, 69, 5, 8637, 24939, 10, 316, 353, 22790, 2617, 3645, 6, 53, 24, 74, 28, 3456, 13, 80, 107, 576, 5, 9297, 4215, 9, 5, 403, 4, 50118, 133, 461, 6, 2828, 11, 5818, 28779, 6, 21, 174, 14, 5, 1802, 6, 988, 17351, 4405, 6, 21, 3606, 31, 11520, 18, 8, 5, 12571, 21, 2542, 9, 39, 22010, 2536, 8, 2166, 474, 77, 79, 553, 123, 13, 5, 2541, 4, 50118, 2515, 439, 7, 39, 184, 7, 22, 4970, 123, 13, 10, 5976, 113, 7, 244, 69, 66, 9, 69, 613, 9282, 8, 37, 1507, 7, 1203, 10, 5851, 3407, 13, 984, 698, 6, 151, 11, 5, 2621, 9, 39, 184, 244, 19, 41, 13746, 14, 24, 74, 28, 1199, 124, 11, 5, 1035, 9, 1824, 4, 50118, 133, 184, 244, 11635, 5, 12571, 10, 76, 423, 77, 5, 418, 21, 45, 28360, 6, 53, 79, 174, 69, 22, 3654, 7, 4022, 59, 24, 845, 50118, 133, 418, 21, 1835, 7, 427, 17351, 4405, 6, 54, 962, 11, 1125, 6, 71, 5, 249, 880, 7, 4830, 5, 3299, 18, 2883, 4, 50118, 133, 1679, 26, 5, 12571, 21, 45, 7958, 30, 26253, 8, 5, 418, 21, 45, 1240, 15, 10, 19813, 6339, 6, 53, 21, 1195, 10, 898, 9, 69, 613, 3834, 14668, 4, 50118, 894, 26, 37, 56, 829, 171, 35164, 261, 9532, 8, 24, 21, 699, 925, 27742, 17034, 21, 3688, 7, 69, 1484, 6, 8, 56, 15732, 13, 171, 82, 11, 10, 23303, 8, 1403, 1672, 169, 4, 50118, 894, 26, 79, 45, 129, 1415, 71, 49, 1131, 782, 53, 67, 1147, 49, 2004, 8, 613, 782, 6, 1311, 82, 418, 54, 58, 11, 4709, 241, 2726, 13, 5956, 6, 8, 4595, 2159, 20279, 13, 1484, 4, 50118, 133, 1679, 26, 5, 12571, 222, 45, 192, 932, 1593, 19, 42, 1548, 6, 61, 37, 1602, 25, 45, 129, 22, 879, 47144, 53, 9458, 845, 50118, 894, 26, 79, 21, 3688, 7, 69, 1484, 53, 21, 540, 2509, 11, 5, 613, 5894, 9, 69, 1524, 6, 8, 1602, 69, 7708, 613, 1052, 25, 22, 833, 3320, 845, 50118, 133, 461, 21, 174, 14, 5, 3299, 2152, 31, 10, 750, 9, 40942, 5467, 8, 21, 11, 1233, 613, 9600, 8, 1164, 31, 69, 827, 23, 5, 86, 4, 50118, 133, 1679, 26, 5, 8637, 222, 45, 386, 66, 25, 65, 9, 32738, 27668, 8, 5, 418, 21, 341, 7, 13904, 97, 2172, 6, 217, 277, 3186, 79, 12942, 418, 7, 4, 50118, 894, 26, 14, 925, 27742, 17034, 56, 15732, 13, 171, 82, 11, 10, 23303, 8, 1403, 1672, 169, 13, 237, 1724, 53, 69, 756, 56, 283, 7, 41, 253, 11, 10, 22, 15110, 352, 11, 7743, 642, 16003, 169, 845, 50118, 894, 26, 42, 21, 10, 22, 18880, 8653, 11, 63, 308, 235, 113, 8, 14, 24, 21, 235, 14, 5, 1233, 6999, 9, 2416, 11, 5, 3299, 12, 23846, 1291, 56, 57, 3271, 4924, 11, 42, 169, 4, 2], [0, 27267, 428, 8774, 9959, 1676, 26, 89, 58, 158, 10858, 13, 358, 11042, 1676, 184, 11, 5, 2109, 8, 235, 7, 907, 22, 25836, 4490, 915, 11, 92, 1611, 845, 50118, 133, 3446, 3905, 7413, 1634, 2981, 6, 13740, 9959, 6, 10636, 2013, 2457, 9959, 8, 15338, 14751, 4, 50118, 10285, 76, 6, 799, 1676, 1611, 11, 5, 2109, 58, 1088, 223, 235, 7, 907, 4, 50118, 14507, 31533, 1259, 6, 6743, 428, 8774, 9959, 18, 5892, 919, 13, 2004, 6, 26, 35, 22, 970, 2563, 16, 10, 403, 11, 5, 2109, 13, 42, 7, 1369, 72, 50118, 133, 3446, 40, 122, 3253, 7, 5, 12093, 1621, 13, 2846, 7, 912, 235, 7, 907, 13, 5, 220, 292, 107, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'labels': [[0, 250, 274, 7043, 7669, 12571, 54, 27820, 352, 19251, 8, 362, 2093, 9, 10, 4478, 7497, 3186, 77, 79, 1447, 7, 13904, 10, 984, 698, 6, 151, 2541, 34, 57, 576, 10, 3456, 1789, 3645, 4, 2], [0, 250, 371, 1926, 5295, 1676, 34, 2763, 7, 912, 82, 2159, 49, 308, 1676, 3960, 71, 2086, 55, 87, 204, 6, 151, 1611, 7, 5, 714, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = splitdata.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "7ff9dcfdc02a486583610199a6f21473",
            "00a57644c51d44cdb97be1de315836d6",
            "5de9c590f64241b2a2daeb99739efc37",
            "6b4a8333c96f4127954a357de51cc2af",
            "420192a98c73440cac6663bd09912e8c",
            "b453be9edf80445a95fc33566c5cf611",
            "949ec59c2fda42ebacb95cbfa3654f9a",
            "cb6c926005c74eba8a29a56c40ffde9f",
            "f0bb1cfb13d344a9845774ca8ca37497",
            "72db0fdc36404e9797d6f054c4bfc933",
            "ebe93421b78c43a095956cc755d4509e",
            "9a0b3269f307454d802bfb2236468713",
            "90c5151e743d4f5ba439e2b361fe70aa",
            "47949ae984e447c1a634aacbd05c7cf6",
            "d94b4733d69b437e9b83df40e6d5c9ce",
            "9fdb6122a13c42558d99da3d2bd29442",
            "b4cd56f8b11844dc88c57da6f9c26cdd",
            "4c0557d29baf4fadb06657c04b87ab3c",
            "e4a3115b14a54a179bedb53cb3b64a6d",
            "e8b35701e02b4746ad8ded64568321ca",
            "79193289ddf0426e925b4dc010e60574",
            "bc962a3c5cce4ccb9722b82390e3e761"
          ]
        },
        "id": "5qr8sdvkjUWp",
        "outputId": "fa02d3e2-86de-4bcd-f2ce-883ada50835c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/9000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ff9dcfdc02a486583610199a6f21473"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a0b3269f307454d802bfb2236468713"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"facebook/bart-large-cnn\""
      ],
      "metadata": {
        "id": "h4NdRgHVj9uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Fine tune the pre-trained model with your data and report results on your test set. You\n",
        "must report the BLEU and ROUGE Scores. (See the code provided in class for more\n",
        "details)**"
      ],
      "metadata": {
        "id": "PQdECrlHlo0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once again, the notebook on the BART documentation is very helpful here."
      ],
      "metadata": {
        "id": "As5bts3Cls4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "5YqUjGvplxlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"{model_name}-finetuned-xsum\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=1,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    #push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "uowefJ6dl8qq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91dfacfe-d268-4c51-c87d-679aaedf3602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dI5bGVgy8gNK",
        "outputId": "1cf78e78-fb87-4ad0-c95b-ed4a54926cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.14)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n"
      ],
      "metadata": {
        "id": "lfoBg7FF7x5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vVZmDcs84DE",
        "outputId": "febfb5f0-abf9-4d90-9fdf-5e7d6d629963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metricr = load(\"rouge\")\n",
        "metricb = load(\"bleu\")"
      ],
      "metadata": {
        "id": "ly4ZTuk87nj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "lsdlzMnpl9xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "\n",
        "    # Note that other metrics may not have a `use_aggregator` parameter\n",
        "    # and thus will return a list, computing a metric for each sentence.\n",
        "    resultr = metricr.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n",
        "    resultb = metricb.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    # Extract a few results\n",
        "    resultr = {key: value * 100 for key, value in resultr.items()}\n",
        "    resultb = {key: value * 100 for key, value in resultb.items()}\n",
        "\n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    resultr[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    rouge = {k: round(v, 4) for k, v in resultr.items()}\n",
        "    rouge[\"bleu\"] = resultb[\"bleu\"]\n",
        "    return rouge"
      ],
      "metadata": {
        "id": "0pYE2OfFmDo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnnQx3J0mFcT",
        "outputId": "dd619f81-0c01-4a19-ca37-a1a7e9ea901f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-786c47e331ae>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "TjrYddZEneP-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "0ba77118-740f-454c-b1c0-847ca02034bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtyler-thraves\u001b[0m (\u001b[33mtyler-thraves-rensselaer-polytechnic-institute\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250322_211834-fa3lmo58</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/tyler-thraves-rensselaer-polytechnic-institute/huggingface/runs/fa3lmo58' target=\"_blank\">bart-large-cnn-finetuned-xsum</a></strong> to <a href='https://wandb.ai/tyler-thraves-rensselaer-polytechnic-institute/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/tyler-thraves-rensselaer-polytechnic-institute/huggingface' target=\"_blank\">https://wandb.ai/tyler-thraves-rensselaer-polytechnic-institute/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/tyler-thraves-rensselaer-polytechnic-institute/huggingface/runs/fa3lmo58' target=\"_blank\">https://wandb.ai/tyler-thraves-rensselaer-polytechnic-institute/huggingface/runs/fa3lmo58</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I keep running into RAM issues, so I'll talk to the teacher to see what the best way to deal with that is.\n",
        "\n",
        "Sounds like I won't get docked for RAM issues, so I'm going to move on."
      ],
      "metadata": {
        "id": "dPx0cLSWwb41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Analyze your results and discuss the impact of hyperparameters. Are your results\n",
        "impacted by the choice of the LLM here? How?**"
      ],
      "metadata": {
        "id": "5GNITfL0a-n1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If I had been able to run the code to completion, I would imagine that the tuning would have resulted in a model with a better rouge score and bleu score than from simply using BART as is. Hyperparameter tuning is useful as it can be used to determine the proper penalties, scale the learning rate, and other important values that might cause a model to converge faster or with better accuracy. Running the model for longer might give a similar result, but it has a risk of overfitting. My result would likely be impacted by the choice of the LLM, as the similarity of BART data to the news data used for tuning would cause a faster convergence for more similarity, and for less similar data it would likely benefit more from tuning."
      ],
      "metadata": {
        "id": "FB6wfpY7bEuR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Task 2(20 points): We discussed how we can formulate RL problems as an MDP. Describe any\n",
        "real-world application that can be formulated as an MDP. Describe the state space, action\n",
        "space, transition model, and rewards for that problem. You do not need to be precise in the\n",
        "description of the transition model and reward (no formula is needed). Qualitative description\n",
        "is enough.**"
      ],
      "metadata": {
        "id": "_QAHkmQAxgkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A self driving car could theoretically be trained using Reinforcement Learning. While such a problem would be hard to give finite states to, it's possible to give access to variables such as: how close the car in the left/right lane is, the current lane of the car, where they are in said lane, how close the car ahead/behind is, the speed/acceleration of the car, and the state of the traffic light. The action space would include turning on turn signals, use of the gas pedal/how much it's used, use of the brake/how much it's used, the current angle of the wheel, and the current gear of the car.\n",
        "\n",
        "As for the transition model, the next position of the car would be determined by the velocity/acceleration as well as the angle of the wheel.\n",
        "\n",
        "To determine the reward/punishment for the state, the car would get a higher reward the closer they are to their destination, and recieve a large penalty for breaking traffic laws such as speeding, changing lane without a signal, or especially crashing.\n",
        "\n",
        "In theory, the car would learn how to efficiently approach it's destination without breaking any laws. It would likely require a lot of training, and to do so safely would require a simulation as opposed to testing in the field."
      ],
      "metadata": {
        "id": "1q5Y2YcRxksk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3(20 points): RL is used in various sectors - Healthcare, recommender systems and trading\n",
        "are a few of those. Pick one of the three areas. Explain one of the problems in any of these\n",
        "domains that can be more effectively solved by reinforcement learning. Find an open-source\n",
        "project (if any) that has addressed this problem. Explain this project in detail.**"
      ],
      "metadata": {
        "id": "KYVesTVs2Z0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reinforcement learning can help with the cold start problem of recommender systems. By considering variables about the items to recommend as the state, the choice of items to recommend would be the action. If those items are clicked on more because they were reccomended, then the system gets a small reward. If those increased clicks result in increased purchases, the system gets a larger reward. By focusing on maximizing the expected increase in clicks, the system will learn to prioritize items that most users will like.\n",
        "\n",
        " I haven't found any open source projects that deal with using reinforcement learning in recommender systems. I have however found a paper that deals with this topic https://arxiv.org/pdf/2108.09141v1, leading me to believe that there aren't open source projects for this specific of a topic that's already been worked on. I will however explain the model for the paper.\n",
        "\n",
        " How it works is that the state for each item involves how often it's viewed, how long it's been availible, and how many sales it's gotten, as well as properties of users associated with the items. The action state is determining a score for each item, with a higher score being more likely to be recommended. The reward is then calculated as the amount of total views the item gets in the next state IPV_t+1, divided by the views caused by reccomendation at the current state, PV_rec,t. By maximizing the sum of the rewards for the items, the system aims to optimize the page views gotten overall. Thus, it will reccomend items to new users that it thinks will in general result in the most views overall.\n",
        "\n"
      ],
      "metadata": {
        "id": "38CIkutb2g8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 5 (30 points): For this task use the MovieLens 100k dataset\n",
        "(https://grouplens.org/datasets/movielens/100k/)\n",
        "Perform the necessary data cleaning, EDA and conversion to User-item matrix.\n",
        "Implement any 2 collaborative filtering recommendation systems (RecSys) algorithms covered\n",
        "in class (Matrix Factorization, Alternating Least Squares, NCF etc.) and compare their\n",
        "performance for any 2-evaluation metrics used for RecSys. You may read literature to find out\n",
        "which evaluation metrics are used for RecSys. Cite all your research.**"
      ],
      "metadata": {
        "id": "xXCM_tMVAr-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First thing's first, I need to get the data."
      ],
      "metadata": {
        "id": "8_6faxTLcmLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip -P /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuDfsPPRc1rC",
        "outputId": "69801b45-a4cf-49c0-807e-b181f78e09cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-26 23:13:20--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘/content/ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  23.8MB/s    in 0.2s    \n",
            "\n",
            "2025-03-26 23:13:20 (23.8 MB/s) - ‘/content/ml-100k.zip’ saved [4924029/4924029]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip ml-100k.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oPwT3Wavc7OP",
        "outputId": "6b4636e0-02a5-4a9b-c3d1-b95634a41567"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ml-100k.zip\n",
            "   creating: ml-100k/\n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: ml-100k/ub.test         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "fVJ24gxReFZv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fortunately, the data is already divided into train and test."
      ],
      "metadata": {
        "id": "E21gXKhWhlJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"ml-100k/ua.base\", sep = \"\\t\", header = None, names = [\"User\", \"Item\", \"Rating\", \"Timestamp\"])\n",
        "test = pd.read_csv(\"ml-100k/ua.test\", sep = \"\\t\", header = None, names = [\"User\", \"Item\", \"Rating\", \"Timestamp\"])"
      ],
      "metadata": {
        "id": "qA1YGCDPeHWQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The guide linked on lesson 18 should be very helpful for this."
      ],
      "metadata": {
        "id": "O0qqsRcOV3Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "xOU91MumfjC8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total = pd.read_csv(\"ml-100k/u.data\", sep = \"\\t\", header = None, names = [\"User\", \"Item\", \"Rating\", \"Timestamp\"])"
      ],
      "metadata": {
        "id": "wlWwsoGYVCeG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.zeros((943, 1682))\n",
        "for i in range(len(train)):\n",
        "  data[train[\"User\"][i] - 1][train[\"Item\"][i] - 1] = train[\"Rating\"][i]"
      ],
      "metadata": {
        "id": "QxGP7rDEojG1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWVwSpXLWw_Q",
        "outputId": "f325e391-b16f-4da4-edd5-052ac5c585d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5. 3. 4. ... 0. 0. 0.]\n",
            " [4. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [5. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 5. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm going to start by implementing alternating least squares."
      ],
      "metadata": {
        "id": "YCNO07deXOnB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random initialization"
      ],
      "metadata": {
        "id": "iHA8zH0fa3QD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Users = np.random.rand(943, 1)\n",
        "Items = np.random.rand(1682, 1)"
      ],
      "metadata": {
        "id": "klik9rWeaSWF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10"
      ],
      "metadata": {
        "id": "4kkxB56Nbd2S"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I got a singular matrix error, so I'll add in a tiny value to prevent a determinant of 0"
      ],
      "metadata": {
        "id": "A1yf_6GQn-pu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training loop"
      ],
      "metadata": {
        "id": "TB4R0BCdbX9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(epochs):\n",
        "  for i in range(943):\n",
        "    RelevantItems = Items[data[i, :] > 0]\n",
        "    RelevantRatings = data[i, data[i, :] > 0]\n",
        "    Users[i] = np.linalg.solve(np.matmul(RelevantItems.T, RelevantItems) + 0.01, np.matmul(RelevantItems.T, RelevantRatings))\n",
        "  for j in range(1682):\n",
        "    RelevantUsers = Users[data[:, j] > 0]\n",
        "    RelevantRatings = data[data[:, j] > 0, j]\n",
        "    Items[j] = np.linalg.solve(np.matmul(RelevantUsers.T, RelevantUsers) + 0.01, np.matmul(RelevantUsers.T, RelevantRatings))"
      ],
      "metadata": {
        "id": "Rsq3BY5zbZc0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Users[0] * Items.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n33U4wSupft3",
        "outputId": "86fbde91-fdab-4ac4-d4cd-ff8e606ae519"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.96310401 3.35242078 3.16933    ... 2.15912876 3.57353495 3.2452953 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdata = np.zeros((943, 1682))\n",
        "for i in range(len(test)):\n",
        "  testdata[test[\"User\"][i] - 1][test[\"Item\"][i] - 1] = test[\"Rating\"][i]"
      ],
      "metadata": {
        "id": "yGIBPjzOqK1y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the first metric I will use Mean Absolute Error, as described here https://neptune.ai/blog/recommender-systems-metrics (under predictive metrics). This was chosen for its popularity, and ease of implementation.\n",
        "To do this I will mask out all the non-tested data points, then calculate the absolute value of the difference of the matrices. Finally, I will compute the average of those values."
      ],
      "metadata": {
        "id": "fK_P9uKWqa5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testmask = testdata > 0"
      ],
      "metadata": {
        "id": "scfWEVAfq5Y_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(testmask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POfddBRXq-qs",
        "outputId": "f60f9d72-e3c5-43c0-c793-50697fd24be4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " ...\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = np.multiply(Users, Items.T)"
      ],
      "metadata": {
        "id": "JwpB2yhMrUCa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8V-79bDraGA",
        "outputId": "2cba4cb6-e967-4142-9a2c-0f1a791a7fe2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.96310401 3.35242078 3.16933    ... 2.15912876 3.57353495 3.2452953 ]\n",
            " [3.974812   3.36232466 3.17869299 ... 2.16550736 3.58409206 3.25488271]\n",
            " [3.38916397 2.8669204  2.71034498 ... 1.84644193 3.05601263 2.77530892]\n",
            " ...\n",
            " [4.11108109 3.47759575 3.28766861 ... 2.23974778 3.70696604 3.36647035]\n",
            " [4.35985271 3.68803362 3.48661352 ... 2.37528043 3.93128367 3.57018375]\n",
            " [3.80312983 3.21709737 3.04139721 ... 2.07197363 3.42928608 3.11429611]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[testmask == False] = 0"
      ],
      "metadata": {
        "id": "L-At9Qefrc3V"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mnKWJYneribg",
        "outputId": "3f8a25e1-4b15-42d0-99ca-fa4a5054807d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sumerror = np.abs(testdata - predictions)"
      ],
      "metadata": {
        "id": "ctRFDxKZsQf-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sum(sumerror) / len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbehHyInsXpY",
        "outputId": "15de5d93-568b-4d9c-ed91-d729bb500579"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7624951778387719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, the mean squared error for this system is 0.762495...\n",
        "\n",
        "I think that's not bad, but there's not exactly a fixed \"good\" score for recommender systems."
      ],
      "metadata": {
        "id": "Nqhg4UGIspTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next up, I will use RMSE, also described here https://neptune.ai/blog/recommender-systems-metrics, and chosen for similar reasons. The way this works is that instead of simply averaging the errors, the errors are squared, added, and then the square root is taken."
      ],
      "metadata": {
        "id": "z2zK01AyvUPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "squareerror = np.square(sumerror)"
      ],
      "metadata": {
        "id": "MoR4Cp58vmwK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squaresum = np.sum(squareerror)"
      ],
      "metadata": {
        "id": "WvQ-EdcVvyM6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averagesquare = squaresum / len(test)"
      ],
      "metadata": {
        "id": "4yYQkE_Yv2kV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sqrt(averagesquare))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ApVwW6av8h8",
        "outputId": "b7d2451b-11cd-4427-d87e-202e034848b5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9684014930777556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, the RMSE for this system is 0.9684....\n",
        "\n",
        "Again, I'm not really sure what a \"good\" score is, but this doesn't seem that bad."
      ],
      "metadata": {
        "id": "KLBmX-_DwBKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second method I will implement is Matrix factorization using SVD. This will be done through scipy, loosely following the guide in lesson 18. Since the data is the same as in alternating least squares, I'll just simply take that matrix. I'll have to demean the data though."
      ],
      "metadata": {
        "id": "oo14FSoHw2vQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meanratings = np.mean(data, axis = 1)"
      ],
      "metadata": {
        "id": "otxsVfsLx2SS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demeaneddata = data - meanratings.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "-vPAN286yBX2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The guide linked in lesson 18 uses a k of 50. After doing some tinkering, I settled on 25 as giving the best error."
      ],
      "metadata": {
        "id": "4mI9wOG8yY_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SVD\n",
        "from scipy.sparse.linalg import svds\n",
        "U, sigma, Vt = svds(demeaneddata, k = 25)"
      ],
      "metadata": {
        "id": "VqyNAK9NzBBu"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sigma = np.diag(sigma)"
      ],
      "metadata": {
        "id": "Y9Vag2C3zFua"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sigma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rhNJDY_ezI1N",
        "outputId": "9f5537bf-f1bd-478d-9e35-e24cba94daf2"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 67.84962381   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.          68.20853197   0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.          68.99264932   0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.          69.77810571   0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.          70.73608247\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "   72.46776004   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.          72.69758785   0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.          73.79018902   0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.          74.27019146   0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.          75.93296202\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "   77.54273033   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.          80.53649066   0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.          84.12597151   0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.          86.02272958   0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.          86.98293502\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "   93.94763873   0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.          98.65828884   0.           0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.         104.68856631   0.           0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.         117.10867859   0.\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.         124.24948022\n",
            "    0.           0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "  134.53927115   0.           0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.         148.18576006   0.           0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.         194.437445     0.           0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.         220.25594609   0.        ]\n",
            " [  0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.           0.\n",
            "    0.           0.           0.           0.         490.78098921]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = np.dot(np.dot(U, sigma), Vt) + meanratings.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "9XNVZMl_zN61"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0K2D74Uzk05",
        "outputId": "49f23d9b-89f4-4620-b3e9-28440b9e1338"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4.81567664e+00  1.80406737e+00  1.56115694e+00 ...  4.64763540e-03\n",
            "   2.49179618e-02  1.11197331e-01]\n",
            " [ 1.83788335e+00 -6.77260181e-02 -2.47645699e-02 ... -1.74749747e-02\n",
            "  -3.67621913e-02 -8.12254074e-02]\n",
            " [ 1.92254647e-02 -7.40483882e-03  1.74401980e-01 ...  2.86203585e-02\n",
            "   5.96692766e-03  8.30478501e-03]\n",
            " ...\n",
            " [ 7.97948938e-01  3.25875040e-02  1.59352480e-01 ...  1.21644496e-02\n",
            "   2.00727177e-02  1.53032014e-03]\n",
            " [ 1.52486576e+00  3.84762788e-01 -1.20639371e-01 ...  3.72313504e-02\n",
            "   1.73374557e-02  7.53984744e-03]\n",
            " [ 1.73397908e+00  1.94265917e+00  1.34257934e+00 ... -2.85129329e-02\n",
            "  -1.41732166e-02  8.23417030e-03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've already got the test data and mask from ALE, so I'll just pull that over for testing MAE."
      ],
      "metadata": {
        "id": "ccn-cven2lHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[testmask == False] = 0"
      ],
      "metadata": {
        "id": "F0adDxNFzrTx"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sumerror = np.abs(testdata - predictions)"
      ],
      "metadata": {
        "id": "pSN4GOXB0GVJ"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sum(sumerror) / len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0dl4QfE0I0j",
        "outputId": "587fece5-57b5-421c-80ed-454b3ac05e6a"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5608889401451504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, clearly this doesn't seem as good as Alternating Least Squares, but let's see if it does better on RMSE."
      ],
      "metadata": {
        "id": "KnsuKBpf0KoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "squareerror = np.square(sumerror)"
      ],
      "metadata": {
        "id": "g-0waTPI2xm9"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squaresum = np.sum(squareerror)"
      ],
      "metadata": {
        "id": "1-NAMiN82zkr"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averagesquare = squaresum / len(test)"
      ],
      "metadata": {
        "id": "uww3GWqI21f_"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sqrt(averagesquare))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4hFXy9Z23pq",
        "outputId": "21f95aa8-4154-44f9-dd18-a3e12e464c40"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.838224471591872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, the RMSE also did worse than in ALS. I think it may be that SVD didn't have a way to account for the missing entries, and treated them as if they actually were rated 0. As a result, the approximation was too far from the test values."
      ],
      "metadata": {
        "id": "4SDHwOP925EJ"
      }
    }
  ]
}