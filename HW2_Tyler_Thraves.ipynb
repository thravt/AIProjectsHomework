{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thravt/AIProjectsHomework/blob/main/HW2_Tyler_Thraves.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWVvbF891f9u"
      },
      "source": [
        "Base imports/installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gmtyccTipPqE",
        "outputId": "8396bcf0-3ffd-4e37-c2aa-45854bf2b43a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.6.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.1.8)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle->opendatasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle->opendatasets) (3.10)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n",
            "Collecting tensorflow_decision_forests\n",
            "  Downloading tensorflow_decision_forests-1.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorflow_decision_forests) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from tensorflow_decision_forests) (2.2.2)\n",
            "Collecting tensorflow==2.18.0 (from tensorflow_decision_forests)\n",
            "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tensorflow_decision_forests) (1.17.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from tensorflow_decision_forests) (1.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from tensorflow_decision_forests) (0.45.1)\n",
            "Collecting wurlitzer (from tensorflow_decision_forests)\n",
            "  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: tf-keras~=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow_decision_forests) (2.17.0)\n",
            "Collecting ydf (from tensorflow_decision_forests)\n",
            "  Downloading ydf-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (25.1.21)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (75.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (1.69.0)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (3.5.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (0.37.1)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras~=2.17 (from tensorflow_decision_forests)\n",
            "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow_decision_forests) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow_decision_forests) (2025.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.18.0->tensorflow_decision_forests) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.18.0->tensorflow_decision_forests) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.18.0->tensorflow_decision_forests) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0->tensorflow_decision_forests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0->tensorflow_decision_forests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0->tensorflow_decision_forests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0->tensorflow_decision_forests) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0->tensorflow_decision_forests) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0->tensorflow_decision_forests) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0->tensorflow_decision_forests) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow==2.18.0->tensorflow_decision_forests) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow==2.18.0->tensorflow_decision_forests) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow==2.18.0->tensorflow_decision_forests) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.18.0->tensorflow_decision_forests) (0.1.2)\n",
            "Downloading tensorflow_decision_forests-1.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n",
            "Downloading ydf-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ydf, wurlitzer, tensorboard, tensorflow, tf-keras, tensorflow_decision_forests\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.17.0\n",
            "    Uninstalling tf_keras-2.17.0:\n",
            "      Successfully uninstalled tf_keras-2.17.0\n",
            "Successfully installed tensorboard-2.18.0 tensorflow-2.18.0 tensorflow_decision_forests-1.11.0 tf-keras-2.18.0 wurlitzer-3.1.1 ydf-0.9.0\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.11/dist-packages (3.1.1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<p style=\"margin:0px;\">🌲 Try <a href=\"https://ydf.readthedocs.io/en/latest/\" target=\"_blank\">YDF</a>, the successor of\n",
              "    <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">TensorFlow\n",
              "        Decision Forests</a> using the same algorithms but with more features and faster\n",
              "    training!\n",
              "</p>\n",
              "<div style=\"display: flex; flex-wrap: wrap; margin:5px;max-width: 880px;\">\n",
              "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
              "        <p\n",
              "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
              "            Old code</p>\n",
              "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
              "import tensorflow_decision_forests as tfdf\n",
              "\n",
              "tf_ds = tfdf.keras.pd_dataframe_to_tf_dataset(ds, label=\"l\")\n",
              "model = tfdf.keras.RandomForestModel(label=\"l\")\n",
              "model.fit(tf_ds)\n",
              "</pre>\n",
              "    </div>\n",
              "    <div style=\"width: 5px;\"></div>\n",
              "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
              "        <p\n",
              "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
              "            New code</p>\n",
              "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
              "import ydf\n",
              "\n",
              "model = ydf.RandomForestLearner(label=\"l\").train(ds)\n",
              "</pre>\n",
              "    </div>\n",
              "</div>\n",
              "<p style=\"margin:0px;font-size: 9pt;\">(Learn more in the <a\n",
              "        href=\"https://ydf.readthedocs.io/en/latest/tutorial/migrating_to_ydf/\" target=\"_blank\">migration\n",
              "        guide</a>)</p>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install opendatasets\n",
        "import math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import opendatasets as od\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import random\n",
        "import os\n",
        "!pip install tensorflow_decision_forests\n",
        "!pip install wurlitzer\n",
        "# Keep using Keras 2\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
        "import tensorflow_decision_forests as tfdf\n",
        "import tensorflow as tf\n",
        "import tf_keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcPEZ0rU1ndL"
      },
      "source": [
        "Download the database from HW1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk697XHu1Zjt",
        "outputId": "cf339522-7f53-4cd4-e159-006e0e8c69d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: tylerthraves\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/devzohaib/eligibility-prediction-for-loan\n",
            "Downloading eligibility-prediction-for-loan.zip to ./eligibility-prediction-for-loan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7.80k/7.80k [00:00<00:00, 5.48MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "od.download(\n",
        "    \"https://www.kaggle.com/datasets/devzohaib/eligibility-prediction-for-loan\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWQm0BrZ1rwg"
      },
      "source": [
        "**Task 1 (30 points): Implement a Decision Tree Classifier for your classification problem. You\n",
        "may use a built-in package to implement your classifier.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjCy8_yu1wXr"
      },
      "source": [
        "To implement the decision tree I will be using the tensorflow_decision_forests package in order to make the tree. The package is well documented on their official website: https://www.tensorflow.org/decision_forests/tutorials/beginner_colab. The choices for the model are listed below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YgLv5OF2Wrd",
        "outputId": "d671e2d5-a8b7-4640-b78a-5c110c5dea6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensorflow_decision_forests.keras.RandomForestModel,\n",
              " tensorflow_decision_forests.keras.GradientBoostedTreesModel,\n",
              " tensorflow_decision_forests.keras.CartModel,\n",
              " tensorflow_decision_forests.keras.DistributedGradientBoostedTreesModel]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfdf.keras.get_all_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A28gVSdB2nDV"
      },
      "source": [
        "I'll use CartModel for this task, as it is the primary method discussed in lecture 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09XS1eo13LOC"
      },
      "source": [
        "Loading the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Grzix3x33Ocg",
        "outputId": "e5915e9d-9be9-4f71-d673-0216270aad25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-69faf7997abd>:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  Database['Loan_Status'] = Database['Loan_Status'].replace({'Y': 1, 'N': 0})\n"
          ]
        }
      ],
      "source": [
        "file =('eligibility-prediction-for-loan/\\\n",
        "Loan_Data.csv')\n",
        "Database = pd.read_csv(file)\n",
        "Database['Loan_Status'] = Database['Loan_Status'].replace({'Y': 1, 'N': 0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DeVL4yFQ3RyA"
      },
      "outputs": [],
      "source": [
        "label = 'Loan_Status'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSjHY0ac4-RF"
      },
      "source": [
        "Convert to a tensorflow dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-Wd9Xxem5Bha"
      },
      "outputs": [],
      "source": [
        "Dataset = tfdf.keras.pd_dataframe_to_tf_dataset(Database, label = label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYWeJA1P5QQd",
        "outputId": "11be6c13-cfd5-4769-c76b-948de62491c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<_PrefetchDataset element_spec=({'Loan_ID': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'Gender': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'Married': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'Dependents': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'Education': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'Self_Employed': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'ApplicantIncome': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'CoapplicantIncome': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'LoanAmount': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'Loan_Amount_Term': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'Credit_History': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'Property_Area': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, TensorSpec(shape=(None,), dtype=tf.int64, name=None))>\n"
          ]
        }
      ],
      "source": [
        "print(Dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y33Zhibq5iqX"
      },
      "source": [
        "Make the Cart model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wYQpmUq5lTg",
        "outputId": "3781e937-9142-49dc-e16a-16a251ab0b4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use /tmp/tmpehdkwnhl as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:04.510521. Found 614 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.054352\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x78a34e9d2bd0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Cart1 = tfdf.keras.CartModel()\n",
        "Cart1.fit(Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UhOvQZS6BYU",
        "outputId": "0167add9-075f-40b0-db52-c8aa585255a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"cart_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1 (1.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 1 (1.00 Byte)\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (12):\n",
            "\tApplicantIncome\n",
            "\tCoapplicantIncome\n",
            "\tCredit_History\n",
            "\tDependents\n",
            "\tEducation\n",
            "\tGender\n",
            "\tLoanAmount\n",
            "\tLoan_Amount_Term\n",
            "\tLoan_ID\n",
            "\tMarried\n",
            "\tProperty_Area\n",
            "\tSelf_Employed\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1.    \"Credit_History\"  1.000000 ################\n",
            "    2.     \"Property_Area\"  0.500000 ######\n",
            "    3.   \"ApplicantIncome\"  0.344828 ###\n",
            "    4. \"CoapplicantIncome\"  0.222222 \n",
            "    5.        \"LoanAmount\"  0.175439 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1. \"Credit_History\"  1.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1.   \"ApplicantIncome\"  4.000000 ################\n",
            "    2. \"CoapplicantIncome\"  2.000000 #####\n",
            "    3.    \"Credit_History\"  1.000000 \n",
            "    4.        \"LoanAmount\"  1.000000 \n",
            "    5.     \"Property_Area\"  1.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1.    \"Credit_History\" 77.371266 ################\n",
            "    2.   \"ApplicantIncome\" 13.102830 ##\n",
            "    3. \"CoapplicantIncome\"  7.729090 #\n",
            "    4.     \"Property_Area\"  5.213080 #\n",
            "    5.        \"LoanAmount\"  0.394958 \n",
            "\n",
            "\n",
            "\n",
            "Winner takes all: false\n",
            "Out-of-bag evaluation: accuracy:0.842105 logloss:1.04088\n",
            "Number of trees: 1\n",
            "Total number of nodes: 19\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 1 Average: 19 StdDev: 0\n",
            "Min: 19 Max: 19 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 19, 19] 1 100.00% 100.00% ##########\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 10 Average: 4.9 StdDev: 2.2561\n",
            "Min: 1 Max: 8 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 1, 2) 1  10.00%  10.00% ###\n",
            "[ 2, 3) 1  10.00%  20.00% ###\n",
            "[ 3, 4) 0   0.00%  20.00%\n",
            "[ 4, 5) 3  30.00%  50.00% ##########\n",
            "[ 5, 6) 1  10.00%  60.00% ###\n",
            "[ 6, 7) 1  10.00%  70.00% ###\n",
            "[ 7, 8) 1  10.00%  80.00% ###\n",
            "[ 8, 8] 2  20.00% 100.00% #######\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 10 Average: 55.7 StdDev: 65.1276\n",
            "Min: 5 Max: 184 Ignored: 0\n",
            "----------------------------------------------\n",
            "[   5,  14) 4  40.00%  40.00% ##########\n",
            "[  14,  23) 0   0.00%  40.00%\n",
            "[  23,  32) 2  20.00%  60.00% #####\n",
            "[  32,  41) 0   0.00%  60.00%\n",
            "[  41,  50) 1  10.00%  70.00% ###\n",
            "[  50,  59) 0   0.00%  70.00%\n",
            "[  59,  68) 0   0.00%  70.00%\n",
            "[  68,  77) 0   0.00%  70.00%\n",
            "[  77,  86) 1  10.00%  80.00% ###\n",
            "[  86,  95) 0   0.00%  80.00%\n",
            "[  95, 104) 0   0.00%  80.00%\n",
            "[ 104, 113) 0   0.00%  80.00%\n",
            "[ 113, 122) 0   0.00%  80.00%\n",
            "[ 122, 131) 0   0.00%  80.00%\n",
            "[ 131, 140) 0   0.00%  80.00%\n",
            "[ 140, 149) 0   0.00%  80.00%\n",
            "[ 149, 158) 0   0.00%  80.00%\n",
            "[ 158, 167) 0   0.00%  80.00%\n",
            "[ 167, 176) 1  10.00%  90.00% ###\n",
            "[ 176, 184] 1  10.00% 100.00% ###\n",
            "\n",
            "Attribute in nodes:\n",
            "\t4 : ApplicantIncome [NUMERICAL]\n",
            "\t2 : CoapplicantIncome [NUMERICAL]\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : LoanAmount [NUMERICAL]\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\t1 : ApplicantIncome [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t2 : ApplicantIncome [NUMERICAL]\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : LoanAmount [NUMERICAL]\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t3 : ApplicantIncome [NUMERICAL]\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : LoanAmount [NUMERICAL]\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\t1 : CoapplicantIncome [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t8 : HigherCondition\n",
            "\t1 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t1 : HigherCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t1 : ContainsBitmapCondition\n",
            "\t1 : HigherCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t2 : HigherCondition\n",
            "\t1 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t4 : HigherCondition\n",
            "\t1 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t6 : HigherCondition\n",
            "\t1 : ContainsBitmapCondition\n",
            "Node format: NOT_SET\n",
            "Pruned nodes during training: 100\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:0.842105 logloss:1.04088\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(Cart1.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SenIgW406baa"
      },
      "source": [
        "Show a visual representation of the tree for easier understanding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "UsbIDU1f6jD2",
        "outputId": "4d3c36f5-73c8-4b89-f1d5-9734e088081a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<script src=\"https://d3js.org/d3.v6.min.js\"></script>\n",
              "<div id=\"tree_plot_9e7c77fd1dae4f80a5993cd4597ffea5\"></div>\n",
              "<script>\n",
              "/*\n",
              " * Copyright 2021 Google LLC.\n",
              " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              " * you may not use this file except in compliance with the License.\n",
              " * You may obtain a copy of the License at\n",
              " *\n",
              " *     https://www.apache.org/licenses/LICENSE-2.0\n",
              " *\n",
              " * Unless required by applicable law or agreed to in writing, software\n",
              " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              " * See the License for the specific language governing permissions and\n",
              " * limitations under the License.\n",
              " */\n",
              "\n",
              "/**\n",
              " *  Plotting of decision trees generated by TF-DF.\n",
              " *\n",
              " *  A tree is a recursive structure of node objects.\n",
              " *  A node contains one or more of the following components:\n",
              " *\n",
              " *    - A value: Representing the output of the node. If the node is not a leaf,\n",
              " *      the value is only present for analysis i.e. it is not used for\n",
              " *      predictions.\n",
              " *\n",
              " *    - A condition : For non-leaf nodes, the condition (also known as split)\n",
              " *      defines a binary test to branch to the positive or negative child.\n",
              " *\n",
              " *    - An explanation: Generally a plot showing the relation between the label\n",
              " *      and the condition to give insights about the effect of the condition.\n",
              " *\n",
              " *    - Two children : For non-leaf nodes, the children nodes. The first\n",
              " *      children (i.e. \"node.children[0]\") is the negative children (drawn in\n",
              " *      red). The second children is the positive one (drawn in green).\n",
              " *\n",
              " */\n",
              "\n",
              "/**\n",
              " * Plots a single decision tree into a DOM element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!tree} raw_tree Recursive tree structure.\n",
              " * @param {string} canvas_id Id of the output dom element.\n",
              " */\n",
              "function display_tree(options, raw_tree, canvas_id) {\n",
              "  console.log(options);\n",
              "\n",
              "  // Determine the node placement.\n",
              "  const tree_struct = d3.tree().nodeSize(\n",
              "      [options.node_y_offset, options.node_x_offset])(d3.hierarchy(raw_tree));\n",
              "\n",
              "  // Boundaries of the node placement.\n",
              "  let x_min = Infinity;\n",
              "  let x_max = -x_min;\n",
              "  let y_min = Infinity;\n",
              "  let y_max = -x_min;\n",
              "\n",
              "  tree_struct.each(d => {\n",
              "    if (d.x > x_max) x_max = d.x;\n",
              "    if (d.x < x_min) x_min = d.x;\n",
              "    if (d.y > y_max) y_max = d.y;\n",
              "    if (d.y < y_min) y_min = d.y;\n",
              "  });\n",
              "\n",
              "  // Size of the plot.\n",
              "  const width = y_max - y_min + options.node_x_size + options.margin * 2;\n",
              "  const height = x_max - x_min + options.node_y_size + options.margin * 2 +\n",
              "      options.node_y_offset - options.node_y_size;\n",
              "\n",
              "  const plot = d3.select(canvas_id);\n",
              "\n",
              "  // Tool tip\n",
              "  options.tooltip = plot.append('div')\n",
              "                        .attr('width', 100)\n",
              "                        .attr('height', 100)\n",
              "                        .style('padding', '4px')\n",
              "                        .style('background', '#fff')\n",
              "                        .style('box-shadow', '4px 4px 0px rgba(0,0,0,0.1)')\n",
              "                        .style('border', '1px solid black')\n",
              "                        .style('font-family', 'sans-serif')\n",
              "                        .style('font-size', options.font_size)\n",
              "                        .style('position', 'absolute')\n",
              "                        .style('z-index', '10')\n",
              "                        .attr('pointer-events', 'none')\n",
              "                        .style('display', 'none');\n",
              "\n",
              "  // Create canvas\n",
              "  const svg = plot.append('svg').attr('width', width).attr('height', height);\n",
              "  const graph =\n",
              "      svg.style('overflow', 'visible')\n",
              "          .append('g')\n",
              "          .attr('font-family', 'sans-serif')\n",
              "          .attr('font-size', options.font_size)\n",
              "          .attr(\n",
              "              'transform',\n",
              "              () => `translate(${options.margin},${\n",
              "                  - x_min + options.node_y_offset / 2 + options.margin})`);\n",
              "\n",
              "  // Plot bounding box.\n",
              "  if (options.show_plot_bounding_box) {\n",
              "    svg.append('rect')\n",
              "        .attr('width', width)\n",
              "        .attr('height', height)\n",
              "        .attr('fill', 'none')\n",
              "        .attr('stroke-width', 1.0)\n",
              "        .attr('stroke', 'black');\n",
              "  }\n",
              "\n",
              "  // Draw the edges.\n",
              "  display_edges(options, graph, tree_struct);\n",
              "\n",
              "  // Draw the nodes.\n",
              "  display_nodes(options, graph, tree_struct);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Draw the nodes of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_nodes(options, graph, tree_struct) {\n",
              "  const nodes = graph.append('g')\n",
              "                    .selectAll('g')\n",
              "                    .data(tree_struct.descendants())\n",
              "                    .join('g')\n",
              "                    .attr('transform', d => `translate(${d.y},${d.x})`);\n",
              "\n",
              "  nodes.append('rect')\n",
              "      .attr('x', 0.5)\n",
              "      .attr('y', 0.5)\n",
              "      .attr('width', options.node_x_size)\n",
              "      .attr('height', options.node_y_size)\n",
              "      .attr('stroke', 'lightgrey')\n",
              "      .attr('stroke-width', 1)\n",
              "      .attr('fill', 'white')\n",
              "      .attr('y', -options.node_y_size / 2);\n",
              "\n",
              "  // Brackets on the right of condition nodes without children.\n",
              "  non_leaf_node_without_children =\n",
              "      nodes.filter(node => node.data.condition != null && node.children == null)\n",
              "          .append('g')\n",
              "          .attr('transform', `translate(${options.node_x_size},0)`);\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,10 10,10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#F00');\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,-10 10,-10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#0F0');\n",
              "\n",
              "  const node_content = nodes.append('g').attr(\n",
              "      'transform',\n",
              "      `translate(0,${options.node_padding - options.node_y_size / 2})`);\n",
              "\n",
              "  node_content.append(node => create_node_element(options, node));\n",
              "}\n",
              "\n",
              "/**\n",
              " * Creates the D3 content for a single node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!node} node Node to draw.\n",
              " * @return {!d3} D3 content.\n",
              " */\n",
              "function create_node_element(options, node) {\n",
              "  // Output accumulator.\n",
              "  let output = {\n",
              "    // Content to draw.\n",
              "    content: d3.create('svg:g'),\n",
              "    // Vertical offset to the next element to draw.\n",
              "    vertical_offset: 0\n",
              "  };\n",
              "\n",
              "  // Conditions.\n",
              "  if (node.data.condition != null) {\n",
              "    display_condition(options, node.data.condition, output);\n",
              "  }\n",
              "\n",
              "  // Values.\n",
              "  if (node.data.value != null) {\n",
              "    display_value(options, node.data.value, output);\n",
              "  }\n",
              "\n",
              "  // Explanations.\n",
              "  if (node.data.explanation != null) {\n",
              "    display_explanation(options, node.data.explanation, output);\n",
              "  }\n",
              "\n",
              "  return output.content.node();\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text(options, text, output) {\n",
              "  output.content.append('text')\n",
              "      .attr('x', options.node_padding)\n",
              "      .attr('y', output.vertical_offset)\n",
              "      .attr('alignment-baseline', 'hanging')\n",
              "      .text(text);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node with a tooltip.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {string} tooltip Text in the Tooltip.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text_with_tooltip(options, text, tooltip, output) {\n",
              "  const item = output.content.append('text')\n",
              "                   .attr('x', options.node_padding)\n",
              "                   .attr('alignment-baseline', 'hanging')\n",
              "                   .text(text);\n",
              "\n",
              "  add_tooltip(options, item, () => tooltip);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a tooltip to a dom element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!dom} target Dom element to equip with a tooltip.\n",
              " * @param {!func} get_content Generates the html content of the tooltip.\n",
              " */\n",
              "function add_tooltip(options, target, get_content) {\n",
              "  function show(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.html(get_content());\n",
              "  }\n",
              "\n",
              "  function hide(d) {\n",
              "    options.tooltip.style('display', 'none');\n",
              "  }\n",
              "\n",
              "  function move(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.style('left', (d.pageX + 5) + 'px');\n",
              "    options.tooltip.style('top', d.pageY + 'px');\n",
              "  }\n",
              "\n",
              "  target.on('mouseover', show);\n",
              "  target.on('mouseout', hide);\n",
              "  target.on('mousemove', move);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a condition inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!condition} condition Condition to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_condition(options, condition, output) {\n",
              "  threshold_format = d3.format('r');\n",
              "\n",
              "  if (condition.type === 'IS_MISSING') {\n",
              "    display_node_text(options, `${condition.attribute} is missing`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'IS_TRUE') {\n",
              "    display_node_text(options, `${condition.attribute} is true`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_IS_HIGHER_THAN') {\n",
              "    format = d3.format('r');\n",
              "    display_node_text(\n",
              "        options,\n",
              "        `${condition.attribute} >= ${threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_IS_IN') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} in [...]`,\n",
              "        `${condition.attribute} in [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_SET_CONTAINS') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} intersect [...]`,\n",
              "        `${condition.attribute} intersect [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_SPARSE_OBLIQUE') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `Sparse oblique split...`,\n",
              "        `[${condition.attributes}]*[${condition.weights}]>=${\n",
              "            threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported condition ${condition.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a value inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!value} value Value to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_value(options, value, output) {\n",
              "  if (value.type === 'PROBABILITY') {\n",
              "    const left_margin = 0;\n",
              "    const right_margin = 50;\n",
              "    const plot_width = options.node_x_size - options.node_padding * 2 -\n",
              "        left_margin - right_margin;\n",
              "\n",
              "    let cusum = Array.from(d3.cumsum(value.distribution));\n",
              "    cusum.unshift(0);\n",
              "    const distribution_plot = output.content.append('g').attr(\n",
              "        'transform', `translate(0,${output.vertical_offset + 0.5})`);\n",
              "\n",
              "    distribution_plot.selectAll('rect')\n",
              "        .data(value.distribution)\n",
              "        .join('rect')\n",
              "        .attr('height', 10)\n",
              "        .attr(\n",
              "            'x',\n",
              "            (d, i) =>\n",
              "                (cusum[i] * plot_width + left_margin + options.node_padding))\n",
              "        .attr('width', (d, i) => d * plot_width)\n",
              "        .style('fill', (d, i) => d3.schemeSet1[i]);\n",
              "\n",
              "    const num_examples =\n",
              "        output.content.append('g')\n",
              "            .attr('transform', `translate(0,${output.vertical_offset})`)\n",
              "            .append('text')\n",
              "            .attr('x', options.node_x_size - options.node_padding)\n",
              "            .attr('alignment-baseline', 'hanging')\n",
              "            .attr('text-anchor', 'end')\n",
              "            .text(`(${value.num_examples})`);\n",
              "\n",
              "    const distribution_details = d3.create('ul');\n",
              "    distribution_details.selectAll('li')\n",
              "        .data(value.distribution)\n",
              "        .join('li')\n",
              "        .append('span')\n",
              "        .text(\n",
              "            (d, i) =>\n",
              "                'class ' + i + ': ' + d3.format('.3%')(value.distribution[i]));\n",
              "\n",
              "    add_tooltip(options, distribution_plot, () => distribution_details.html());\n",
              "    add_tooltip(options, num_examples, () => 'Number of examples');\n",
              "\n",
              "    output.vertical_offset += 10;\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'REGRESSION') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'value: ' + d3.format('r')(value.value) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'UPLIFT') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'effect: ' + d3.format('r')(value.treatment_effect) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(options, `Non supported value ${value.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds an explanation inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!explanation} explanation Explanation to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_explanation(options, explanation, output) {\n",
              "  // Margin before the explanation.\n",
              "  output.vertical_offset += 10;\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported explanation ${explanation.type}`, output);\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Draw the edges of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_edges(options, graph, tree_struct) {\n",
              "  // Draw an edge between a parent and a child node with a bezier.\n",
              "  function draw_single_edge(d) {\n",
              "    return 'M' + (d.source.y + options.node_x_size) + ',' + d.source.x + ' C' +\n",
              "        (d.source.y + options.node_x_size + options.edge_rounding) + ',' +\n",
              "        d.source.x + ' ' + (d.target.y - options.edge_rounding) + ',' +\n",
              "        d.target.x + ' ' + d.target.y + ',' + d.target.x;\n",
              "  }\n",
              "\n",
              "  graph.append('g')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.2)\n",
              "      .selectAll('path')\n",
              "      .data(tree_struct.links())\n",
              "      .join('path')\n",
              "      .attr('d', draw_single_edge)\n",
              "      .attr(\n",
              "          'stroke', d => (d.target === d.source.children[0]) ? '#0F0' : '#F00');\n",
              "}\n",
              "\n",
              "display_tree({\"margin\": 10, \"node_x_size\": 160, \"node_y_size\": 28, \"node_x_offset\": 180, \"node_y_offset\": 33, \"font_size\": 10, \"edge_rounding\": 20, \"node_padding\": 2, \"show_plot_bounding_box\": false}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3123877917414722, 0.6876122082585279], \"num_examples\": 557.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Credit_History\", \"threshold\": 0.42109930515289307}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.21008403361344538, 0.7899159663865546], \"num_examples\": 476.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"Property_Area\", \"mask\": [\"Semiurban\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.1358695652173913, 0.8641304347826086], \"num_examples\": 184.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.2568493150684932, 0.7431506849315068], \"num_examples\": 292.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ApplicantIncome\", \"threshold\": 1612.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.24555160142348753, 0.7544483985765125], \"num_examples\": 281.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ApplicantIncome\", \"threshold\": 3399.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.29651162790697677, 0.7034883720930233], \"num_examples\": 172.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.1651376146788991, 0.8348623853211009], \"num_examples\": 109.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"CoapplicantIncome\", \"threshold\": 618.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.08974358974358974, 0.9102564102564102], \"num_examples\": 78.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ApplicantIncome\", \"threshold\": 2956.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 26.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.1346153846153846, 0.8653846153846154], \"num_examples\": 52.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"CoapplicantIncome\", \"threshold\": 2816.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.36363636363636365, 0.6363636363636364], \"num_examples\": 11.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ApplicantIncome\", \"threshold\": 2459.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 6.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8, 0.2], \"num_examples\": 5.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.07317073170731707, 0.926829268292683], \"num_examples\": 41.0}}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3548387096774194, 0.6451612903225806], \"num_examples\": 31.0}}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.5454545454545454, 0.45454545454545453], \"num_examples\": 11.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"LoanAmount\", \"threshold\": 123.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.6666666666666666, 0.3333333333333333], \"num_examples\": 6.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.4, 0.6], \"num_examples\": 5.0}}]}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9135802469135802, 0.08641975308641975], \"num_examples\": 81.0}}]}, \"#tree_plot_9e7c77fd1dae4f80a5993cd4597ffea5\")\n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(Cart1, tree_idx=0, max_depth=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y04ArHJ97z6y"
      },
      "source": [
        "As we can see, the default settings gave us an accuracy of around 84%, which compared with the last homework I did, I'd say it turned out pretty great. Focusing on the individual parameters used for decisions, Credit history seems to be the most important, as a low enough amount will result in a nearly guranteed denial. If it's high enough, it seems like a semiurban property area will result in a likely approval. From there it's mostly a balance of the applicant income, the loan amount, and the coapplicant income, with a high applicant income and coapplicant income being more likely to get approval, and a high loan amount being less likely to get approval."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utgp8ouWGJn2"
      },
      "source": [
        "**Visualize the decision tree structure for at least three different parameter settings.\n",
        "Comment on how the depth and complexity change the tree.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJQknGpGGTG6"
      },
      "source": [
        "The first parameter setting to be visualized is the defaults, as shown above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7NBeDQWGcf5"
      },
      "source": [
        "The second I will be visualizing is setting min_examples to 2, in order to see if the decreased requirement will result in more accurate leafs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SZBLmTbHU6V",
        "outputId": "610fafeb-5369-4a4f-8a28-58ee5d9e8685"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use /tmp/tmppyufub9g as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.251228. Found 614 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.046405\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7e429283f1d0>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Cart2 = tfdf.keras.CartModel(min_examples = 2)\n",
        "Cart2.fit(Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdnlt7c0HbDp",
        "outputId": "6c3fd3b4-58ad-4f5e-b272-e87d32dd1555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"cart_model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1 (1.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 1 (1.00 Byte)\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (12):\n",
            "\tApplicantIncome\n",
            "\tCoapplicantIncome\n",
            "\tCredit_History\n",
            "\tDependents\n",
            "\tEducation\n",
            "\tGender\n",
            "\tLoanAmount\n",
            "\tLoan_Amount_Term\n",
            "\tLoan_ID\n",
            "\tMarried\n",
            "\tProperty_Area\n",
            "\tSelf_Employed\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1.    \"Credit_History\"  1.000000 ################\n",
            "    2.     \"Property_Area\"  0.500000 ######\n",
            "    3. \"CoapplicantIncome\"  0.342105 ###\n",
            "    4.   \"ApplicantIncome\"  0.220339 #\n",
            "    5.        \"LoanAmount\"  0.156627 \n",
            "    6.        \"Dependents\"  0.146067 \n",
            "    7.         \"Education\"  0.138298 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1. \"Credit_History\"  1.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1. \"CoapplicantIncome\"  3.000000 ################\n",
            "    2.   \"ApplicantIncome\"  2.000000 ########\n",
            "    3.    \"Credit_History\"  2.000000 ########\n",
            "    4.        \"LoanAmount\"  2.000000 ########\n",
            "    5.        \"Dependents\"  1.000000 \n",
            "    6.         \"Education\"  1.000000 \n",
            "    7.     \"Property_Area\"  1.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1.    \"Credit_History\" 78.556205 ################\n",
            "    2. \"CoapplicantIncome\" 11.877326 ##\n",
            "    3.   \"ApplicantIncome\"  7.182562 #\n",
            "    4.     \"Property_Area\"  5.213080 \n",
            "    5.        \"LoanAmount\"  3.221582 \n",
            "    6.         \"Education\"  2.071032 \n",
            "    7.        \"Dependents\"  1.754267 \n",
            "\n",
            "\n",
            "\n",
            "Winner takes all: false\n",
            "Out-of-bag evaluation: accuracy:0.842105 logloss:0.470521\n",
            "Number of trees: 1\n",
            "Total number of nodes: 25\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 1 Average: 25 StdDev: 0\n",
            "Min: 25 Max: 25 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 25, 25] 1 100.00% 100.00% ##########\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 13 Average: 6.92308 StdDev: 3.62601\n",
            "Min: 1 Max: 12 Ignored: 0\n",
            "----------------------------------------------\n",
            "[  1,  2) 1   7.69%   7.69% #####\n",
            "[  2,  3) 1   7.69%  15.38% #####\n",
            "[  3,  4) 1   7.69%  23.08% #####\n",
            "[  4,  5) 1   7.69%  30.77% #####\n",
            "[  5,  6) 1   7.69%  38.46% #####\n",
            "[  6,  7) 1   7.69%  46.15% #####\n",
            "[  7,  8) 1   7.69%  53.85% #####\n",
            "[  8,  9) 1   7.69%  61.54% #####\n",
            "[  9, 10) 1   7.69%  69.23% #####\n",
            "[ 10, 11) 1   7.69%  76.92% #####\n",
            "[ 11, 12) 1   7.69%  84.62% #####\n",
            "[ 12, 12] 2  15.38% 100.00% ##########\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 13 Average: 42.8462 StdDev: 62.6097\n",
            "Min: 2 Max: 184 Ignored: 0\n",
            "----------------------------------------------\n",
            "[   2,  11) 9  69.23%  69.23% ##########\n",
            "[  11,  20) 0   0.00%  69.23%\n",
            "[  20,  29) 0   0.00%  69.23%\n",
            "[  29,  38) 0   0.00%  69.23%\n",
            "[  38,  47) 0   0.00%  69.23%\n",
            "[  47,  56) 0   0.00%  69.23%\n",
            "[  56,  66) 0   0.00%  69.23%\n",
            "[  66,  75) 0   0.00%  69.23%\n",
            "[  75,  84) 2  15.38%  84.62% ##\n",
            "[  84,  93) 0   0.00%  84.62%\n",
            "[  93, 102) 0   0.00%  84.62%\n",
            "[ 102, 111) 0   0.00%  84.62%\n",
            "[ 111, 120) 0   0.00%  84.62%\n",
            "[ 120, 130) 0   0.00%  84.62%\n",
            "[ 130, 139) 0   0.00%  84.62%\n",
            "[ 139, 148) 0   0.00%  84.62%\n",
            "[ 148, 157) 0   0.00%  84.62%\n",
            "[ 157, 166) 0   0.00%  84.62%\n",
            "[ 166, 175) 1   7.69%  92.31% #\n",
            "[ 175, 184] 1   7.69% 100.00% #\n",
            "\n",
            "Attribute in nodes:\n",
            "\t3 : CoapplicantIncome [NUMERICAL]\n",
            "\t2 : LoanAmount [NUMERICAL]\n",
            "\t2 : Credit_History [NUMERICAL]\n",
            "\t2 : ApplicantIncome [NUMERICAL]\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : Education [CATEGORICAL]\n",
            "\t1 : Dependents [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\t1 : CoapplicantIncome [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t2 : CoapplicantIncome [NUMERICAL]\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t3 : CoapplicantIncome [NUMERICAL]\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\t1 : ApplicantIncome [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t9 : HigherCondition\n",
            "\t3 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t1 : HigherCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t1 : ContainsBitmapCondition\n",
            "\t1 : HigherCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t2 : HigherCondition\n",
            "\t1 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t3 : HigherCondition\n",
            "\t1 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t5 : HigherCondition\n",
            "\t1 : ContainsBitmapCondition\n",
            "Node format: NOT_SET\n",
            "Pruned nodes during training: 172\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:0.842105 logloss:0.470521\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(Cart2.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "5Elp-EVxHfct",
        "outputId": "e0af3aa9-2388-4609-a9d8-afed1dbba313"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<script src=\"https://d3js.org/d3.v6.min.js\"></script>\n",
              "<div id=\"tree_plot_39f1772a459c4107ac473570ddddd34f\"></div>\n",
              "<script>\n",
              "/*\n",
              " * Copyright 2021 Google LLC.\n",
              " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              " * you may not use this file except in compliance with the License.\n",
              " * You may obtain a copy of the License at\n",
              " *\n",
              " *     https://www.apache.org/licenses/LICENSE-2.0\n",
              " *\n",
              " * Unless required by applicable law or agreed to in writing, software\n",
              " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              " * See the License for the specific language governing permissions and\n",
              " * limitations under the License.\n",
              " */\n",
              "\n",
              "/**\n",
              " *  Plotting of decision trees generated by TF-DF.\n",
              " *\n",
              " *  A tree is a recursive structure of node objects.\n",
              " *  A node contains one or more of the following components:\n",
              " *\n",
              " *    - A value: Representing the output of the node. If the node is not a leaf,\n",
              " *      the value is only present for analysis i.e. it is not used for\n",
              " *      predictions.\n",
              " *\n",
              " *    - A condition : For non-leaf nodes, the condition (also known as split)\n",
              " *      defines a binary test to branch to the positive or negative child.\n",
              " *\n",
              " *    - An explanation: Generally a plot showing the relation between the label\n",
              " *      and the condition to give insights about the effect of the condition.\n",
              " *\n",
              " *    - Two children : For non-leaf nodes, the children nodes. The first\n",
              " *      children (i.e. \"node.children[0]\") is the negative children (drawn in\n",
              " *      red). The second children is the positive one (drawn in green).\n",
              " *\n",
              " */\n",
              "\n",
              "/**\n",
              " * Plots a single decision tree into a DOM element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!tree} raw_tree Recursive tree structure.\n",
              " * @param {string} canvas_id Id of the output dom element.\n",
              " */\n",
              "function display_tree(options, raw_tree, canvas_id) {\n",
              "  console.log(options);\n",
              "\n",
              "  // Determine the node placement.\n",
              "  const tree_struct = d3.tree().nodeSize(\n",
              "      [options.node_y_offset, options.node_x_offset])(d3.hierarchy(raw_tree));\n",
              "\n",
              "  // Boundaries of the node placement.\n",
              "  let x_min = Infinity;\n",
              "  let x_max = -x_min;\n",
              "  let y_min = Infinity;\n",
              "  let y_max = -x_min;\n",
              "\n",
              "  tree_struct.each(d => {\n",
              "    if (d.x > x_max) x_max = d.x;\n",
              "    if (d.x < x_min) x_min = d.x;\n",
              "    if (d.y > y_max) y_max = d.y;\n",
              "    if (d.y < y_min) y_min = d.y;\n",
              "  });\n",
              "\n",
              "  // Size of the plot.\n",
              "  const width = y_max - y_min + options.node_x_size + options.margin * 2;\n",
              "  const height = x_max - x_min + options.node_y_size + options.margin * 2 +\n",
              "      options.node_y_offset - options.node_y_size;\n",
              "\n",
              "  const plot = d3.select(canvas_id);\n",
              "\n",
              "  // Tool tip\n",
              "  options.tooltip = plot.append('div')\n",
              "                        .attr('width', 100)\n",
              "                        .attr('height', 100)\n",
              "                        .style('padding', '4px')\n",
              "                        .style('background', '#fff')\n",
              "                        .style('box-shadow', '4px 4px 0px rgba(0,0,0,0.1)')\n",
              "                        .style('border', '1px solid black')\n",
              "                        .style('font-family', 'sans-serif')\n",
              "                        .style('font-size', options.font_size)\n",
              "                        .style('position', 'absolute')\n",
              "                        .style('z-index', '10')\n",
              "                        .attr('pointer-events', 'none')\n",
              "                        .style('display', 'none');\n",
              "\n",
              "  // Create canvas\n",
              "  const svg = plot.append('svg').attr('width', width).attr('height', height);\n",
              "  const graph =\n",
              "      svg.style('overflow', 'visible')\n",
              "          .append('g')\n",
              "          .attr('font-family', 'sans-serif')\n",
              "          .attr('font-size', options.font_size)\n",
              "          .attr(\n",
              "              'transform',\n",
              "              () => `translate(${options.margin},${\n",
              "                  - x_min + options.node_y_offset / 2 + options.margin})`);\n",
              "\n",
              "  // Plot bounding box.\n",
              "  if (options.show_plot_bounding_box) {\n",
              "    svg.append('rect')\n",
              "        .attr('width', width)\n",
              "        .attr('height', height)\n",
              "        .attr('fill', 'none')\n",
              "        .attr('stroke-width', 1.0)\n",
              "        .attr('stroke', 'black');\n",
              "  }\n",
              "\n",
              "  // Draw the edges.\n",
              "  display_edges(options, graph, tree_struct);\n",
              "\n",
              "  // Draw the nodes.\n",
              "  display_nodes(options, graph, tree_struct);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Draw the nodes of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_nodes(options, graph, tree_struct) {\n",
              "  const nodes = graph.append('g')\n",
              "                    .selectAll('g')\n",
              "                    .data(tree_struct.descendants())\n",
              "                    .join('g')\n",
              "                    .attr('transform', d => `translate(${d.y},${d.x})`);\n",
              "\n",
              "  nodes.append('rect')\n",
              "      .attr('x', 0.5)\n",
              "      .attr('y', 0.5)\n",
              "      .attr('width', options.node_x_size)\n",
              "      .attr('height', options.node_y_size)\n",
              "      .attr('stroke', 'lightgrey')\n",
              "      .attr('stroke-width', 1)\n",
              "      .attr('fill', 'white')\n",
              "      .attr('y', -options.node_y_size / 2);\n",
              "\n",
              "  // Brackets on the right of condition nodes without children.\n",
              "  non_leaf_node_without_children =\n",
              "      nodes.filter(node => node.data.condition != null && node.children == null)\n",
              "          .append('g')\n",
              "          .attr('transform', `translate(${options.node_x_size},0)`);\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,10 10,10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#F00');\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,-10 10,-10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#0F0');\n",
              "\n",
              "  const node_content = nodes.append('g').attr(\n",
              "      'transform',\n",
              "      `translate(0,${options.node_padding - options.node_y_size / 2})`);\n",
              "\n",
              "  node_content.append(node => create_node_element(options, node));\n",
              "}\n",
              "\n",
              "/**\n",
              " * Creates the D3 content for a single node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!node} node Node to draw.\n",
              " * @return {!d3} D3 content.\n",
              " */\n",
              "function create_node_element(options, node) {\n",
              "  // Output accumulator.\n",
              "  let output = {\n",
              "    // Content to draw.\n",
              "    content: d3.create('svg:g'),\n",
              "    // Vertical offset to the next element to draw.\n",
              "    vertical_offset: 0\n",
              "  };\n",
              "\n",
              "  // Conditions.\n",
              "  if (node.data.condition != null) {\n",
              "    display_condition(options, node.data.condition, output);\n",
              "  }\n",
              "\n",
              "  // Values.\n",
              "  if (node.data.value != null) {\n",
              "    display_value(options, node.data.value, output);\n",
              "  }\n",
              "\n",
              "  // Explanations.\n",
              "  if (node.data.explanation != null) {\n",
              "    display_explanation(options, node.data.explanation, output);\n",
              "  }\n",
              "\n",
              "  return output.content.node();\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text(options, text, output) {\n",
              "  output.content.append('text')\n",
              "      .attr('x', options.node_padding)\n",
              "      .attr('y', output.vertical_offset)\n",
              "      .attr('alignment-baseline', 'hanging')\n",
              "      .text(text);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node with a tooltip.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {string} tooltip Text in the Tooltip.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text_with_tooltip(options, text, tooltip, output) {\n",
              "  const item = output.content.append('text')\n",
              "                   .attr('x', options.node_padding)\n",
              "                   .attr('alignment-baseline', 'hanging')\n",
              "                   .text(text);\n",
              "\n",
              "  add_tooltip(options, item, () => tooltip);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a tooltip to a dom element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!dom} target Dom element to equip with a tooltip.\n",
              " * @param {!func} get_content Generates the html content of the tooltip.\n",
              " */\n",
              "function add_tooltip(options, target, get_content) {\n",
              "  function show(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.html(get_content());\n",
              "  }\n",
              "\n",
              "  function hide(d) {\n",
              "    options.tooltip.style('display', 'none');\n",
              "  }\n",
              "\n",
              "  function move(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.style('left', (d.pageX + 5) + 'px');\n",
              "    options.tooltip.style('top', d.pageY + 'px');\n",
              "  }\n",
              "\n",
              "  target.on('mouseover', show);\n",
              "  target.on('mouseout', hide);\n",
              "  target.on('mousemove', move);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a condition inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!condition} condition Condition to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_condition(options, condition, output) {\n",
              "  threshold_format = d3.format('r');\n",
              "\n",
              "  if (condition.type === 'IS_MISSING') {\n",
              "    display_node_text(options, `${condition.attribute} is missing`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'IS_TRUE') {\n",
              "    display_node_text(options, `${condition.attribute} is true`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_IS_HIGHER_THAN') {\n",
              "    format = d3.format('r');\n",
              "    display_node_text(\n",
              "        options,\n",
              "        `${condition.attribute} >= ${threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_IS_IN') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} in [...]`,\n",
              "        `${condition.attribute} in [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_SET_CONTAINS') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} intersect [...]`,\n",
              "        `${condition.attribute} intersect [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_SPARSE_OBLIQUE') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `Sparse oblique split...`,\n",
              "        `[${condition.attributes}]*[${condition.weights}]>=${\n",
              "            threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported condition ${condition.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a value inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!value} value Value to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_value(options, value, output) {\n",
              "  if (value.type === 'PROBABILITY') {\n",
              "    const left_margin = 0;\n",
              "    const right_margin = 50;\n",
              "    const plot_width = options.node_x_size - options.node_padding * 2 -\n",
              "        left_margin - right_margin;\n",
              "\n",
              "    let cusum = Array.from(d3.cumsum(value.distribution));\n",
              "    cusum.unshift(0);\n",
              "    const distribution_plot = output.content.append('g').attr(\n",
              "        'transform', `translate(0,${output.vertical_offset + 0.5})`);\n",
              "\n",
              "    distribution_plot.selectAll('rect')\n",
              "        .data(value.distribution)\n",
              "        .join('rect')\n",
              "        .attr('height', 10)\n",
              "        .attr(\n",
              "            'x',\n",
              "            (d, i) =>\n",
              "                (cusum[i] * plot_width + left_margin + options.node_padding))\n",
              "        .attr('width', (d, i) => d * plot_width)\n",
              "        .style('fill', (d, i) => d3.schemeSet1[i]);\n",
              "\n",
              "    const num_examples =\n",
              "        output.content.append('g')\n",
              "            .attr('transform', `translate(0,${output.vertical_offset})`)\n",
              "            .append('text')\n",
              "            .attr('x', options.node_x_size - options.node_padding)\n",
              "            .attr('alignment-baseline', 'hanging')\n",
              "            .attr('text-anchor', 'end')\n",
              "            .text(`(${value.num_examples})`);\n",
              "\n",
              "    const distribution_details = d3.create('ul');\n",
              "    distribution_details.selectAll('li')\n",
              "        .data(value.distribution)\n",
              "        .join('li')\n",
              "        .append('span')\n",
              "        .text(\n",
              "            (d, i) =>\n",
              "                'class ' + i + ': ' + d3.format('.3%')(value.distribution[i]));\n",
              "\n",
              "    add_tooltip(options, distribution_plot, () => distribution_details.html());\n",
              "    add_tooltip(options, num_examples, () => 'Number of examples');\n",
              "\n",
              "    output.vertical_offset += 10;\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'REGRESSION') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'value: ' + d3.format('r')(value.value) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'UPLIFT') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'effect: ' + d3.format('r')(value.treatment_effect) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(options, `Non supported value ${value.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds an explanation inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!explanation} explanation Explanation to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_explanation(options, explanation, output) {\n",
              "  // Margin before the explanation.\n",
              "  output.vertical_offset += 10;\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported explanation ${explanation.type}`, output);\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Draw the edges of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_edges(options, graph, tree_struct) {\n",
              "  // Draw an edge between a parent and a child node with a bezier.\n",
              "  function draw_single_edge(d) {\n",
              "    return 'M' + (d.source.y + options.node_x_size) + ',' + d.source.x + ' C' +\n",
              "        (d.source.y + options.node_x_size + options.edge_rounding) + ',' +\n",
              "        d.source.x + ' ' + (d.target.y - options.edge_rounding) + ',' +\n",
              "        d.target.x + ' ' + d.target.y + ',' + d.target.x;\n",
              "  }\n",
              "\n",
              "  graph.append('g')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.2)\n",
              "      .selectAll('path')\n",
              "      .data(tree_struct.links())\n",
              "      .join('path')\n",
              "      .attr('d', draw_single_edge)\n",
              "      .attr(\n",
              "          'stroke', d => (d.target === d.source.children[0]) ? '#0F0' : '#F00');\n",
              "}\n",
              "\n",
              "display_tree({\"margin\": 10, \"node_x_size\": 160, \"node_y_size\": 28, \"node_x_offset\": 180, \"node_y_offset\": 33, \"font_size\": 10, \"edge_rounding\": 20, \"node_padding\": 2, \"show_plot_bounding_box\": false}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3123877917414722, 0.6876122082585279], \"num_examples\": 557.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Credit_History\", \"threshold\": 0.42109930515289307}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.21008403361344538, 0.7899159663865546], \"num_examples\": 476.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"Property_Area\", \"mask\": [\"Semiurban\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.1358695652173913, 0.8641304347826086], \"num_examples\": 184.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.2568493150684932, 0.7431506849315068], \"num_examples\": 292.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"CoapplicantIncome\", \"threshold\": 14166.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 3.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.2491349480968858, 0.7508650519031141], \"num_examples\": 289.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"CoapplicantIncome\", \"threshold\": 5401.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 10.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.25806451612903225, 0.7419354838709677], \"num_examples\": 279.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ApplicantIncome\", \"threshold\": 3399.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3072289156626506, 0.6927710843373494], \"num_examples\": 166.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.18584070796460178, 0.8141592920353983], \"num_examples\": 113.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"CoapplicantIncome\", \"threshold\": 618.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.1111111111111111, 0.8888888888888888], \"num_examples\": 81.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.375, 0.625], \"num_examples\": 32.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ApplicantIncome\", \"threshold\": 2389.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.24, 0.76], \"num_examples\": 25.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"LoanAmount\", \"threshold\": 62.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3157894736842105, 0.6842105263157895], \"num_examples\": 19.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"Dependents\", \"mask\": [\"2\", \"3+\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 4.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.4, 0.6], \"num_examples\": 15.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"Education\", \"mask\": [\"Graduate\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3076923076923077, 0.6923076923076923], \"num_examples\": 13.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"LoanAmount\", \"threshold\": 70.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.4, 0.6], \"num_examples\": 10.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Credit_History\", \"threshold\": 0.9210993051528931}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.5, 0.5], \"num_examples\": 8.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 2.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 3.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 2.0}}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 6.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8571428571428571, 0.14285714285714285], \"num_examples\": 7.0}}]}]}]}]}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9135802469135802, 0.08641975308641975], \"num_examples\": 81.0}}]}, \"#tree_plot_39f1772a459c4107ac473570ddddd34f\")\n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(Cart2, tree_idx=0, max_depth=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeRXpJtiIIKc"
      },
      "source": [
        "This tree had the exact same accuracy at .84, but the logloss was less than half the default tree. While this does get leaf nodes with more purity, I'm not sure that many of the splits are worth it, as there's often splits that result in less than 10% of the dataset being split off, and the complexity this could give doesn't seem worth it. The tree's also somewhere around 50% deeper, so this doesn't seem like it would scale well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyMCkRb_JFm1"
      },
      "source": [
        "For my third model, I'll set the max_depth to 5. I'm guessing it will just end up with a truncated version of the first model, but it is possible that the lower depth will force the model to split differently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhnbiwehKUyc",
        "outputId": "8e3d09a6-09df-4753-ca5f-e4db24f39b34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use /tmp/tmpjo2e5s04 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.837110. Found 614 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.059245\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7e4292e6e910>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Cart3 = tfdf.keras.CartModel(max_depth = 5)\n",
        "Cart3.fit(Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ayh5CFM-Kci-",
        "outputId": "ac05f065-5bcf-4e6b-d0ac-617def375593"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"cart_model_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1 (1.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 1 (1.00 Byte)\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (12):\n",
            "\tApplicantIncome\n",
            "\tCoapplicantIncome\n",
            "\tCredit_History\n",
            "\tDependents\n",
            "\tEducation\n",
            "\tGender\n",
            "\tLoanAmount\n",
            "\tLoan_Amount_Term\n",
            "\tLoan_ID\n",
            "\tMarried\n",
            "\tProperty_Area\n",
            "\tSelf_Employed\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1. \"Credit_History\"  1.000000 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1. \"Credit_History\"  1.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1. \"Credit_History\"  1.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1. \"Credit_History\" 77.371266 \n",
            "\n",
            "\n",
            "\n",
            "Winner takes all: false\n",
            "Out-of-bag evaluation: accuracy:0.824561 logloss:0.44777\n",
            "Number of trees: 1\n",
            "Total number of nodes: 3\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 1 Average: 3 StdDev: 0\n",
            "Min: 3 Max: 3 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 3, 3] 1 100.00% 100.00% ##########\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 2 Average: 1 StdDev: 0\n",
            "Min: 1 Max: 1 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 1, 1] 2 100.00% 100.00% ##########\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 2 Average: 278.5 StdDev: 197.5\n",
            "Min: 81 Max: 476 Ignored: 0\n",
            "----------------------------------------------\n",
            "[  81, 100) 1  50.00%  50.00% ##########\n",
            "[ 100, 120) 0   0.00%  50.00%\n",
            "[ 120, 140) 0   0.00%  50.00%\n",
            "[ 140, 160) 0   0.00%  50.00%\n",
            "[ 160, 180) 0   0.00%  50.00%\n",
            "[ 180, 199) 0   0.00%  50.00%\n",
            "[ 199, 219) 0   0.00%  50.00%\n",
            "[ 219, 239) 0   0.00%  50.00%\n",
            "[ 239, 259) 0   0.00%  50.00%\n",
            "[ 259, 279) 0   0.00%  50.00%\n",
            "[ 279, 298) 0   0.00%  50.00%\n",
            "[ 298, 318) 0   0.00%  50.00%\n",
            "[ 318, 338) 0   0.00%  50.00%\n",
            "[ 338, 358) 0   0.00%  50.00%\n",
            "[ 358, 378) 0   0.00%  50.00%\n",
            "[ 378, 397) 0   0.00%  50.00%\n",
            "[ 397, 417) 0   0.00%  50.00%\n",
            "[ 417, 437) 0   0.00%  50.00%\n",
            "[ 437, 457) 0   0.00%  50.00%\n",
            "[ 457, 476] 1  50.00% 100.00% ##########\n",
            "\n",
            "Attribute in nodes:\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t1 : HigherCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t1 : HigherCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t1 : HigherCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t1 : HigherCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t1 : HigherCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t1 : HigherCondition\n",
            "Node format: NOT_SET\n",
            "Pruned nodes during training: 24\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:0.824561 logloss:0.44777\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(Cart3.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "O2Tns0iUKlnO",
        "outputId": "7a5ae611-75aa-4967-c8c3-8421c6524f66"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<script src=\"https://d3js.org/d3.v6.min.js\"></script>\n",
              "<div id=\"tree_plot_ea714e0eb8094f518569d1904ef3e057\"></div>\n",
              "<script>\n",
              "/*\n",
              " * Copyright 2021 Google LLC.\n",
              " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              " * you may not use this file except in compliance with the License.\n",
              " * You may obtain a copy of the License at\n",
              " *\n",
              " *     https://www.apache.org/licenses/LICENSE-2.0\n",
              " *\n",
              " * Unless required by applicable law or agreed to in writing, software\n",
              " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              " * See the License for the specific language governing permissions and\n",
              " * limitations under the License.\n",
              " */\n",
              "\n",
              "/**\n",
              " *  Plotting of decision trees generated by TF-DF.\n",
              " *\n",
              " *  A tree is a recursive structure of node objects.\n",
              " *  A node contains one or more of the following components:\n",
              " *\n",
              " *    - A value: Representing the output of the node. If the node is not a leaf,\n",
              " *      the value is only present for analysis i.e. it is not used for\n",
              " *      predictions.\n",
              " *\n",
              " *    - A condition : For non-leaf nodes, the condition (also known as split)\n",
              " *      defines a binary test to branch to the positive or negative child.\n",
              " *\n",
              " *    - An explanation: Generally a plot showing the relation between the label\n",
              " *      and the condition to give insights about the effect of the condition.\n",
              " *\n",
              " *    - Two children : For non-leaf nodes, the children nodes. The first\n",
              " *      children (i.e. \"node.children[0]\") is the negative children (drawn in\n",
              " *      red). The second children is the positive one (drawn in green).\n",
              " *\n",
              " */\n",
              "\n",
              "/**\n",
              " * Plots a single decision tree into a DOM element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!tree} raw_tree Recursive tree structure.\n",
              " * @param {string} canvas_id Id of the output dom element.\n",
              " */\n",
              "function display_tree(options, raw_tree, canvas_id) {\n",
              "  console.log(options);\n",
              "\n",
              "  // Determine the node placement.\n",
              "  const tree_struct = d3.tree().nodeSize(\n",
              "      [options.node_y_offset, options.node_x_offset])(d3.hierarchy(raw_tree));\n",
              "\n",
              "  // Boundaries of the node placement.\n",
              "  let x_min = Infinity;\n",
              "  let x_max = -x_min;\n",
              "  let y_min = Infinity;\n",
              "  let y_max = -x_min;\n",
              "\n",
              "  tree_struct.each(d => {\n",
              "    if (d.x > x_max) x_max = d.x;\n",
              "    if (d.x < x_min) x_min = d.x;\n",
              "    if (d.y > y_max) y_max = d.y;\n",
              "    if (d.y < y_min) y_min = d.y;\n",
              "  });\n",
              "\n",
              "  // Size of the plot.\n",
              "  const width = y_max - y_min + options.node_x_size + options.margin * 2;\n",
              "  const height = x_max - x_min + options.node_y_size + options.margin * 2 +\n",
              "      options.node_y_offset - options.node_y_size;\n",
              "\n",
              "  const plot = d3.select(canvas_id);\n",
              "\n",
              "  // Tool tip\n",
              "  options.tooltip = plot.append('div')\n",
              "                        .attr('width', 100)\n",
              "                        .attr('height', 100)\n",
              "                        .style('padding', '4px')\n",
              "                        .style('background', '#fff')\n",
              "                        .style('box-shadow', '4px 4px 0px rgba(0,0,0,0.1)')\n",
              "                        .style('border', '1px solid black')\n",
              "                        .style('font-family', 'sans-serif')\n",
              "                        .style('font-size', options.font_size)\n",
              "                        .style('position', 'absolute')\n",
              "                        .style('z-index', '10')\n",
              "                        .attr('pointer-events', 'none')\n",
              "                        .style('display', 'none');\n",
              "\n",
              "  // Create canvas\n",
              "  const svg = plot.append('svg').attr('width', width).attr('height', height);\n",
              "  const graph =\n",
              "      svg.style('overflow', 'visible')\n",
              "          .append('g')\n",
              "          .attr('font-family', 'sans-serif')\n",
              "          .attr('font-size', options.font_size)\n",
              "          .attr(\n",
              "              'transform',\n",
              "              () => `translate(${options.margin},${\n",
              "                  - x_min + options.node_y_offset / 2 + options.margin})`);\n",
              "\n",
              "  // Plot bounding box.\n",
              "  if (options.show_plot_bounding_box) {\n",
              "    svg.append('rect')\n",
              "        .attr('width', width)\n",
              "        .attr('height', height)\n",
              "        .attr('fill', 'none')\n",
              "        .attr('stroke-width', 1.0)\n",
              "        .attr('stroke', 'black');\n",
              "  }\n",
              "\n",
              "  // Draw the edges.\n",
              "  display_edges(options, graph, tree_struct);\n",
              "\n",
              "  // Draw the nodes.\n",
              "  display_nodes(options, graph, tree_struct);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Draw the nodes of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_nodes(options, graph, tree_struct) {\n",
              "  const nodes = graph.append('g')\n",
              "                    .selectAll('g')\n",
              "                    .data(tree_struct.descendants())\n",
              "                    .join('g')\n",
              "                    .attr('transform', d => `translate(${d.y},${d.x})`);\n",
              "\n",
              "  nodes.append('rect')\n",
              "      .attr('x', 0.5)\n",
              "      .attr('y', 0.5)\n",
              "      .attr('width', options.node_x_size)\n",
              "      .attr('height', options.node_y_size)\n",
              "      .attr('stroke', 'lightgrey')\n",
              "      .attr('stroke-width', 1)\n",
              "      .attr('fill', 'white')\n",
              "      .attr('y', -options.node_y_size / 2);\n",
              "\n",
              "  // Brackets on the right of condition nodes without children.\n",
              "  non_leaf_node_without_children =\n",
              "      nodes.filter(node => node.data.condition != null && node.children == null)\n",
              "          .append('g')\n",
              "          .attr('transform', `translate(${options.node_x_size},0)`);\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,10 10,10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#F00');\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,-10 10,-10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#0F0');\n",
              "\n",
              "  const node_content = nodes.append('g').attr(\n",
              "      'transform',\n",
              "      `translate(0,${options.node_padding - options.node_y_size / 2})`);\n",
              "\n",
              "  node_content.append(node => create_node_element(options, node));\n",
              "}\n",
              "\n",
              "/**\n",
              " * Creates the D3 content for a single node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!node} node Node to draw.\n",
              " * @return {!d3} D3 content.\n",
              " */\n",
              "function create_node_element(options, node) {\n",
              "  // Output accumulator.\n",
              "  let output = {\n",
              "    // Content to draw.\n",
              "    content: d3.create('svg:g'),\n",
              "    // Vertical offset to the next element to draw.\n",
              "    vertical_offset: 0\n",
              "  };\n",
              "\n",
              "  // Conditions.\n",
              "  if (node.data.condition != null) {\n",
              "    display_condition(options, node.data.condition, output);\n",
              "  }\n",
              "\n",
              "  // Values.\n",
              "  if (node.data.value != null) {\n",
              "    display_value(options, node.data.value, output);\n",
              "  }\n",
              "\n",
              "  // Explanations.\n",
              "  if (node.data.explanation != null) {\n",
              "    display_explanation(options, node.data.explanation, output);\n",
              "  }\n",
              "\n",
              "  return output.content.node();\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text(options, text, output) {\n",
              "  output.content.append('text')\n",
              "      .attr('x', options.node_padding)\n",
              "      .attr('y', output.vertical_offset)\n",
              "      .attr('alignment-baseline', 'hanging')\n",
              "      .text(text);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node with a tooltip.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {string} tooltip Text in the Tooltip.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text_with_tooltip(options, text, tooltip, output) {\n",
              "  const item = output.content.append('text')\n",
              "                   .attr('x', options.node_padding)\n",
              "                   .attr('alignment-baseline', 'hanging')\n",
              "                   .text(text);\n",
              "\n",
              "  add_tooltip(options, item, () => tooltip);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a tooltip to a dom element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!dom} target Dom element to equip with a tooltip.\n",
              " * @param {!func} get_content Generates the html content of the tooltip.\n",
              " */\n",
              "function add_tooltip(options, target, get_content) {\n",
              "  function show(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.html(get_content());\n",
              "  }\n",
              "\n",
              "  function hide(d) {\n",
              "    options.tooltip.style('display', 'none');\n",
              "  }\n",
              "\n",
              "  function move(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.style('left', (d.pageX + 5) + 'px');\n",
              "    options.tooltip.style('top', d.pageY + 'px');\n",
              "  }\n",
              "\n",
              "  target.on('mouseover', show);\n",
              "  target.on('mouseout', hide);\n",
              "  target.on('mousemove', move);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a condition inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!condition} condition Condition to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_condition(options, condition, output) {\n",
              "  threshold_format = d3.format('r');\n",
              "\n",
              "  if (condition.type === 'IS_MISSING') {\n",
              "    display_node_text(options, `${condition.attribute} is missing`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'IS_TRUE') {\n",
              "    display_node_text(options, `${condition.attribute} is true`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_IS_HIGHER_THAN') {\n",
              "    format = d3.format('r');\n",
              "    display_node_text(\n",
              "        options,\n",
              "        `${condition.attribute} >= ${threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_IS_IN') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} in [...]`,\n",
              "        `${condition.attribute} in [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_SET_CONTAINS') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} intersect [...]`,\n",
              "        `${condition.attribute} intersect [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_SPARSE_OBLIQUE') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `Sparse oblique split...`,\n",
              "        `[${condition.attributes}]*[${condition.weights}]>=${\n",
              "            threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported condition ${condition.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a value inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!value} value Value to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_value(options, value, output) {\n",
              "  if (value.type === 'PROBABILITY') {\n",
              "    const left_margin = 0;\n",
              "    const right_margin = 50;\n",
              "    const plot_width = options.node_x_size - options.node_padding * 2 -\n",
              "        left_margin - right_margin;\n",
              "\n",
              "    let cusum = Array.from(d3.cumsum(value.distribution));\n",
              "    cusum.unshift(0);\n",
              "    const distribution_plot = output.content.append('g').attr(\n",
              "        'transform', `translate(0,${output.vertical_offset + 0.5})`);\n",
              "\n",
              "    distribution_plot.selectAll('rect')\n",
              "        .data(value.distribution)\n",
              "        .join('rect')\n",
              "        .attr('height', 10)\n",
              "        .attr(\n",
              "            'x',\n",
              "            (d, i) =>\n",
              "                (cusum[i] * plot_width + left_margin + options.node_padding))\n",
              "        .attr('width', (d, i) => d * plot_width)\n",
              "        .style('fill', (d, i) => d3.schemeSet1[i]);\n",
              "\n",
              "    const num_examples =\n",
              "        output.content.append('g')\n",
              "            .attr('transform', `translate(0,${output.vertical_offset})`)\n",
              "            .append('text')\n",
              "            .attr('x', options.node_x_size - options.node_padding)\n",
              "            .attr('alignment-baseline', 'hanging')\n",
              "            .attr('text-anchor', 'end')\n",
              "            .text(`(${value.num_examples})`);\n",
              "\n",
              "    const distribution_details = d3.create('ul');\n",
              "    distribution_details.selectAll('li')\n",
              "        .data(value.distribution)\n",
              "        .join('li')\n",
              "        .append('span')\n",
              "        .text(\n",
              "            (d, i) =>\n",
              "                'class ' + i + ': ' + d3.format('.3%')(value.distribution[i]));\n",
              "\n",
              "    add_tooltip(options, distribution_plot, () => distribution_details.html());\n",
              "    add_tooltip(options, num_examples, () => 'Number of examples');\n",
              "\n",
              "    output.vertical_offset += 10;\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'REGRESSION') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'value: ' + d3.format('r')(value.value) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'UPLIFT') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'effect: ' + d3.format('r')(value.treatment_effect) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(options, `Non supported value ${value.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds an explanation inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!explanation} explanation Explanation to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_explanation(options, explanation, output) {\n",
              "  // Margin before the explanation.\n",
              "  output.vertical_offset += 10;\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported explanation ${explanation.type}`, output);\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Draw the edges of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_edges(options, graph, tree_struct) {\n",
              "  // Draw an edge between a parent and a child node with a bezier.\n",
              "  function draw_single_edge(d) {\n",
              "    return 'M' + (d.source.y + options.node_x_size) + ',' + d.source.x + ' C' +\n",
              "        (d.source.y + options.node_x_size + options.edge_rounding) + ',' +\n",
              "        d.source.x + ' ' + (d.target.y - options.edge_rounding) + ',' +\n",
              "        d.target.x + ' ' + d.target.y + ',' + d.target.x;\n",
              "  }\n",
              "\n",
              "  graph.append('g')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.2)\n",
              "      .selectAll('path')\n",
              "      .data(tree_struct.links())\n",
              "      .join('path')\n",
              "      .attr('d', draw_single_edge)\n",
              "      .attr(\n",
              "          'stroke', d => (d.target === d.source.children[0]) ? '#0F0' : '#F00');\n",
              "}\n",
              "\n",
              "display_tree({\"margin\": 10, \"node_x_size\": 160, \"node_y_size\": 28, \"node_x_offset\": 180, \"node_y_offset\": 33, \"font_size\": 10, \"edge_rounding\": 20, \"node_padding\": 2, \"show_plot_bounding_box\": false}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3123877917414722, 0.6876122082585279], \"num_examples\": 557.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Credit_History\", \"threshold\": 0.42109930515289307}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.21008403361344538, 0.7899159663865546], \"num_examples\": 476.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9135802469135802, 0.08641975308641975], \"num_examples\": 81.0}}]}, \"#tree_plot_ea714e0eb8094f518569d1904ef3e057\")\n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(Cart3, tree_idx=0, max_depth=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpSW995kK5hi"
      },
      "source": [
        "Well, I was right that it would end up as a truncated version of the first model, but I didn't expect it to go back to a single split. Comparing the visualizations, I noticed that the splits between depth 2 and 5 would either result in both having a higher percentage of a single class, or would have a lower purity than that of the original split. As such, the model must have chosen to prune those nodes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6S6w4FUNYk7"
      },
      "source": [
        "Overall, the default settings for the model had the best balance of depth in my opinion. Lowering the minimum amount of nodes to split on did provide more pure splits, but those pure splits would barely have any examples in them, so I don't think those splits were worth the extra depth. Furthermore, it's hard to tell in that model if those splits were due to an actual good boundary, or if those entries were outliers.\n",
        "Decreasing the maximum depth resulted in a model that has less depth and is less complex, but the simplicity could result in important decision points being lost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxI7sEi_P0mS"
      },
      "source": [
        "**Do some research on what sensitivity analysis is and how it is performed (include\n",
        "citations). Perform a sensitivity analysis to measure the impact of at least two input\n",
        "features on your model's decision boundary.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G9YKL2KP5x1"
      },
      "source": [
        "In order to learn about sensitivity analysis, I looked at this website: https://medium.com/@einat_93627/understand-your-black-box-model-using-sensitivity-analysis-practical-guide-ef6ac4175e55.\n",
        "\n",
        "The way it's described is to change a feature in a database, and see how it changes the model. If it's a big change, the feature is important for the prediction. If it isn't, then the feature isn't very important.\n",
        "\n",
        "The way I'll implement it for this is through permutation, in which I randomly shuffle the values for a feature.\n",
        "\n",
        "There are also methods I didn't choose such as taking the uniform distribution, changing how missing values work, or to consider multiple variables at once.\n",
        "\n",
        "As for the features that sensitivity analysis will be performed on, I'll choose credit history and applicant income, as those are the first 2 continuous values to cause splits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsCD1YIXG5vS"
      },
      "source": [
        "Sensitivity analysis for credit history:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efTF0rTiHXJE",
        "outputId": "3ae558bc-e22a-4bfb-d8b0-e48a414b4637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Loan_ID  Gender Married Dependents     Education Self_Employed  \\\n",
            "0    LP001002    Male      No          0      Graduate            No   \n",
            "1    LP001003    Male     Yes          1      Graduate            No   \n",
            "2    LP001005    Male     Yes          0      Graduate           Yes   \n",
            "3    LP001006    Male     Yes          0  Not Graduate            No   \n",
            "4    LP001008    Male      No          0      Graduate            No   \n",
            "..        ...     ...     ...        ...           ...           ...   \n",
            "609  LP002978  Female      No          0      Graduate            No   \n",
            "610  LP002979    Male     Yes         3+      Graduate            No   \n",
            "611  LP002983    Male     Yes          1      Graduate            No   \n",
            "612  LP002984    Male     Yes          2      Graduate            No   \n",
            "613  LP002990  Female      No          0      Graduate           Yes   \n",
            "\n",
            "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
            "0               5849                0.0         NaN             360.0   \n",
            "1               4583             1508.0       128.0             360.0   \n",
            "2               3000                0.0        66.0             360.0   \n",
            "3               2583             2358.0       120.0             360.0   \n",
            "4               6000                0.0       141.0             360.0   \n",
            "..               ...                ...         ...               ...   \n",
            "609             2900                0.0        71.0             360.0   \n",
            "610             4106                0.0        40.0             180.0   \n",
            "611             8072              240.0       253.0             360.0   \n",
            "612             7583                0.0       187.0             360.0   \n",
            "613             4583                0.0       133.0             360.0   \n",
            "\n",
            "     Credit_History Property_Area  Loan_Status  \n",
            "0               1.0         Urban            1  \n",
            "1               1.0         Rural            0  \n",
            "2               1.0         Urban            1  \n",
            "3               1.0         Urban            1  \n",
            "4               1.0         Urban            1  \n",
            "..              ...           ...          ...  \n",
            "609             1.0         Rural            1  \n",
            "610             1.0         Rural            1  \n",
            "611             1.0         Urban            1  \n",
            "612             1.0         Urban            1  \n",
            "613             0.0     Semiurban            0  \n",
            "\n",
            "[614 rows x 13 columns]\n"
          ]
        }
      ],
      "source": [
        "SensitiveDatabase = Database.copy()\n",
        "print(SensitiveDatabase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJMv9JloHnt0"
      },
      "outputs": [],
      "source": [
        "SensitiveDatabase['Credit_History'] = SensitiveDatabase['Credit_History'].sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sFOPG7JJFjk",
        "outputId": "c45fb62b-e8f3-4c9e-e2a0-e49ba6d8f872"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0      1.0\n",
            "1      1.0\n",
            "2      1.0\n",
            "3      1.0\n",
            "4      1.0\n",
            "      ... \n",
            "609    1.0\n",
            "610    1.0\n",
            "611    1.0\n",
            "612    1.0\n",
            "613    0.0\n",
            "Name: Credit_History, Length: 614, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(Database['Credit_History'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U848s___JPqH",
        "outputId": "c23746cd-5b0b-4d31-b391-d28c8a06088d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0      1.0\n",
            "1      1.0\n",
            "2      1.0\n",
            "3      1.0\n",
            "4      1.0\n",
            "      ... \n",
            "609    0.0\n",
            "610    1.0\n",
            "611    1.0\n",
            "612    1.0\n",
            "613    1.0\n",
            "Name: Credit_History, Length: 614, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(SensitiveDatabase['Credit_History'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JsY9dOqJwAM"
      },
      "outputs": [],
      "source": [
        "SensitiveDataset1 = tfdf.keras.pd_dataframe_to_tf_dataset(SensitiveDatabase, label = label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOxytdTwJ6Ua",
        "outputId": "094b961d-79dd-43df-aafe-b37606c2d285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use /tmp/tmph4umjflk as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.279943. Found 614 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.039118\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x78a34ea09bd0>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SensitiveCart1 = tfdf.keras.CartModel()\n",
        "SensitiveCart1.fit(SensitiveDataset1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRXKwdWgKF-G",
        "outputId": "1b8ef76b-d06d-45ba-9e63-f34b69fc6ae8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"cart_model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1 (1.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 1 (1.00 Byte)\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (12):\n",
            "\tApplicantIncome\n",
            "\tCoapplicantIncome\n",
            "\tCredit_History\n",
            "\tDependents\n",
            "\tEducation\n",
            "\tGender\n",
            "\tLoanAmount\n",
            "\tLoan_Amount_Term\n",
            "\tLoan_ID\n",
            "\tMarried\n",
            "\tProperty_Area\n",
            "\tSelf_Employed\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1.     \"Property_Area\"  1.000000 ################\n",
            "    2.  \"Loan_Amount_Term\"  0.500000 ######\n",
            "    3.         \"Education\"  0.343750 ###\n",
            "    4.   \"ApplicantIncome\"  0.268293 #\n",
            "    5.        \"LoanAmount\"  0.186441 \n",
            "    6.        \"Dependents\"  0.174603 \n",
            "    7. \"CoapplicantIncome\"  0.166667 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1. \"Property_Area\"  1.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1.   \"ApplicantIncome\"  3.000000 ################\n",
            "    2.        \"LoanAmount\"  2.000000 ########\n",
            "    3. \"CoapplicantIncome\"  1.000000 \n",
            "    4.        \"Dependents\"  1.000000 \n",
            "    5.         \"Education\"  1.000000 \n",
            "    6.  \"Loan_Amount_Term\"  1.000000 \n",
            "    7.     \"Property_Area\"  1.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1.   \"ApplicantIncome\" 11.586134 ################\n",
            "    2.     \"Property_Area\"  4.955277 #####\n",
            "    3.        \"LoanAmount\"  4.783250 ####\n",
            "    4.  \"Loan_Amount_Term\"  2.897300 #\n",
            "    5. \"CoapplicantIncome\"  2.517027 #\n",
            "    6.        \"Dependents\"  1.908501 \n",
            "    7.         \"Education\"  1.829927 \n",
            "\n",
            "\n",
            "\n",
            "Winner takes all: false\n",
            "Out-of-bag evaluation: accuracy:0.736842 logloss:0.584747\n",
            "Number of trees: 1\n",
            "Total number of nodes: 21\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 1 Average: 21 StdDev: 0\n",
            "Min: 21 Max: 21 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 21, 21] 1 100.00% 100.00% ##########\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 11 Average: 5.18182 StdDev: 2.20817\n",
            "Min: 1 Max: 8 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 1, 2) 1   9.09%   9.09% ###\n",
            "[ 2, 3) 1   9.09%  18.18% ###\n",
            "[ 3, 4) 1   9.09%  27.27% ###\n",
            "[ 4, 5) 0   0.00%  27.27%\n",
            "[ 5, 6) 2  18.18%  45.45% #######\n",
            "[ 6, 7) 3  27.27%  72.73% ##########\n",
            "[ 7, 8) 1   9.09%  81.82% ###\n",
            "[ 8, 8] 2  18.18% 100.00% #######\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 11 Average: 50.6364 StdDev: 59.1904\n",
            "Min: 5 Max: 213 Ignored: 0\n",
            "----------------------------------------------\n",
            "[   5,  15) 4  36.36%  36.36% ##########\n",
            "[  15,  25) 1   9.09%  45.45% ###\n",
            "[  25,  36) 2  18.18%  63.64% #####\n",
            "[  36,  46) 0   0.00%  63.64%\n",
            "[  46,  57) 0   0.00%  63.64%\n",
            "[  57,  67) 1   9.09%  72.73% ###\n",
            "[  67,  78) 0   0.00%  72.73%\n",
            "[  78,  88) 1   9.09%  81.82% ###\n",
            "[  88,  99) 1   9.09%  90.91% ###\n",
            "[  99, 109) 0   0.00%  90.91%\n",
            "[ 109, 119) 0   0.00%  90.91%\n",
            "[ 119, 130) 0   0.00%  90.91%\n",
            "[ 130, 140) 0   0.00%  90.91%\n",
            "[ 140, 151) 0   0.00%  90.91%\n",
            "[ 151, 161) 0   0.00%  90.91%\n",
            "[ 161, 172) 0   0.00%  90.91%\n",
            "[ 172, 182) 0   0.00%  90.91%\n",
            "[ 182, 193) 0   0.00%  90.91%\n",
            "[ 193, 203) 0   0.00%  90.91%\n",
            "[ 203, 213] 1   9.09% 100.00% ###\n",
            "\n",
            "Attribute in nodes:\n",
            "\t3 : ApplicantIncome [NUMERICAL]\n",
            "\t2 : LoanAmount [NUMERICAL]\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : Loan_Amount_Term [NUMERICAL]\n",
            "\t1 : Education [CATEGORICAL]\n",
            "\t1 : Dependents [CATEGORICAL]\n",
            "\t1 : CoapplicantIncome [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : Loan_Amount_Term [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : Loan_Amount_Term [NUMERICAL]\n",
            "\t1 : Education [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : Loan_Amount_Term [NUMERICAL]\n",
            "\t1 : Education [CATEGORICAL]\n",
            "\t1 : ApplicantIncome [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t3 : ApplicantIncome [NUMERICAL]\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : Loan_Amount_Term [NUMERICAL]\n",
            "\t1 : LoanAmount [NUMERICAL]\n",
            "\t1 : Education [CATEGORICAL]\n",
            "\t1 : CoapplicantIncome [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t7 : HigherCondition\n",
            "\t3 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t1 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t1 : ContainsBitmapCondition\n",
            "\t1 : HigherCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t2 : ContainsBitmapCondition\n",
            "\t1 : HigherCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t2 : ContainsBitmapCondition\n",
            "\t2 : HigherCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t6 : HigherCondition\n",
            "\t2 : ContainsBitmapCondition\n",
            "Node format: NOT_SET\n",
            "Pruned nodes during training: 130\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:0.736842 logloss:0.584747\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(SensitiveCart1.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "MaFULhfnKMbl",
        "outputId": "e5f3f4ba-94b7-4dcf-cc6b-1c3d32ef12de"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<script src=\"https://d3js.org/d3.v6.min.js\"></script>\n",
              "<div id=\"tree_plot_9f4b6bc55ad34a29b710899cdfcdfe1e\"></div>\n",
              "<script>\n",
              "/*\n",
              " * Copyright 2021 Google LLC.\n",
              " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              " * you may not use this file except in compliance with the License.\n",
              " * You may obtain a copy of the License at\n",
              " *\n",
              " *     https://www.apache.org/licenses/LICENSE-2.0\n",
              " *\n",
              " * Unless required by applicable law or agreed to in writing, software\n",
              " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              " * See the License for the specific language governing permissions and\n",
              " * limitations under the License.\n",
              " */\n",
              "\n",
              "/**\n",
              " *  Plotting of decision trees generated by TF-DF.\n",
              " *\n",
              " *  A tree is a recursive structure of node objects.\n",
              " *  A node contains one or more of the following components:\n",
              " *\n",
              " *    - A value: Representing the output of the node. If the node is not a leaf,\n",
              " *      the value is only present for analysis i.e. it is not used for\n",
              " *      predictions.\n",
              " *\n",
              " *    - A condition : For non-leaf nodes, the condition (also known as split)\n",
              " *      defines a binary test to branch to the positive or negative child.\n",
              " *\n",
              " *    - An explanation: Generally a plot showing the relation between the label\n",
              " *      and the condition to give insights about the effect of the condition.\n",
              " *\n",
              " *    - Two children : For non-leaf nodes, the children nodes. The first\n",
              " *      children (i.e. \"node.children[0]\") is the negative children (drawn in\n",
              " *      red). The second children is the positive one (drawn in green).\n",
              " *\n",
              " */\n",
              "\n",
              "/**\n",
              " * Plots a single decision tree into a DOM element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!tree} raw_tree Recursive tree structure.\n",
              " * @param {string} canvas_id Id of the output dom element.\n",
              " */\n",
              "function display_tree(options, raw_tree, canvas_id) {\n",
              "  console.log(options);\n",
              "\n",
              "  // Determine the node placement.\n",
              "  const tree_struct = d3.tree().nodeSize(\n",
              "      [options.node_y_offset, options.node_x_offset])(d3.hierarchy(raw_tree));\n",
              "\n",
              "  // Boundaries of the node placement.\n",
              "  let x_min = Infinity;\n",
              "  let x_max = -x_min;\n",
              "  let y_min = Infinity;\n",
              "  let y_max = -x_min;\n",
              "\n",
              "  tree_struct.each(d => {\n",
              "    if (d.x > x_max) x_max = d.x;\n",
              "    if (d.x < x_min) x_min = d.x;\n",
              "    if (d.y > y_max) y_max = d.y;\n",
              "    if (d.y < y_min) y_min = d.y;\n",
              "  });\n",
              "\n",
              "  // Size of the plot.\n",
              "  const width = y_max - y_min + options.node_x_size + options.margin * 2;\n",
              "  const height = x_max - x_min + options.node_y_size + options.margin * 2 +\n",
              "      options.node_y_offset - options.node_y_size;\n",
              "\n",
              "  const plot = d3.select(canvas_id);\n",
              "\n",
              "  // Tool tip\n",
              "  options.tooltip = plot.append('div')\n",
              "                        .attr('width', 100)\n",
              "                        .attr('height', 100)\n",
              "                        .style('padding', '4px')\n",
              "                        .style('background', '#fff')\n",
              "                        .style('box-shadow', '4px 4px 0px rgba(0,0,0,0.1)')\n",
              "                        .style('border', '1px solid black')\n",
              "                        .style('font-family', 'sans-serif')\n",
              "                        .style('font-size', options.font_size)\n",
              "                        .style('position', 'absolute')\n",
              "                        .style('z-index', '10')\n",
              "                        .attr('pointer-events', 'none')\n",
              "                        .style('display', 'none');\n",
              "\n",
              "  // Create canvas\n",
              "  const svg = plot.append('svg').attr('width', width).attr('height', height);\n",
              "  const graph =\n",
              "      svg.style('overflow', 'visible')\n",
              "          .append('g')\n",
              "          .attr('font-family', 'sans-serif')\n",
              "          .attr('font-size', options.font_size)\n",
              "          .attr(\n",
              "              'transform',\n",
              "              () => `translate(${options.margin},${\n",
              "                  - x_min + options.node_y_offset / 2 + options.margin})`);\n",
              "\n",
              "  // Plot bounding box.\n",
              "  if (options.show_plot_bounding_box) {\n",
              "    svg.append('rect')\n",
              "        .attr('width', width)\n",
              "        .attr('height', height)\n",
              "        .attr('fill', 'none')\n",
              "        .attr('stroke-width', 1.0)\n",
              "        .attr('stroke', 'black');\n",
              "  }\n",
              "\n",
              "  // Draw the edges.\n",
              "  display_edges(options, graph, tree_struct);\n",
              "\n",
              "  // Draw the nodes.\n",
              "  display_nodes(options, graph, tree_struct);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Draw the nodes of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_nodes(options, graph, tree_struct) {\n",
              "  const nodes = graph.append('g')\n",
              "                    .selectAll('g')\n",
              "                    .data(tree_struct.descendants())\n",
              "                    .join('g')\n",
              "                    .attr('transform', d => `translate(${d.y},${d.x})`);\n",
              "\n",
              "  nodes.append('rect')\n",
              "      .attr('x', 0.5)\n",
              "      .attr('y', 0.5)\n",
              "      .attr('width', options.node_x_size)\n",
              "      .attr('height', options.node_y_size)\n",
              "      .attr('stroke', 'lightgrey')\n",
              "      .attr('stroke-width', 1)\n",
              "      .attr('fill', 'white')\n",
              "      .attr('y', -options.node_y_size / 2);\n",
              "\n",
              "  // Brackets on the right of condition nodes without children.\n",
              "  non_leaf_node_without_children =\n",
              "      nodes.filter(node => node.data.condition != null && node.children == null)\n",
              "          .append('g')\n",
              "          .attr('transform', `translate(${options.node_x_size},0)`);\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,10 10,10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#F00');\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,-10 10,-10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#0F0');\n",
              "\n",
              "  const node_content = nodes.append('g').attr(\n",
              "      'transform',\n",
              "      `translate(0,${options.node_padding - options.node_y_size / 2})`);\n",
              "\n",
              "  node_content.append(node => create_node_element(options, node));\n",
              "}\n",
              "\n",
              "/**\n",
              " * Creates the D3 content for a single node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!node} node Node to draw.\n",
              " * @return {!d3} D3 content.\n",
              " */\n",
              "function create_node_element(options, node) {\n",
              "  // Output accumulator.\n",
              "  let output = {\n",
              "    // Content to draw.\n",
              "    content: d3.create('svg:g'),\n",
              "    // Vertical offset to the next element to draw.\n",
              "    vertical_offset: 0\n",
              "  };\n",
              "\n",
              "  // Conditions.\n",
              "  if (node.data.condition != null) {\n",
              "    display_condition(options, node.data.condition, output);\n",
              "  }\n",
              "\n",
              "  // Values.\n",
              "  if (node.data.value != null) {\n",
              "    display_value(options, node.data.value, output);\n",
              "  }\n",
              "\n",
              "  // Explanations.\n",
              "  if (node.data.explanation != null) {\n",
              "    display_explanation(options, node.data.explanation, output);\n",
              "  }\n",
              "\n",
              "  return output.content.node();\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text(options, text, output) {\n",
              "  output.content.append('text')\n",
              "      .attr('x', options.node_padding)\n",
              "      .attr('y', output.vertical_offset)\n",
              "      .attr('alignment-baseline', 'hanging')\n",
              "      .text(text);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node with a tooltip.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {string} tooltip Text in the Tooltip.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text_with_tooltip(options, text, tooltip, output) {\n",
              "  const item = output.content.append('text')\n",
              "                   .attr('x', options.node_padding)\n",
              "                   .attr('alignment-baseline', 'hanging')\n",
              "                   .text(text);\n",
              "\n",
              "  add_tooltip(options, item, () => tooltip);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a tooltip to a dom element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!dom} target Dom element to equip with a tooltip.\n",
              " * @param {!func} get_content Generates the html content of the tooltip.\n",
              " */\n",
              "function add_tooltip(options, target, get_content) {\n",
              "  function show(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.html(get_content());\n",
              "  }\n",
              "\n",
              "  function hide(d) {\n",
              "    options.tooltip.style('display', 'none');\n",
              "  }\n",
              "\n",
              "  function move(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.style('left', (d.pageX + 5) + 'px');\n",
              "    options.tooltip.style('top', d.pageY + 'px');\n",
              "  }\n",
              "\n",
              "  target.on('mouseover', show);\n",
              "  target.on('mouseout', hide);\n",
              "  target.on('mousemove', move);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a condition inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!condition} condition Condition to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_condition(options, condition, output) {\n",
              "  threshold_format = d3.format('r');\n",
              "\n",
              "  if (condition.type === 'IS_MISSING') {\n",
              "    display_node_text(options, `${condition.attribute} is missing`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'IS_TRUE') {\n",
              "    display_node_text(options, `${condition.attribute} is true`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_IS_HIGHER_THAN') {\n",
              "    format = d3.format('r');\n",
              "    display_node_text(\n",
              "        options,\n",
              "        `${condition.attribute} >= ${threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_IS_IN') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} in [...]`,\n",
              "        `${condition.attribute} in [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_SET_CONTAINS') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} intersect [...]`,\n",
              "        `${condition.attribute} intersect [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_SPARSE_OBLIQUE') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `Sparse oblique split...`,\n",
              "        `[${condition.attributes}]*[${condition.weights}]>=${\n",
              "            threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported condition ${condition.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a value inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!value} value Value to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_value(options, value, output) {\n",
              "  if (value.type === 'PROBABILITY') {\n",
              "    const left_margin = 0;\n",
              "    const right_margin = 50;\n",
              "    const plot_width = options.node_x_size - options.node_padding * 2 -\n",
              "        left_margin - right_margin;\n",
              "\n",
              "    let cusum = Array.from(d3.cumsum(value.distribution));\n",
              "    cusum.unshift(0);\n",
              "    const distribution_plot = output.content.append('g').attr(\n",
              "        'transform', `translate(0,${output.vertical_offset + 0.5})`);\n",
              "\n",
              "    distribution_plot.selectAll('rect')\n",
              "        .data(value.distribution)\n",
              "        .join('rect')\n",
              "        .attr('height', 10)\n",
              "        .attr(\n",
              "            'x',\n",
              "            (d, i) =>\n",
              "                (cusum[i] * plot_width + left_margin + options.node_padding))\n",
              "        .attr('width', (d, i) => d * plot_width)\n",
              "        .style('fill', (d, i) => d3.schemeSet1[i]);\n",
              "\n",
              "    const num_examples =\n",
              "        output.content.append('g')\n",
              "            .attr('transform', `translate(0,${output.vertical_offset})`)\n",
              "            .append('text')\n",
              "            .attr('x', options.node_x_size - options.node_padding)\n",
              "            .attr('alignment-baseline', 'hanging')\n",
              "            .attr('text-anchor', 'end')\n",
              "            .text(`(${value.num_examples})`);\n",
              "\n",
              "    const distribution_details = d3.create('ul');\n",
              "    distribution_details.selectAll('li')\n",
              "        .data(value.distribution)\n",
              "        .join('li')\n",
              "        .append('span')\n",
              "        .text(\n",
              "            (d, i) =>\n",
              "                'class ' + i + ': ' + d3.format('.3%')(value.distribution[i]));\n",
              "\n",
              "    add_tooltip(options, distribution_plot, () => distribution_details.html());\n",
              "    add_tooltip(options, num_examples, () => 'Number of examples');\n",
              "\n",
              "    output.vertical_offset += 10;\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'REGRESSION') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'value: ' + d3.format('r')(value.value) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'UPLIFT') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'effect: ' + d3.format('r')(value.treatment_effect) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(options, `Non supported value ${value.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds an explanation inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!explanation} explanation Explanation to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_explanation(options, explanation, output) {\n",
              "  // Margin before the explanation.\n",
              "  output.vertical_offset += 10;\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported explanation ${explanation.type}`, output);\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Draw the edges of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_edges(options, graph, tree_struct) {\n",
              "  // Draw an edge between a parent and a child node with a bezier.\n",
              "  function draw_single_edge(d) {\n",
              "    return 'M' + (d.source.y + options.node_x_size) + ',' + d.source.x + ' C' +\n",
              "        (d.source.y + options.node_x_size + options.edge_rounding) + ',' +\n",
              "        d.source.x + ' ' + (d.target.y - options.edge_rounding) + ',' +\n",
              "        d.target.x + ' ' + d.target.y + ',' + d.target.x;\n",
              "  }\n",
              "\n",
              "  graph.append('g')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.2)\n",
              "      .selectAll('path')\n",
              "      .data(tree_struct.links())\n",
              "      .join('path')\n",
              "      .attr('d', draw_single_edge)\n",
              "      .attr(\n",
              "          'stroke', d => (d.target === d.source.children[0]) ? '#0F0' : '#F00');\n",
              "}\n",
              "\n",
              "display_tree({\"margin\": 10, \"node_x_size\": 160, \"node_y_size\": 28, \"node_x_offset\": 180, \"node_y_offset\": 33, \"font_size\": 10, \"edge_rounding\": 20, \"node_padding\": 2, \"show_plot_bounding_box\": false}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3123877917414722, 0.6876122082585279], \"num_examples\": 557.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"Property_Area\", \"mask\": [\"Semiurban\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.2347417840375587, 0.7652582159624414], \"num_examples\": 213.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.36046511627906974, 0.6395348837209303], \"num_examples\": 344.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Loan_Amount_Term\", \"threshold\": 420.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8333333333333334, 0.16666666666666666], \"num_examples\": 6.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3520710059171598, 0.6479289940828402], \"num_examples\": 338.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"Education\", \"mask\": [\"Graduate\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.32432432432432434, 0.6756756756756757], \"num_examples\": 259.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ApplicantIncome\", \"threshold\": 3336.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.38125, 0.61875], \"num_examples\": 160.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ApplicantIncome\", \"threshold\": 3633.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.34965034965034963, 0.6503496503496503], \"num_examples\": 143.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"LoanAmount\", \"threshold\": 58.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.36231884057971014, 0.6376811594202898], \"num_examples\": 138.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"Dependents\", \"mask\": [\"2\", \"3+\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.22857142857142856, 0.7714285714285715], \"num_examples\": 35.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.4077669902912621, 0.5922330097087378], \"num_examples\": 103.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"LoanAmount\", \"threshold\": 110.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3695652173913043, 0.6304347826086957], \"num_examples\": 92.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.7272727272727273, 0.2727272727272727], \"num_examples\": 11.0}}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 5.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.6470588235294118, 0.35294117647058826], \"num_examples\": 17.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.23232323232323232, 0.7676767676767676], \"num_examples\": 99.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ApplicantIncome\", \"threshold\": 2437.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.125, 0.875], \"num_examples\": 64.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.42857142857142855, 0.5714285714285714], \"num_examples\": 35.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"CoapplicantIncome\", \"threshold\": 543.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3448275862068966, 0.6551724137931034], \"num_examples\": 29.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8333333333333334, 0.16666666666666666], \"num_examples\": 6.0}}]}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.4430379746835443, 0.5569620253164557], \"num_examples\": 79.0}}]}]}]}, \"#tree_plot_9f4b6bc55ad34a29b710899cdfcdfe1e\")\n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(SensitiveCart1, tree_idx=0, max_depth=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHnfYvK0KUzu"
      },
      "source": [
        "As we can see, the new tree is quite different from the old one, and this means that as expected, credit history has a big impact on the decision boundary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wva88Uf1LDFR"
      },
      "source": [
        "Sensitivity analysis for applicant income:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qI2uJD5LLFPt"
      },
      "outputs": [],
      "source": [
        "SensitiveDatabase = Database.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iwQDwv_LMCf"
      },
      "outputs": [],
      "source": [
        "SensitiveDatabase['ApplicantIncome'] = SensitiveDatabase['ApplicantIncome'].sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzDW79CbLXC8"
      },
      "outputs": [],
      "source": [
        "SensitiveDataset2 = tfdf.keras.pd_dataframe_to_tf_dataset(SensitiveDatabase, label = label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYkf3YRaLbb2",
        "outputId": "55ba055a-7bc9-4f34-b2a1-f6d71ed007c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use /tmp/tmpbqn7xs99 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.271259. Found 614 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.040092\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x78a33ad0c190>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SensitiveCart2 = tfdf.keras.CartModel()\n",
        "SensitiveCart2.fit(SensitiveDataset2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJtdkrkgLgaM",
        "outputId": "ec09b3d7-9254-4761-f08c-489587f92fae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"cart_model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1 (1.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 1 (1.00 Byte)\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (12):\n",
            "\tApplicantIncome\n",
            "\tCoapplicantIncome\n",
            "\tCredit_History\n",
            "\tDependents\n",
            "\tEducation\n",
            "\tGender\n",
            "\tLoanAmount\n",
            "\tLoan_Amount_Term\n",
            "\tLoan_ID\n",
            "\tMarried\n",
            "\tProperty_Area\n",
            "\tSelf_Employed\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1.    \"Credit_History\"  1.000000 ################\n",
            "    2.     \"Property_Area\"  0.500000 ######\n",
            "    3.   \"ApplicantIncome\"  0.342105 ###\n",
            "    4.        \"LoanAmount\"  0.191176 \n",
            "    5. \"CoapplicantIncome\"  0.166667 \n",
            "    6.  \"Loan_Amount_Term\"  0.151163 \n",
            "    7.         \"Education\"  0.139785 \n",
            "    8.           \"Married\"  0.139785 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1. \"Credit_History\"  1.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1.   \"ApplicantIncome\"  5.000000 ################\n",
            "    2. \"CoapplicantIncome\"  1.000000 \n",
            "    3.    \"Credit_History\"  1.000000 \n",
            "    4.         \"Education\"  1.000000 \n",
            "    5.        \"LoanAmount\"  1.000000 \n",
            "    6.  \"Loan_Amount_Term\"  1.000000 \n",
            "    7.           \"Married\"  1.000000 \n",
            "    8.     \"Property_Area\"  1.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1.    \"Credit_History\" 77.371266 ################\n",
            "    2.   \"ApplicantIncome\" 15.778273 ##\n",
            "    3.     \"Property_Area\"  5.213080 \n",
            "    4.  \"Loan_Amount_Term\"  4.525279 \n",
            "    5.        \"LoanAmount\"  4.468078 \n",
            "    6.           \"Married\"  4.270340 \n",
            "    7. \"CoapplicantIncome\"  3.537544 \n",
            "    8.         \"Education\"  1.847553 \n",
            "\n",
            "\n",
            "\n",
            "Winner takes all: false\n",
            "Out-of-bag evaluation: accuracy:0.859649 logloss:0.435117\n",
            "Number of trees: 1\n",
            "Total number of nodes: 25\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 1 Average: 25 StdDev: 0\n",
            "Min: 25 Max: 25 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 25, 25] 1 100.00% 100.00% ##########\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 13 Average: 6.30769 StdDev: 2.89255\n",
            "Min: 1 Max: 10 Ignored: 0\n",
            "----------------------------------------------\n",
            "[  1,  2) 1   7.69%   7.69% ###\n",
            "[  2,  3) 1   7.69%  15.38% ###\n",
            "[  3,  4) 1   7.69%  23.08% ###\n",
            "[  4,  5) 1   7.69%  30.77% ###\n",
            "[  5,  6) 1   7.69%  38.46% ###\n",
            "[  6,  7) 0   0.00%  38.46%\n",
            "[  7,  8) 2  15.38%  53.85% #######\n",
            "[  8,  9) 3  23.08%  76.92% ##########\n",
            "[  9, 10) 1   7.69%  84.62% ###\n",
            "[ 10, 10] 2  15.38% 100.00% #######\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 13 Average: 42.8462 StdDev: 46.583\n",
            "Min: 6 Max: 184 Ignored: 0\n",
            "----------------------------------------------\n",
            "[   6,  14) 4  30.77%  30.77% ##########\n",
            "[  14,  23) 2  15.38%  46.15% #####\n",
            "[  23,  32) 1   7.69%  53.85% ###\n",
            "[  32,  41) 0   0.00%  53.85%\n",
            "[  41,  50) 2  15.38%  69.23% #####\n",
            "[  50,  59) 2  15.38%  84.62% #####\n",
            "[  59,  68) 0   0.00%  84.62%\n",
            "[  68,  77) 0   0.00%  84.62%\n",
            "[  77,  86) 1   7.69%  92.31% ###\n",
            "[  86,  95) 0   0.00%  92.31%\n",
            "[  95, 104) 0   0.00%  92.31%\n",
            "[ 104, 113) 0   0.00%  92.31%\n",
            "[ 113, 122) 0   0.00%  92.31%\n",
            "[ 122, 131) 0   0.00%  92.31%\n",
            "[ 131, 140) 0   0.00%  92.31%\n",
            "[ 140, 149) 0   0.00%  92.31%\n",
            "[ 149, 158) 0   0.00%  92.31%\n",
            "[ 158, 167) 0   0.00%  92.31%\n",
            "[ 167, 176) 0   0.00%  92.31%\n",
            "[ 176, 184] 1   7.69% 100.00% ###\n",
            "\n",
            "Attribute in nodes:\n",
            "\t5 : ApplicantIncome [NUMERICAL]\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : Married [CATEGORICAL]\n",
            "\t1 : Loan_Amount_Term [NUMERICAL]\n",
            "\t1 : LoanAmount [NUMERICAL]\n",
            "\t1 : Education [CATEGORICAL]\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\t1 : CoapplicantIncome [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\t1 : ApplicantIncome [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t2 : ApplicantIncome [NUMERICAL]\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t3 : ApplicantIncome [NUMERICAL]\n",
            "\t1 : Property_Area [CATEGORICAL]\n",
            "\t1 : LoanAmount [NUMERICAL]\n",
            "\t1 : Credit_History [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t9 : HigherCondition\n",
            "\t3 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t1 : HigherCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t1 : ContainsBitmapCondition\n",
            "\t1 : HigherCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t2 : HigherCondition\n",
            "\t1 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t3 : HigherCondition\n",
            "\t1 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t5 : HigherCondition\n",
            "\t1 : ContainsBitmapCondition\n",
            "Node format: NOT_SET\n",
            "Pruned nodes during training: 96\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:0.859649 logloss:0.435117\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(SensitiveCart2.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "o03D-gErLnYU",
        "outputId": "4e104ce7-0210-4b78-c5ca-dcd334570466"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<script src=\"https://d3js.org/d3.v6.min.js\"></script>\n",
              "<div id=\"tree_plot_ad0f5f7b8d1f4fa8ae101160808aa4de\"></div>\n",
              "<script>\n",
              "/*\n",
              " * Copyright 2021 Google LLC.\n",
              " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              " * you may not use this file except in compliance with the License.\n",
              " * You may obtain a copy of the License at\n",
              " *\n",
              " *     https://www.apache.org/licenses/LICENSE-2.0\n",
              " *\n",
              " * Unless required by applicable law or agreed to in writing, software\n",
              " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              " * See the License for the specific language governing permissions and\n",
              " * limitations under the License.\n",
              " */\n",
              "\n",
              "/**\n",
              " *  Plotting of decision trees generated by TF-DF.\n",
              " *\n",
              " *  A tree is a recursive structure of node objects.\n",
              " *  A node contains one or more of the following components:\n",
              " *\n",
              " *    - A value: Representing the output of the node. If the node is not a leaf,\n",
              " *      the value is only present for analysis i.e. it is not used for\n",
              " *      predictions.\n",
              " *\n",
              " *    - A condition : For non-leaf nodes, the condition (also known as split)\n",
              " *      defines a binary test to branch to the positive or negative child.\n",
              " *\n",
              " *    - An explanation: Generally a plot showing the relation between the label\n",
              " *      and the condition to give insights about the effect of the condition.\n",
              " *\n",
              " *    - Two children : For non-leaf nodes, the children nodes. The first\n",
              " *      children (i.e. \"node.children[0]\") is the negative children (drawn in\n",
              " *      red). The second children is the positive one (drawn in green).\n",
              " *\n",
              " */\n",
              "\n",
              "/**\n",
              " * Plots a single decision tree into a DOM element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!tree} raw_tree Recursive tree structure.\n",
              " * @param {string} canvas_id Id of the output dom element.\n",
              " */\n",
              "function display_tree(options, raw_tree, canvas_id) {\n",
              "  console.log(options);\n",
              "\n",
              "  // Determine the node placement.\n",
              "  const tree_struct = d3.tree().nodeSize(\n",
              "      [options.node_y_offset, options.node_x_offset])(d3.hierarchy(raw_tree));\n",
              "\n",
              "  // Boundaries of the node placement.\n",
              "  let x_min = Infinity;\n",
              "  let x_max = -x_min;\n",
              "  let y_min = Infinity;\n",
              "  let y_max = -x_min;\n",
              "\n",
              "  tree_struct.each(d => {\n",
              "    if (d.x > x_max) x_max = d.x;\n",
              "    if (d.x < x_min) x_min = d.x;\n",
              "    if (d.y > y_max) y_max = d.y;\n",
              "    if (d.y < y_min) y_min = d.y;\n",
              "  });\n",
              "\n",
              "  // Size of the plot.\n",
              "  const width = y_max - y_min + options.node_x_size + options.margin * 2;\n",
              "  const height = x_max - x_min + options.node_y_size + options.margin * 2 +\n",
              "      options.node_y_offset - options.node_y_size;\n",
              "\n",
              "  const plot = d3.select(canvas_id);\n",
              "\n",
              "  // Tool tip\n",
              "  options.tooltip = plot.append('div')\n",
              "                        .attr('width', 100)\n",
              "                        .attr('height', 100)\n",
              "                        .style('padding', '4px')\n",
              "                        .style('background', '#fff')\n",
              "                        .style('box-shadow', '4px 4px 0px rgba(0,0,0,0.1)')\n",
              "                        .style('border', '1px solid black')\n",
              "                        .style('font-family', 'sans-serif')\n",
              "                        .style('font-size', options.font_size)\n",
              "                        .style('position', 'absolute')\n",
              "                        .style('z-index', '10')\n",
              "                        .attr('pointer-events', 'none')\n",
              "                        .style('display', 'none');\n",
              "\n",
              "  // Create canvas\n",
              "  const svg = plot.append('svg').attr('width', width).attr('height', height);\n",
              "  const graph =\n",
              "      svg.style('overflow', 'visible')\n",
              "          .append('g')\n",
              "          .attr('font-family', 'sans-serif')\n",
              "          .attr('font-size', options.font_size)\n",
              "          .attr(\n",
              "              'transform',\n",
              "              () => `translate(${options.margin},${\n",
              "                  - x_min + options.node_y_offset / 2 + options.margin})`);\n",
              "\n",
              "  // Plot bounding box.\n",
              "  if (options.show_plot_bounding_box) {\n",
              "    svg.append('rect')\n",
              "        .attr('width', width)\n",
              "        .attr('height', height)\n",
              "        .attr('fill', 'none')\n",
              "        .attr('stroke-width', 1.0)\n",
              "        .attr('stroke', 'black');\n",
              "  }\n",
              "\n",
              "  // Draw the edges.\n",
              "  display_edges(options, graph, tree_struct);\n",
              "\n",
              "  // Draw the nodes.\n",
              "  display_nodes(options, graph, tree_struct);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Draw the nodes of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_nodes(options, graph, tree_struct) {\n",
              "  const nodes = graph.append('g')\n",
              "                    .selectAll('g')\n",
              "                    .data(tree_struct.descendants())\n",
              "                    .join('g')\n",
              "                    .attr('transform', d => `translate(${d.y},${d.x})`);\n",
              "\n",
              "  nodes.append('rect')\n",
              "      .attr('x', 0.5)\n",
              "      .attr('y', 0.5)\n",
              "      .attr('width', options.node_x_size)\n",
              "      .attr('height', options.node_y_size)\n",
              "      .attr('stroke', 'lightgrey')\n",
              "      .attr('stroke-width', 1)\n",
              "      .attr('fill', 'white')\n",
              "      .attr('y', -options.node_y_size / 2);\n",
              "\n",
              "  // Brackets on the right of condition nodes without children.\n",
              "  non_leaf_node_without_children =\n",
              "      nodes.filter(node => node.data.condition != null && node.children == null)\n",
              "          .append('g')\n",
              "          .attr('transform', `translate(${options.node_x_size},0)`);\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,10 10,10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#F00');\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,-10 10,-10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#0F0');\n",
              "\n",
              "  const node_content = nodes.append('g').attr(\n",
              "      'transform',\n",
              "      `translate(0,${options.node_padding - options.node_y_size / 2})`);\n",
              "\n",
              "  node_content.append(node => create_node_element(options, node));\n",
              "}\n",
              "\n",
              "/**\n",
              " * Creates the D3 content for a single node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!node} node Node to draw.\n",
              " * @return {!d3} D3 content.\n",
              " */\n",
              "function create_node_element(options, node) {\n",
              "  // Output accumulator.\n",
              "  let output = {\n",
              "    // Content to draw.\n",
              "    content: d3.create('svg:g'),\n",
              "    // Vertical offset to the next element to draw.\n",
              "    vertical_offset: 0\n",
              "  };\n",
              "\n",
              "  // Conditions.\n",
              "  if (node.data.condition != null) {\n",
              "    display_condition(options, node.data.condition, output);\n",
              "  }\n",
              "\n",
              "  // Values.\n",
              "  if (node.data.value != null) {\n",
              "    display_value(options, node.data.value, output);\n",
              "  }\n",
              "\n",
              "  // Explanations.\n",
              "  if (node.data.explanation != null) {\n",
              "    display_explanation(options, node.data.explanation, output);\n",
              "  }\n",
              "\n",
              "  return output.content.node();\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text(options, text, output) {\n",
              "  output.content.append('text')\n",
              "      .attr('x', options.node_padding)\n",
              "      .attr('y', output.vertical_offset)\n",
              "      .attr('alignment-baseline', 'hanging')\n",
              "      .text(text);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node with a tooltip.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {string} tooltip Text in the Tooltip.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text_with_tooltip(options, text, tooltip, output) {\n",
              "  const item = output.content.append('text')\n",
              "                   .attr('x', options.node_padding)\n",
              "                   .attr('alignment-baseline', 'hanging')\n",
              "                   .text(text);\n",
              "\n",
              "  add_tooltip(options, item, () => tooltip);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a tooltip to a dom element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!dom} target Dom element to equip with a tooltip.\n",
              " * @param {!func} get_content Generates the html content of the tooltip.\n",
              " */\n",
              "function add_tooltip(options, target, get_content) {\n",
              "  function show(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.html(get_content());\n",
              "  }\n",
              "\n",
              "  function hide(d) {\n",
              "    options.tooltip.style('display', 'none');\n",
              "  }\n",
              "\n",
              "  function move(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.style('left', (d.pageX + 5) + 'px');\n",
              "    options.tooltip.style('top', d.pageY + 'px');\n",
              "  }\n",
              "\n",
              "  target.on('mouseover', show);\n",
              "  target.on('mouseout', hide);\n",
              "  target.on('mousemove', move);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a condition inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!condition} condition Condition to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_condition(options, condition, output) {\n",
              "  threshold_format = d3.format('r');\n",
              "\n",
              "  if (condition.type === 'IS_MISSING') {\n",
              "    display_node_text(options, `${condition.attribute} is missing`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'IS_TRUE') {\n",
              "    display_node_text(options, `${condition.attribute} is true`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_IS_HIGHER_THAN') {\n",
              "    format = d3.format('r');\n",
              "    display_node_text(\n",
              "        options,\n",
              "        `${condition.attribute} >= ${threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_IS_IN') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} in [...]`,\n",
              "        `${condition.attribute} in [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_SET_CONTAINS') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} intersect [...]`,\n",
              "        `${condition.attribute} intersect [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_SPARSE_OBLIQUE') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `Sparse oblique split...`,\n",
              "        `[${condition.attributes}]*[${condition.weights}]>=${\n",
              "            threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported condition ${condition.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a value inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!value} value Value to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_value(options, value, output) {\n",
              "  if (value.type === 'PROBABILITY') {\n",
              "    const left_margin = 0;\n",
              "    const right_margin = 50;\n",
              "    const plot_width = options.node_x_size - options.node_padding * 2 -\n",
              "        left_margin - right_margin;\n",
              "\n",
              "    let cusum = Array.from(d3.cumsum(value.distribution));\n",
              "    cusum.unshift(0);\n",
              "    const distribution_plot = output.content.append('g').attr(\n",
              "        'transform', `translate(0,${output.vertical_offset + 0.5})`);\n",
              "\n",
              "    distribution_plot.selectAll('rect')\n",
              "        .data(value.distribution)\n",
              "        .join('rect')\n",
              "        .attr('height', 10)\n",
              "        .attr(\n",
              "            'x',\n",
              "            (d, i) =>\n",
              "                (cusum[i] * plot_width + left_margin + options.node_padding))\n",
              "        .attr('width', (d, i) => d * plot_width)\n",
              "        .style('fill', (d, i) => d3.schemeSet1[i]);\n",
              "\n",
              "    const num_examples =\n",
              "        output.content.append('g')\n",
              "            .attr('transform', `translate(0,${output.vertical_offset})`)\n",
              "            .append('text')\n",
              "            .attr('x', options.node_x_size - options.node_padding)\n",
              "            .attr('alignment-baseline', 'hanging')\n",
              "            .attr('text-anchor', 'end')\n",
              "            .text(`(${value.num_examples})`);\n",
              "\n",
              "    const distribution_details = d3.create('ul');\n",
              "    distribution_details.selectAll('li')\n",
              "        .data(value.distribution)\n",
              "        .join('li')\n",
              "        .append('span')\n",
              "        .text(\n",
              "            (d, i) =>\n",
              "                'class ' + i + ': ' + d3.format('.3%')(value.distribution[i]));\n",
              "\n",
              "    add_tooltip(options, distribution_plot, () => distribution_details.html());\n",
              "    add_tooltip(options, num_examples, () => 'Number of examples');\n",
              "\n",
              "    output.vertical_offset += 10;\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'REGRESSION') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'value: ' + d3.format('r')(value.value) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'UPLIFT') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'effect: ' + d3.format('r')(value.treatment_effect) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(options, `Non supported value ${value.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds an explanation inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!explanation} explanation Explanation to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_explanation(options, explanation, output) {\n",
              "  // Margin before the explanation.\n",
              "  output.vertical_offset += 10;\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported explanation ${explanation.type}`, output);\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Draw the edges of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_edges(options, graph, tree_struct) {\n",
              "  // Draw an edge between a parent and a child node with a bezier.\n",
              "  function draw_single_edge(d) {\n",
              "    return 'M' + (d.source.y + options.node_x_size) + ',' + d.source.x + ' C' +\n",
              "        (d.source.y + options.node_x_size + options.edge_rounding) + ',' +\n",
              "        d.source.x + ' ' + (d.target.y - options.edge_rounding) + ',' +\n",
              "        d.target.x + ' ' + d.target.y + ',' + d.target.x;\n",
              "  }\n",
              "\n",
              "  graph.append('g')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.2)\n",
              "      .selectAll('path')\n",
              "      .data(tree_struct.links())\n",
              "      .join('path')\n",
              "      .attr('d', draw_single_edge)\n",
              "      .attr(\n",
              "          'stroke', d => (d.target === d.source.children[0]) ? '#0F0' : '#F00');\n",
              "}\n",
              "\n",
              "display_tree({\"margin\": 10, \"node_x_size\": 160, \"node_y_size\": 28, \"node_x_offset\": 180, \"node_y_offset\": 33, \"font_size\": 10, \"edge_rounding\": 20, \"node_padding\": 2, \"show_plot_bounding_box\": false}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3123877917414722, 0.6876122082585279], \"num_examples\": 557.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Credit_History\", \"threshold\": 0.42109930515289307}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.21008403361344538, 0.7899159663865546], \"num_examples\": 476.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"Property_Area\", \"mask\": [\"Semiurban\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.1358695652173913, 0.8641304347826086], \"num_examples\": 184.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.2568493150684932, 0.7431506849315068], \"num_examples\": 292.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ApplicantIncome\", \"threshold\": 2417.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.2834008097165992, 0.7165991902834008], \"num_examples\": 247.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ApplicantIncome\", \"threshold\": 12688.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.08695652173913043, 0.9130434782608695], \"num_examples\": 23.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.30357142857142855, 0.6964285714285714], \"num_examples\": 224.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ApplicantIncome\", \"threshold\": 3154.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.2727272727272727, 0.7272727272727273], \"num_examples\": 176.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"LoanAmount\", \"threshold\": 200.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.5789473684210527, 0.42105263157894735], \"num_examples\": 19.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"Married\", \"mask\": [\"Yes\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.38461538461538464, 0.6153846153846154], \"num_examples\": 13.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 6.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.2356687898089172, 0.7643312101910829], \"num_examples\": 157.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"CoapplicantIncome\", \"threshold\": 1007.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.15294117647058825, 0.8470588235294118], \"num_examples\": 85.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Loan_Amount_Term\", \"threshold\": 240.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.11392405063291139, 0.8860759493670886], \"num_examples\": 79.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ApplicantIncome\", \"threshold\": 5705.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 20.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.15254237288135594, 0.847457627118644], \"num_examples\": 59.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"ApplicantIncome\", \"threshold\": 5176.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.6666666666666666, 0.3333333333333333], \"num_examples\": 6.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.09433962264150944, 0.9056603773584906], \"num_examples\": 53.0}}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.6666666666666666, 0.3333333333333333], \"num_examples\": 6.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3333333333333333, 0.6666666666666666], \"num_examples\": 72.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"Education\", \"mask\": [\"Graduate\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.2727272727272727, 0.7272727272727273], \"num_examples\": 55.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.5294117647058824, 0.47058823529411764], \"num_examples\": 17.0}}]}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.4166666666666667, 0.5833333333333334], \"num_examples\": 48.0}}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.1111111111111111, 0.8888888888888888], \"num_examples\": 45.0}}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9135802469135802, 0.08641975308641975], \"num_examples\": 81.0}}]}, \"#tree_plot_ad0f5f7b8d1f4fa8ae101160808aa4de\")\n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(SensitiveCart2, tree_idx=0, max_depth=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCpNqbPELxv7"
      },
      "source": [
        "This tree is pretty similar to the original tree earlier on, but the deeper it gets, the more different it is. This indicates that while it's not as important as credit history or property area for the decision boundary, it does still have a signifigant importance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86-amGSbMjsV"
      },
      "source": [
        "**Task 2 (30 points): From the Bagging and Boosting ensemble methods pick any one algorithm\n",
        "from each category. Implement both the algorithms using the same data.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YHOj2iXY0jS"
      },
      "source": [
        "For the bagging algorithm I will be random forest. Like before, this will be implemented through tensorflow decision forests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2XSLABvZWMt",
        "outputId": "6f4fc697-b219-4d24-b357-206637177d1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use /tmp/tmp9r77w04n as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:04.070493. Found 614 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.550988\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7f2d403a0dd0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Make the forest model\n",
        "RandomForest = tfdf.keras.RandomForestModel()\n",
        "RandomForest.fit(Dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFv_7m0baFnC"
      },
      "source": [
        "Summary of model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eza5OfIiaBGr",
        "outputId": "735234c5-3a17-44f1-8191-dfd12a720227"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"random_forest_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1 (1.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 1 (1.00 Byte)\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (12):\n",
            "\tApplicantIncome\n",
            "\tCoapplicantIncome\n",
            "\tCredit_History\n",
            "\tDependents\n",
            "\tEducation\n",
            "\tGender\n",
            "\tLoanAmount\n",
            "\tLoan_Amount_Term\n",
            "\tLoan_ID\n",
            "\tMarried\n",
            "\tProperty_Area\n",
            "\tSelf_Employed\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1.    \"Credit_History\"  0.454517 ################\n",
            "    2.        \"LoanAmount\"  0.215920 ####\n",
            "    3.   \"ApplicantIncome\"  0.207329 ####\n",
            "    4.     \"Property_Area\"  0.201034 ####\n",
            "    5. \"CoapplicantIncome\"  0.187291 ###\n",
            "    6.  \"Loan_Amount_Term\"  0.145994 #\n",
            "    7.        \"Dependents\"  0.139434 #\n",
            "    8.           \"Married\"  0.134909 \n",
            "    9.         \"Education\"  0.128134 \n",
            "   10.     \"Self_Employed\"  0.115017 \n",
            "   11.            \"Gender\"  0.114371 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1.    \"Credit_History\" 137.000000 ################\n",
            "    2.     \"Property_Area\" 45.000000 ####\n",
            "    3.        \"LoanAmount\" 23.000000 ##\n",
            "    4.   \"ApplicantIncome\" 21.000000 ##\n",
            "    5. \"CoapplicantIncome\" 21.000000 ##\n",
            "    6.  \"Loan_Amount_Term\" 21.000000 ##\n",
            "    7.           \"Married\" 15.000000 #\n",
            "    8.         \"Education\" 13.000000 #\n",
            "    9.        \"Dependents\"  4.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1.   \"ApplicantIncome\" 4795.000000 ################\n",
            "    2.        \"LoanAmount\" 4328.000000 ##############\n",
            "    3. \"CoapplicantIncome\" 2441.000000 #######\n",
            "    4.        \"Dependents\" 1291.000000 ###\n",
            "    5.     \"Property_Area\" 1146.000000 ###\n",
            "    6.    \"Credit_History\" 771.000000 #\n",
            "    7.  \"Loan_Amount_Term\" 583.000000 #\n",
            "    8.           \"Married\" 569.000000 \n",
            "    9.         \"Education\" 417.000000 \n",
            "   10.            \"Gender\" 371.000000 \n",
            "   11.     \"Self_Employed\" 294.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1.    \"Credit_History\" 26773.469777 ################\n",
            "    2.   \"ApplicantIncome\" 16173.127513 #########\n",
            "    3.        \"LoanAmount\" 14498.196895 ########\n",
            "    4. \"CoapplicantIncome\" 8922.058324 ####\n",
            "    5.     \"Property_Area\" 4208.675238 ##\n",
            "    6.        \"Dependents\" 4203.950641 ##\n",
            "    7.  \"Loan_Amount_Term\" 2073.426333 \n",
            "    8.           \"Married\" 1860.917297 \n",
            "    9.         \"Education\" 1436.529013 \n",
            "   10.            \"Gender\" 959.917493 \n",
            "   11.     \"Self_Employed\" 899.521129 \n",
            "\n",
            "\n",
            "\n",
            "Winner takes all: true\n",
            "Out-of-bag evaluation: accuracy:0.798046 logloss:0.510613\n",
            "Number of trees: 300\n",
            "Total number of nodes: 34312\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 300 Average: 114.373 StdDev: 7.95868\n",
            "Min: 83 Max: 137 Ignored: 0\n",
            "----------------------------------------------\n",
            "[  83,  85)  1   0.33%   0.33%\n",
            "[  85,  88)  2   0.67%   1.00%\n",
            "[  88,  91)  0   0.00%   1.00%\n",
            "[  91,  94)  2   0.67%   1.67%\n",
            "[  94,  96)  0   0.00%   1.67%\n",
            "[  96,  99)  2   0.67%   2.33%\n",
            "[  99, 102)  9   3.00%   5.33% ##\n",
            "[ 102, 105) 17   5.67%  11.00% ###\n",
            "[ 105, 107)  8   2.67%  13.67% #\n",
            "[ 107, 110) 37  12.33%  26.00% ######\n",
            "[ 110, 113) 26   8.67%  34.67% #####\n",
            "[ 113, 116) 57  19.00%  53.67% ##########\n",
            "[ 116, 118) 46  15.33%  69.00% ########\n",
            "[ 118, 121) 29   9.67%  78.67% #####\n",
            "[ 121, 124) 36  12.00%  90.67% ######\n",
            "[ 124, 127) 13   4.33%  95.00% ##\n",
            "[ 127, 129)  5   1.67%  96.67% #\n",
            "[ 129, 132)  6   2.00%  98.67% #\n",
            "[ 132, 135)  2   0.67%  99.33%\n",
            "[ 135, 137]  2   0.67% 100.00%\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 17306 Average: 8.24015 StdDev: 2.91931\n",
            "Min: 1 Max: 15 Ignored: 0\n",
            "----------------------------------------------\n",
            "[  1,  2)   21   0.12%   0.12%\n",
            "[  2,  3)  192   1.11%   1.23% #\n",
            "[  3,  4)  575   3.32%   4.55% ###\n",
            "[  4,  5) 1028   5.94%  10.49% #####\n",
            "[  5,  6) 1399   8.08%  18.58% ######\n",
            "[  6,  7) 1865  10.78%  29.35% ########\n",
            "[  7,  8) 2166  12.52%  41.87% ##########\n",
            "[  8,  9) 2227  12.87%  54.74% ##########\n",
            "[  9, 10) 2067  11.94%  66.68% #########\n",
            "[ 10, 11) 1788  10.33%  77.01% ########\n",
            "[ 11, 12) 1511   8.73%  85.74% #######\n",
            "[ 12, 13) 1046   6.04%  91.79% #####\n",
            "[ 13, 14)  679   3.92%  95.71% ###\n",
            "[ 14, 15)  414   2.39%  98.10% ##\n",
            "[ 15, 15]  328   1.90% 100.00% #\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 17306 Average: 10.6437 StdDev: 10.8584\n",
            "Min: 5 Max: 126 Ignored: 0\n",
            "----------------------------------------------\n",
            "[   5,  11) 13304  76.88%  76.88% ##########\n",
            "[  11,  17)  1629   9.41%  86.29% #\n",
            "[  17,  23)   850   4.91%  91.20% #\n",
            "[  23,  29)   515   2.98%  94.18%\n",
            "[  29,  35)   307   1.77%  95.95%\n",
            "[  35,  41)   185   1.07%  97.02%\n",
            "[  41,  47)   143   0.83%  97.84%\n",
            "[  47,  53)    91   0.53%  98.37%\n",
            "[  53,  59)    84   0.49%  98.86%\n",
            "[  59,  66)    67   0.39%  99.24%\n",
            "[  66,  72)    27   0.16%  99.40%\n",
            "[  72,  78)    32   0.18%  99.58%\n",
            "[  78,  84)    24   0.14%  99.72%\n",
            "[  84,  90)    18   0.10%  99.83%\n",
            "[  90,  96)    11   0.06%  99.89%\n",
            "[  96, 102)     7   0.04%  99.93%\n",
            "[ 102, 108)     7   0.04%  99.97%\n",
            "[ 108, 114)     1   0.01%  99.98%\n",
            "[ 114, 120)     2   0.01%  99.99%\n",
            "[ 120, 126]     2   0.01% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t4795 : ApplicantIncome [NUMERICAL]\n",
            "\t4328 : LoanAmount [NUMERICAL]\n",
            "\t2441 : CoapplicantIncome [NUMERICAL]\n",
            "\t1291 : Dependents [CATEGORICAL]\n",
            "\t1146 : Property_Area [CATEGORICAL]\n",
            "\t771 : Credit_History [NUMERICAL]\n",
            "\t583 : Loan_Amount_Term [NUMERICAL]\n",
            "\t569 : Married [CATEGORICAL]\n",
            "\t417 : Education [CATEGORICAL]\n",
            "\t371 : Gender [CATEGORICAL]\n",
            "\t294 : Self_Employed [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t137 : Credit_History [NUMERICAL]\n",
            "\t45 : Property_Area [CATEGORICAL]\n",
            "\t23 : LoanAmount [NUMERICAL]\n",
            "\t21 : Loan_Amount_Term [NUMERICAL]\n",
            "\t21 : CoapplicantIncome [NUMERICAL]\n",
            "\t21 : ApplicantIncome [NUMERICAL]\n",
            "\t15 : Married [CATEGORICAL]\n",
            "\t13 : Education [CATEGORICAL]\n",
            "\t4 : Dependents [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t252 : Credit_History [NUMERICAL]\n",
            "\t128 : LoanAmount [NUMERICAL]\n",
            "\t124 : Property_Area [CATEGORICAL]\n",
            "\t95 : ApplicantIncome [NUMERICAL]\n",
            "\t88 : CoapplicantIncome [NUMERICAL]\n",
            "\t55 : Dependents [CATEGORICAL]\n",
            "\t50 : Loan_Amount_Term [NUMERICAL]\n",
            "\t46 : Married [CATEGORICAL]\n",
            "\t33 : Education [CATEGORICAL]\n",
            "\t4 : Self_Employed [CATEGORICAL]\n",
            "\t4 : Gender [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t373 : Credit_History [NUMERICAL]\n",
            "\t352 : LoanAmount [NUMERICAL]\n",
            "\t285 : ApplicantIncome [NUMERICAL]\n",
            "\t216 : CoapplicantIncome [NUMERICAL]\n",
            "\t210 : Property_Area [CATEGORICAL]\n",
            "\t130 : Dependents [CATEGORICAL]\n",
            "\t105 : Loan_Amount_Term [NUMERICAL]\n",
            "\t82 : Married [CATEGORICAL]\n",
            "\t57 : Education [CATEGORICAL]\n",
            "\t23 : Self_Employed [CATEGORICAL]\n",
            "\t12 : Gender [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t666 : LoanAmount [NUMERICAL]\n",
            "\t606 : ApplicantIncome [NUMERICAL]\n",
            "\t487 : Credit_History [NUMERICAL]\n",
            "\t416 : CoapplicantIncome [NUMERICAL]\n",
            "\t320 : Property_Area [CATEGORICAL]\n",
            "\t223 : Dependents [CATEGORICAL]\n",
            "\t189 : Loan_Amount_Term [NUMERICAL]\n",
            "\t128 : Married [CATEGORICAL]\n",
            "\t92 : Education [CATEGORICAL]\n",
            "\t39 : Self_Employed [CATEGORICAL]\n",
            "\t36 : Gender [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t1582 : ApplicantIncome [NUMERICAL]\n",
            "\t1528 : LoanAmount [NUMERICAL]\n",
            "\t1001 : CoapplicantIncome [NUMERICAL]\n",
            "\t647 : Credit_History [NUMERICAL]\n",
            "\t548 : Dependents [CATEGORICAL]\n",
            "\t545 : Property_Area [CATEGORICAL]\n",
            "\t343 : Loan_Amount_Term [NUMERICAL]\n",
            "\t255 : Married [CATEGORICAL]\n",
            "\t176 : Education [CATEGORICAL]\n",
            "\t121 : Self_Employed [CATEGORICAL]\n",
            "\t115 : Gender [CATEGORICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t12918 : HigherCondition\n",
            "\t4088 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t223 : HigherCondition\n",
            "\t77 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t613 : HigherCondition\n",
            "\t266 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t1331 : HigherCondition\n",
            "\t514 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t2364 : HigherCondition\n",
            "\t838 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t5101 : HigherCondition\n",
            "\t1760 : ContainsBitmapCondition\n",
            "Node format: NOT_SET\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:0.733032 logloss:9.62251\n",
            "\ttrees: 11, Out-of-bag evaluation: accuracy:0.702128 logloss:3.61988\n",
            "\ttrees: 21, Out-of-bag evaluation: accuracy:0.747557 logloss:1.98236\n",
            "\ttrees: 31, Out-of-bag evaluation: accuracy:0.754072 logloss:1.43873\n",
            "\ttrees: 41, Out-of-bag evaluation: accuracy:0.775244 logloss:1.21743\n",
            "\ttrees: 51, Out-of-bag evaluation: accuracy:0.775244 logloss:0.993974\n",
            "\ttrees: 61, Out-of-bag evaluation: accuracy:0.776873 logloss:0.941345\n",
            "\ttrees: 71, Out-of-bag evaluation: accuracy:0.781759 logloss:0.832219\n",
            "\ttrees: 81, Out-of-bag evaluation: accuracy:0.785016 logloss:0.774995\n",
            "\ttrees: 91, Out-of-bag evaluation: accuracy:0.789902 logloss:0.775127\n",
            "\ttrees: 101, Out-of-bag evaluation: accuracy:0.789902 logloss:0.616334\n",
            "\ttrees: 111, Out-of-bag evaluation: accuracy:0.776873 logloss:0.617656\n",
            "\ttrees: 121, Out-of-bag evaluation: accuracy:0.783388 logloss:0.562616\n",
            "\ttrees: 131, Out-of-bag evaluation: accuracy:0.786645 logloss:0.561389\n",
            "\ttrees: 141, Out-of-bag evaluation: accuracy:0.791531 logloss:0.560506\n",
            "\ttrees: 151, Out-of-bag evaluation: accuracy:0.794788 logloss:0.561089\n",
            "\ttrees: 161, Out-of-bag evaluation: accuracy:0.791531 logloss:0.560331\n",
            "\ttrees: 171, Out-of-bag evaluation: accuracy:0.79316 logloss:0.563167\n",
            "\ttrees: 181, Out-of-bag evaluation: accuracy:0.79316 logloss:0.562418\n",
            "\ttrees: 191, Out-of-bag evaluation: accuracy:0.796417 logloss:0.564605\n",
            "\ttrees: 201, Out-of-bag evaluation: accuracy:0.796417 logloss:0.564708\n",
            "\ttrees: 211, Out-of-bag evaluation: accuracy:0.794788 logloss:0.564561\n",
            "\ttrees: 221, Out-of-bag evaluation: accuracy:0.794788 logloss:0.511587\n",
            "\ttrees: 231, Out-of-bag evaluation: accuracy:0.796417 logloss:0.510639\n",
            "\ttrees: 241, Out-of-bag evaluation: accuracy:0.796417 logloss:0.511335\n",
            "\ttrees: 251, Out-of-bag evaluation: accuracy:0.796417 logloss:0.510209\n",
            "\ttrees: 261, Out-of-bag evaluation: accuracy:0.799674 logloss:0.509775\n",
            "\ttrees: 271, Out-of-bag evaluation: accuracy:0.798046 logloss:0.509072\n",
            "\ttrees: 281, Out-of-bag evaluation: accuracy:0.796417 logloss:0.510705\n",
            "\ttrees: 291, Out-of-bag evaluation: accuracy:0.796417 logloss:0.509804\n",
            "\ttrees: 300, Out-of-bag evaluation: accuracy:0.798046 logloss:0.510613\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(RandomForest.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngaezxqqZwhY"
      },
      "source": [
        "Plotting any individual tree for this model wouldn't be helpful due to the injected noise. The oob evaluation gave an accuracy of around 80%, and logloss of around 0.51, so the model doesn't seem as good as the Cart model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEnx1GFtcG47"
      },
      "source": [
        "For the Boosting model, I'll be using a Gradient boosting model, tensorflow's GradientBoostedTreesModel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhkuAsnCdDGN",
        "outputId": "ceb881c0-9cb9-4247-c24b-d925a0cd97c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use /tmp/tmpw8bjseq_ as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.278482. Found 614 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.184444\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7bf9068275d0>"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "GradientBoost = tfdf.keras.GradientBoostedTreesModel()\n",
        "GradientBoost.fit(Dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6OPEiL7dNbn"
      },
      "source": [
        "Summary of the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1gjFtIDdM-v",
        "outputId": "6992c8f3-f2ab-4200-8724-3b16e7806e5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"gradient_boosted_trees_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1 (1.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 1 (1.00 Byte)\n",
            "_________________________________________________________________\n",
            "Type: \"GRADIENT_BOOSTED_TREES\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (12):\n",
            "\tApplicantIncome\n",
            "\tCoapplicantIncome\n",
            "\tCredit_History\n",
            "\tDependents\n",
            "\tEducation\n",
            "\tGender\n",
            "\tLoanAmount\n",
            "\tLoan_Amount_Term\n",
            "\tLoan_ID\n",
            "\tMarried\n",
            "\tProperty_Area\n",
            "\tSelf_Employed\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1.    \"Credit_History\"  1.000000 ################\n",
            "    2.        \"LoanAmount\"  0.275070 #\n",
            "    3.  \"Loan_Amount_Term\"  0.229720 \n",
            "    4.     \"Property_Area\"  0.228862 \n",
            "    5.   \"ApplicantIncome\"  0.228088 \n",
            "    6. \"CoapplicantIncome\"  0.216107 \n",
            "    7.           \"Married\"  0.195554 \n",
            "    8.        \"Dependents\"  0.184586 \n",
            "    9.     \"Self_Employed\"  0.183242 \n",
            "   10.         \"Education\"  0.182931 \n",
            "   11.            \"Gender\"  0.181697 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1. \"Credit_History\" 20.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1.   \"ApplicantIncome\" 110.000000 ################\n",
            "    2.        \"LoanAmount\" 85.000000 ############\n",
            "    3. \"CoapplicantIncome\" 53.000000 #######\n",
            "    4.  \"Loan_Amount_Term\" 33.000000 ####\n",
            "    5.     \"Property_Area\" 31.000000 ####\n",
            "    6.    \"Credit_History\" 25.000000 ###\n",
            "    7.           \"Married\" 15.000000 #\n",
            "    8.        \"Dependents\" 13.000000 #\n",
            "    9.            \"Gender\"  4.000000 \n",
            "   10.         \"Education\"  3.000000 \n",
            "   11.     \"Self_Employed\"  2.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1.    \"Credit_History\" 180.049780 ################\n",
            "    2.   \"ApplicantIncome\" 51.668460 ####\n",
            "    3. \"CoapplicantIncome\" 26.885627 ##\n",
            "    4.        \"LoanAmount\" 23.632121 ##\n",
            "    5.     \"Property_Area\" 14.235750 #\n",
            "    6.  \"Loan_Amount_Term\"  9.397277 \n",
            "    7.           \"Married\"  5.581587 \n",
            "    8.        \"Dependents\"  4.207983 \n",
            "    9.         \"Education\"  1.628337 \n",
            "   10.            \"Gender\"  0.995759 \n",
            "   11.     \"Self_Employed\"  0.484801 \n",
            "\n",
            "\n",
            "\n",
            "Loss: BINOMIAL_LOG_LIKELIHOOD\n",
            "Validation loss value: 0.989699\n",
            "Number of trees per iteration: 1\n",
            "Node format: NOT_SET\n",
            "Number of trees: 20\n",
            "Total number of nodes: 768\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 20 Average: 38.4 StdDev: 6.48383\n",
            "Min: 29 Max: 51 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 29, 30) 1   5.00%   5.00% ###\n",
            "[ 30, 31) 0   0.00%   5.00%\n",
            "[ 31, 32) 3  15.00%  20.00% ##########\n",
            "[ 32, 33) 0   0.00%  20.00%\n",
            "[ 33, 34) 3  15.00%  35.00% ##########\n",
            "[ 34, 35) 0   0.00%  35.00%\n",
            "[ 35, 37) 2  10.00%  45.00% #######\n",
            "[ 37, 38) 2  10.00%  55.00% #######\n",
            "[ 38, 39) 0   0.00%  55.00%\n",
            "[ 39, 40) 1   5.00%  60.00% ###\n",
            "[ 40, 41) 0   0.00%  60.00%\n",
            "[ 41, 42) 1   5.00%  65.00% ###\n",
            "[ 42, 43) 0   0.00%  65.00%\n",
            "[ 43, 45) 2  10.00%  75.00% #######\n",
            "[ 45, 46) 1   5.00%  80.00% ###\n",
            "[ 46, 47) 0   0.00%  80.00%\n",
            "[ 47, 48) 3  15.00%  95.00% ##########\n",
            "[ 48, 49) 0   0.00%  95.00%\n",
            "[ 49, 50) 0   0.00%  95.00%\n",
            "[ 50, 51] 1   5.00% 100.00% ###\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 394 Average: 4.57868 StdDev: 0.774041\n",
            "Min: 2 Max: 5 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 2, 3)  10   2.54%   2.54%\n",
            "[ 3, 4)  40  10.15%  12.69% #\n",
            "[ 4, 5)  56  14.21%  26.90% ##\n",
            "[ 5, 5] 288  73.10% 100.00% ##########\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 394 Average: 28.2741 StdDev: 46.4992\n",
            "Min: 5 Max: 321 Ignored: 0\n",
            "----------------------------------------------\n",
            "[   5,  20) 286  72.59%  72.59% ##########\n",
            "[  20,  36)  28   7.11%  79.70% #\n",
            "[  36,  52)  24   6.09%  85.79% #\n",
            "[  52,  68)   6   1.52%  87.31%\n",
            "[  68,  84)  12   3.05%  90.36%\n",
            "[  84, 100)   6   1.52%  91.88%\n",
            "[ 100, 115)   5   1.27%  93.15%\n",
            "[ 115, 131)   4   1.02%  94.16%\n",
            "[ 131, 147)   5   1.27%  95.43%\n",
            "[ 147, 163)   5   1.27%  96.70%\n",
            "[ 163, 179)   4   1.02%  97.72%\n",
            "[ 179, 195)   4   1.02%  98.73%\n",
            "[ 195, 211)   2   0.51%  99.24%\n",
            "[ 211, 226)   0   0.00%  99.24%\n",
            "[ 226, 242)   0   0.00%  99.24%\n",
            "[ 242, 258)   0   0.00%  99.24%\n",
            "[ 258, 274)   1   0.25%  99.49%\n",
            "[ 274, 290)   1   0.25%  99.75%\n",
            "[ 290, 306)   0   0.00%  99.75%\n",
            "[ 306, 321]   1   0.25% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t110 : ApplicantIncome [NUMERICAL]\n",
            "\t85 : LoanAmount [NUMERICAL]\n",
            "\t53 : CoapplicantIncome [NUMERICAL]\n",
            "\t33 : Loan_Amount_Term [NUMERICAL]\n",
            "\t31 : Property_Area [CATEGORICAL]\n",
            "\t25 : Credit_History [NUMERICAL]\n",
            "\t15 : Married [CATEGORICAL]\n",
            "\t13 : Dependents [CATEGORICAL]\n",
            "\t4 : Gender [CATEGORICAL]\n",
            "\t3 : Education [CATEGORICAL]\n",
            "\t2 : Self_Employed [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t20 : Credit_History [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t20 : Credit_History [NUMERICAL]\n",
            "\t12 : LoanAmount [NUMERICAL]\n",
            "\t10 : Loan_Amount_Term [NUMERICAL]\n",
            "\t8 : Property_Area [CATEGORICAL]\n",
            "\t5 : CoapplicantIncome [NUMERICAL]\n",
            "\t3 : Married [CATEGORICAL]\n",
            "\t1 : Self_Employed [CATEGORICAL]\n",
            "\t1 : ApplicantIncome [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t29 : LoanAmount [NUMERICAL]\n",
            "\t21 : Credit_History [NUMERICAL]\n",
            "\t20 : Loan_Amount_Term [NUMERICAL]\n",
            "\t19 : ApplicantIncome [NUMERICAL]\n",
            "\t15 : CoapplicantIncome [NUMERICAL]\n",
            "\t13 : Property_Area [CATEGORICAL]\n",
            "\t8 : Married [CATEGORICAL]\n",
            "\t2 : Education [CATEGORICAL]\n",
            "\t2 : Dependents [CATEGORICAL]\n",
            "\t1 : Self_Employed [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t55 : LoanAmount [NUMERICAL]\n",
            "\t52 : ApplicantIncome [NUMERICAL]\n",
            "\t28 : CoapplicantIncome [NUMERICAL]\n",
            "\t24 : Credit_History [NUMERICAL]\n",
            "\t23 : Loan_Amount_Term [NUMERICAL]\n",
            "\t21 : Property_Area [CATEGORICAL]\n",
            "\t11 : Married [CATEGORICAL]\n",
            "\t9 : Dependents [CATEGORICAL]\n",
            "\t3 : Gender [CATEGORICAL]\n",
            "\t2 : Self_Employed [CATEGORICAL]\n",
            "\t2 : Education [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t110 : ApplicantIncome [NUMERICAL]\n",
            "\t85 : LoanAmount [NUMERICAL]\n",
            "\t53 : CoapplicantIncome [NUMERICAL]\n",
            "\t33 : Loan_Amount_Term [NUMERICAL]\n",
            "\t31 : Property_Area [CATEGORICAL]\n",
            "\t25 : Credit_History [NUMERICAL]\n",
            "\t15 : Married [CATEGORICAL]\n",
            "\t13 : Dependents [CATEGORICAL]\n",
            "\t4 : Gender [CATEGORICAL]\n",
            "\t3 : Education [CATEGORICAL]\n",
            "\t2 : Self_Employed [CATEGORICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t306 : HigherCondition\n",
            "\t68 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t20 : HigherCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t48 : HigherCondition\n",
            "\t12 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t104 : HigherCondition\n",
            "\t26 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t182 : HigherCondition\n",
            "\t48 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t306 : HigherCondition\n",
            "\t68 : ContainsBitmapCondition\n",
            "\n",
            "Training logs:\n",
            "Number of iteration to final model: 20\n",
            "\tIter:1 train-loss:1.170387 valid-loss:1.194041  train-accuracy:0.687612 valid-accuracy:0.684211\n",
            "\tIter:2 train-loss:1.115481 valid-loss:1.152980  train-accuracy:0.687612 valid-accuracy:0.684211\n",
            "\tIter:3 train-loss:1.072847 valid-loss:1.117054  train-accuracy:0.768402 valid-accuracy:0.754386\n",
            "\tIter:4 train-loss:1.036827 valid-loss:1.096802  train-accuracy:0.813285 valid-accuracy:0.789474\n",
            "\tIter:5 train-loss:0.996628 valid-loss:1.084926  train-accuracy:0.822262 valid-accuracy:0.789474\n",
            "\tIter:6 train-loss:0.966892 valid-loss:1.067256  train-accuracy:0.816876 valid-accuracy:0.807018\n",
            "\tIter:16 train-loss:0.762318 valid-loss:1.009420  train-accuracy:0.836625 valid-accuracy:0.807018\n",
            "\tIter:26 train-loss:0.681423 valid-loss:1.000686  train-accuracy:0.843806 valid-accuracy:0.789474\n",
            "\tIter:36 train-loss:0.618343 valid-loss:1.005185  train-accuracy:0.872531 valid-accuracy:0.789474\n",
            "\tIter:46 train-loss:0.537500 valid-loss:1.024895  train-accuracy:0.886894 valid-accuracy:0.789474\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(GradientBoost.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68zlD3AndxHL"
      },
      "source": [
        "The gradient boost gave me a train-loss of 0.53, and a valid-loss of 1.02, so not as good as the random forest. The train-accuracy was 0.887, and valid-accuracy was .789, which was relatively comparable to random forest's .798. Overall I'm surprised that the train-accuracy for for gradient boost was only somewhat higher than for CART, but I suppose those small improvements can mean a lot with more data. Overall I feel that gradient performed the best."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8_23hhNgDa0"
      },
      "source": [
        "**Use stratified k-fold cross-validation with at least three different folds (e.g., 5, 10, 15).\n",
        "You may do your own research on this technique (include citations).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAWH0pc1gIYB"
      },
      "source": [
        "Stratified k-fold validation involves splitting the dataset into k equally subsets, in which the subsets all share the same proportion of y values as the original set. Each fold gets to act as the test set once, while all others are the training set. The average scores between the subsets are then taken for the final score.\n",
        "\n",
        "In order to learn this, I used this website: https://medium.com/@juanc.olamendy/a-comprehensive-guide-to-stratified-k-fold-cross-validation-for-unbalanced-data-014691060f17."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwikYwkMdRDj"
      },
      "source": [
        "To implement stratified k-fold validation, I will be using sklearn.model_selection.StratifiedKFold(), found on the scikit website https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.StratifiedKFold.html. It would be simple enough for me to make a for loop with a modular arithmatic check to divide the data into groups, but since that would require around 60 datasets (30 train and 30 test) per model, I figured it would be more storage and time efficient to use this. I will be using 5 fold, 10 fold, and 15 fold (hence, the 30 datasets of each per model). In order to ensure the shuffle doesn't cause one model to do better, I'll use the random state 64."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvjW13esx9dg"
      },
      "source": [
        "First, I'm going to get this implemented for Random Forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D9HzQsjEfSd6"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EwKVwYFKlMhu"
      },
      "outputs": [],
      "source": [
        "skf5 = StratifiedKFold(n_splits=5, random_state = 64, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RXOO4L7Pf-PK"
      },
      "outputs": [],
      "source": [
        "X = Database.drop(label, axis = 1).values\n",
        "y = Database[label].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTE3XhNYmIoa",
        "outputId": "cdede817-f825-49af-ab0a-4a6771e51b63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use /tmp/tmpwlza_zu9 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.287496. Found 491 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.358014\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 538ms/step - loss: 0.0000e+00 - accuracy: 0.8211 - recall_7: 0.9412 - precision_4: 0.8247\n",
            "Use /tmp/tmp8r6uqg__ as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.292609. Found 491 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.358906\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 0.0000e+00 - accuracy: 0.7480 - recall_8: 0.9412 - precision_5: 0.7547\n",
            "Use /tmp/tmpgfjzza4r as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.369073. Found 491 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.432083\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 422ms/step - loss: 0.0000e+00 - accuracy: 0.7967 - recall_9: 0.9405 - precision_6: 0.7980\n",
            "Use /tmp/tmpefb3a4pa as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.289365. Found 491 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.357247\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.0000e+00 - accuracy: 0.7724 - recall_10: 0.9286 - precision_7: 0.7800\n",
            "Use /tmp/tmp590bpnf3 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.425109. Found 492 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.626369\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 622ms/step - loss: 0.0000e+00 - accuracy: 0.7705 - recall_11: 0.9048 - precision_8: 0.7917\n",
            "accuracy: 0.7817406296730042\n",
            "recall: 0.931232488155365\n",
            "precision 0.7898211359977723\n"
          ]
        }
      ],
      "source": [
        "rf5a = np.zeros(5)\n",
        "rf5r = np.zeros(5)\n",
        "rf5p = np.zeros(5)\n",
        "for i, (train_index, test_index) in enumerate(skf5.split(X, y)):\n",
        "  TrainDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[train_index], label = label)\n",
        "  TestDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[test_index], label = label)\n",
        "\n",
        "  RandomForestk = tfdf.keras.RandomForestModel()\n",
        "  RandomForestk.fit(TrainDatak)\n",
        "  RandomForestk.compile(metrics=[\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "  evaluation = RandomForestk.evaluate(TestDatak)\n",
        "  rf5a[i] = evaluation[1]\n",
        "  rf5r[i] = evaluation[2]\n",
        "  rf5p[i] = evaluation[3]\n",
        "rf5accuracy = np.mean(rf5a)\n",
        "rf5recall = np.mean(rf5r)\n",
        "rf5precision= np.mean(rf5p)\n",
        "print(\"accuracy:\", rf5accuracy)\n",
        "print(\"recall:\", rf5recall)\n",
        "print(\"precision\", rf5precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlEzptprxHZl"
      },
      "outputs": [],
      "source": [
        "skf10 = StratifiedKFold(n_splits=10, random_state = 64, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt-h1xaVxOFB",
        "outputId": "269cf123-a2fe-4afd-fa10-d6f4797bd7df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use /tmp/tmp4i3mtcue as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.302973. Found 552 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.411321\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 553ms/step - loss: 0.0000e+00 - accuracy: 0.8710 - recall_12: 1.0000 - precision_9: 0.8431\n",
            "Use /tmp/tmp9lbof7l_ as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.288436. Found 552 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.506161\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.0000e+00 - accuracy: 0.8065 - recall_13: 0.9535 - precision_10: 0.8039\n",
            "Use /tmp/tmpnv6dj4bv as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.267860. Found 552 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.389160\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.0000e+00 - accuracy: 0.7742 - recall_14: 0.9524 - precision_11: 0.7692\n",
            "Use /tmp/tmpa0fp6ezm as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.285646. Found 552 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.406664\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.0000e+00 - accuracy: 0.6935 - recall_15: 0.9048 - precision_12: 0.7170\n",
            "Use /tmp/tmp7puegkdb as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.342289. Found 553 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.409386\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.0000e+00 - accuracy: 0.8033 - recall_16: 0.9286 - precision_13: 0.8125\n",
            "Use /tmp/tmpr88y89tg as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.285910. Found 553 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.414211\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 513ms/step - loss: 0.0000e+00 - accuracy: 0.8197 - recall_17: 1.0000 - precision_14: 0.7925\n",
            "Use /tmp/tmpvpkoczpk as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.388739. Found 553 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.694176\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 594ms/step - loss: 0.0000e+00 - accuracy: 0.8852 - recall_18: 0.9762 - precision_15: 0.8723\n",
            "Use /tmp/tmpdtscfv96 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.431325. Found 553 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.667008\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.0000e+00 - accuracy: 0.6885 - recall_19: 0.9048 - precision_16: 0.7170\n",
            "Use /tmp/tmpvohl6r90 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.280981. Found 553 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.410254\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 0.0000e+00 - accuracy: 0.7541 - recall_20: 0.9048 - precision_17: 0.7755\n",
            "Use /tmp/tmpqw6s3obu as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:01.126291. Found 553 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.439134\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.0000e+00 - accuracy: 0.8361 - recall_21: 0.9762 - precision_18: 0.8200\n",
            "accuracy: 0.7932046532630921\n",
            "recall: 0.9501107335090637\n",
            "precision 0.7923055291175842\n"
          ]
        }
      ],
      "source": [
        "rf10a = np.zeros(10)\n",
        "rf10r = np.zeros(10)\n",
        "rf10p = np.zeros(10)\n",
        "for i, (train_index, test_index) in enumerate(skf10.split(X, y)):\n",
        "  TrainDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[train_index], label = label)\n",
        "  TestDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[test_index], label = label)\n",
        "\n",
        "  RandomForestk = tfdf.keras.RandomForestModel()\n",
        "  RandomForestk.fit(TrainDatak)\n",
        "  RandomForestk.compile(metrics=[\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "  evaluation = RandomForestk.evaluate(TestDatak)\n",
        "  rf10a[i] = evaluation[1]\n",
        "  rf10r[i] = evaluation[2]\n",
        "  rf10p[i] = evaluation[3]\n",
        "rf10accuracy = np.mean(rf10a)\n",
        "rf10recall = np.mean(rf10r)\n",
        "rf10precision= np.mean(rf10p)\n",
        "print(\"accuracy:\", rf10accuracy)\n",
        "print(\"recall:\", rf10recall)\n",
        "print(\"precision\", rf10precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpVgFyB6xfJb"
      },
      "outputs": [],
      "source": [
        "skf15 = StratifiedKFold(n_splits=15, random_state = 64, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-sl6jjXxmkT",
        "outputId": "2dc43b54-dfb8-4baa-99d6-d71da0e16158"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use /tmp/tmpogr89p6i as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.297752. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.483632\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0000e+00 - accuracy: 0.8293 - recall_22: 1.0000 - precision_19: 0.8056\n",
            "Use /tmp/tmp73ltaurg as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.320888. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.441680\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 0.0000e+00 - accuracy: 0.9024 - recall_23: 1.0000 - precision_20: 0.8788\n",
            "Use /tmp/tmp3p0sfuzx as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.285216. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.511567\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.0000e+00 - accuracy: 0.8049 - recall_24: 0.9286 - precision_21: 0.8125\n",
            "Use /tmp/tmpypfvfinp as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.301131. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.397782\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 0.0000e+00 - accuracy: 0.8049 - recall_25: 0.9286 - precision_22: 0.8125\n",
            "Use /tmp/tmpjz6jr1hk as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.277890. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.422160\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.0000e+00 - accuracy: 0.7317 - recall_26: 0.9643 - precision_23: 0.7297\n",
            "Use /tmp/tmpy_3l_rzh as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.312572. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.436789\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.0000e+00 - accuracy: 0.7073 - recall_27: 0.9286 - precision_24: 0.7222\n",
            "Use /tmp/tmpafsgfoa7 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.413539. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.678753\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.0000e+00 - accuracy: 0.8293 - recall_28: 0.9286 - precision_25: 0.8387\n",
            "Use /tmp/tmp3y6pgncr as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.457118. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.491985\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.0000e+00 - accuracy: 0.7561 - recall_29: 0.9643 - precision_26: 0.7500\n",
            "Use /tmp/tmpib570a6t as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.312786. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.413631\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 543ms/step - loss: 0.0000e+00 - accuracy: 0.8537 - recall_30: 1.0000 - precision_27: 0.8235\n",
            "Use /tmp/tmp443hp7vl as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.294684. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.486128\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.0000e+00 - accuracy: 0.8537 - recall_31: 0.9643 - precision_28: 0.8438\n",
            "Use /tmp/tmpn9htk6vm as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.297491. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.421547\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 530ms/step - loss: 0.0000e+00 - accuracy: 0.7805 - recall_32: 0.8929 - precision_29: 0.8065\n",
            "Use /tmp/tmphhyxf9_o as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.284791. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.419046\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0000e+00 - accuracy: 0.7317 - recall_33: 1.0000 - precision_30: 0.7179\n",
            "Use /tmp/tmpu474jlze as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.374033. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.517290\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 419ms/step - loss: 0.0000e+00 - accuracy: 0.7561 - recall_34: 0.9286 - precision_31: 0.7647\n",
            "Use /tmp/tmp2wesg4u6 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.286933. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.401733\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.0000e+00 - accuracy: 0.8049 - recall_35: 0.9643 - precision_32: 0.7941\n",
            "Use /tmp/tmpkck_jrnk as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.474885. Found 574 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.717306\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.0000e+00 - accuracy: 0.8500 - recall_36: 0.9643 - precision_33: 0.8438\n",
            "accuracy: 0.7997560977935791\n",
            "recall: 0.9571428537368775\n",
            "precision 0.7962838888168335\n"
          ]
        }
      ],
      "source": [
        "rf15a = np.zeros(15)\n",
        "rf15r = np.zeros(15)\n",
        "rf15p = np.zeros(15)\n",
        "for i, (train_index, test_index) in enumerate(skf15.split(X, y)):\n",
        "  TrainDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[train_index], label = label)\n",
        "  TestDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[test_index], label = label)\n",
        "\n",
        "  RandomForestk = tfdf.keras.RandomForestModel()\n",
        "  RandomForestk.fit(TrainDatak)\n",
        "  RandomForestk.compile(metrics=[\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "  evaluation = RandomForestk.evaluate(TestDatak)\n",
        "  rf15a[i] = evaluation[1]\n",
        "  rf15r[i] = evaluation[2]\n",
        "  rf15p[i] = evaluation[3]\n",
        "rf15accuracy = np.mean(rf15a)\n",
        "rf15recall = np.mean(rf15r)\n",
        "rf15precision= np.mean(rf15p)\n",
        "print(\"accuracy:\", rf15accuracy)\n",
        "print(\"recall:\", rf15recall)\n",
        "print(\"precision\", rf15precision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ys2OJhkx5Uq"
      },
      "source": [
        "Next, the same implementation will be done with gradient boost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioAQPhmi0Fgq",
        "outputId": "2e2a853a-b89f-4502-c5c3-c4cad56ddeb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use /tmp/tmp0h61jgu_ as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.530996. Found 491 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.406636\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.0000e+00 - accuracy: 0.8130 - recall_37: 0.9294 - precision_34: 0.8229\n",
            "Use /tmp/tmpg_zrey83 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.436719. Found 491 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.181244\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.0000e+00 - accuracy: 0.7805 - recall_38: 0.9765 - precision_35: 0.7685\n",
            "Use /tmp/tmpms5ds95p as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.480966. Found 491 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.170704\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0000e+00 - accuracy: 0.7805 - recall_39: 0.9524 - precision_36: 0.7767\n",
            "Use /tmp/tmpu4mh0q36 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.371355. Found 491 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.229300\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 0.0000e+00 - accuracy: 0.7724 - recall_40: 0.9524 - precision_37: 0.7692\n",
            "Use /tmp/tmp6pdugeoi as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.307700. Found 492 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.208378\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.0000e+00 - accuracy: 0.8197 - recall_41: 0.9762 - precision_38: 0.8039\n",
            "accuracy: 0.7932026982307434\n",
            "recall: 0.957366943359375\n",
            "precision 0.7882573127746582\n"
          ]
        }
      ],
      "source": [
        "gb5a = np.zeros(5)\n",
        "gb5r = np.zeros(5)\n",
        "gb5p = np.zeros(5)\n",
        "for i, (train_index, test_index) in enumerate(skf5.split(X, y)):\n",
        "  TrainDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[train_index], label = label)\n",
        "  TestDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[test_index], label = label)\n",
        "\n",
        "  GradientBoostk = tfdf.keras.GradientBoostedTreesModel()\n",
        "  GradientBoostk.fit(TrainDatak)\n",
        "  GradientBoostk.compile(metrics=[\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "  evaluation = GradientBoostk.evaluate(TestDatak)\n",
        "  gb5a[i] = evaluation[1]\n",
        "  gb5r[i] = evaluation[2]\n",
        "  gb5p[i] = evaluation[3]\n",
        "gb5accuracy = np.mean(gb5a)\n",
        "gb5recall = np.mean(gb5r)\n",
        "gb5precision= np.mean(gb5p)\n",
        "print(\"accuracy:\", gb5accuracy)\n",
        "print(\"recall:\", gb5recall)\n",
        "print(\"precision\", gb5precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVXeYvNx0aDf",
        "outputId": "3d31d101-155f-432f-fce0-d205821909c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use /tmp/tmpkqjh59gj as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.467507. Found 552 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.513424\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 0.0000e+00 - accuracy: 0.8387 - recall_42: 0.9535 - precision_39: 0.8367\n",
            "Use /tmp/tmp6vxbhkpw as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.299979. Found 552 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.218522\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 458ms/step - loss: 0.0000e+00 - accuracy: 0.8387 - recall_43: 1.0000 - precision_40: 0.8113\n",
            "Use /tmp/tmpfptu8m31 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.346558. Found 552 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.208349\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 522ms/step - loss: 0.0000e+00 - accuracy: 0.7903 - recall_44: 1.0000 - precision_41: 0.7636\n",
            "Use /tmp/tmps_eimjob as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.323320. Found 552 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.172168\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.0000e+00 - accuracy: 0.7419 - recall_45: 0.9524 - precision_42: 0.7407\n",
            "Use /tmp/tmpgkqm8i97 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.322199. Found 553 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.175607\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 638ms/step - loss: 0.0000e+00 - accuracy: 0.7377 - recall_46: 0.8571 - precision_43: 0.7826\n",
            "Use /tmp/tmpmscqquck as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.511985. Found 553 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.189780\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 0.0000e+00 - accuracy: 0.8197 - recall_47: 1.0000 - precision_44: 0.7925\n",
            "Use /tmp/tmpdjus2ku1 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.658024. Found 553 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.254373\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 562ms/step - loss: 0.0000e+00 - accuracy: 0.8525 - recall_48: 0.9762 - precision_45: 0.8367\n",
            "Use /tmp/tmp29nce4b2 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.517689. Found 553 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.307098\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 606ms/step - loss: 0.0000e+00 - accuracy: 0.7049 - recall_49: 0.9286 - precision_46: 0.7222\n",
            "Use /tmp/tmprrp_rkjy as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.568340. Found 553 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.282857\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.0000e+00 - accuracy: 0.7705 - recall_50: 0.8810 - precision_47: 0.8043\n",
            "Use /tmp/tmpufhvk5mh as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.416103. Found 553 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.251106\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 0.0000e+00 - accuracy: 0.8361 - recall_51: 0.9762 - precision_48: 0.8200\n",
            "accuracy: 0.7930988848209382\n",
            "recall: 0.952491682767868\n",
            "precision 0.7910798788070679\n"
          ]
        }
      ],
      "source": [
        "gb10a = np.zeros(10)\n",
        "gb10r = np.zeros(10)\n",
        "gb10p = np.zeros(10)\n",
        "for i, (train_index, test_index) in enumerate(skf10.split(X, y)):\n",
        "  TrainDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[train_index], label = label)\n",
        "  TestDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[test_index], label = label)\n",
        "\n",
        "  GradientBoostk = tfdf.keras.GradientBoostedTreesModel()\n",
        "  GradientBoostk.fit(TrainDatak)\n",
        "  GradientBoostk.compile(metrics=[\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "  evaluation = GradientBoostk.evaluate(TestDatak)\n",
        "  gb10a[i] = evaluation[1]\n",
        "  gb10r[i] = evaluation[2]\n",
        "  gb10p[i] = evaluation[3]\n",
        "gb10accuracy = np.mean(gb10a)\n",
        "gb10recall = np.mean(gb10r)\n",
        "gb10precision= np.mean(gb10p)\n",
        "print(\"accuracy:\", gb10accuracy)\n",
        "print(\"recall:\", gb10recall)\n",
        "print(\"precision\", gb10precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5be6iOS0rcK",
        "outputId": "d1ce0a64-3bfc-472c-abf2-25f58c5bb33d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use /tmp/tmpzxr5lpq0 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.309473. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.201780\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 508ms/step - loss: 0.0000e+00 - accuracy: 0.8049 - recall_52: 0.9655 - precision_49: 0.8000\n",
            "Use /tmp/tmpmqa48xtr as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.333135. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.233111\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0000e+00 - accuracy: 0.9024 - recall_53: 1.0000 - precision_50: 0.8788\n",
            "Use /tmp/tmpn01ea1c1 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.303490. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.281153\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.0000e+00 - accuracy: 0.8049 - recall_54: 0.9286 - precision_51: 0.8125\n",
            "Use /tmp/tmpycqxroy8 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.354540. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.211663\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 594ms/step - loss: 0.0000e+00 - accuracy: 0.8293 - recall_55: 0.9643 - precision_52: 0.8182\n",
            "Use /tmp/tmphfgnx3fs as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.456864. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.355930\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 414ms/step - loss: 0.0000e+00 - accuracy: 0.7317 - recall_56: 0.9286 - precision_53: 0.7429\n",
            "Use /tmp/tmprn3s1wkm as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.293116. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.249403\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 500ms/step - loss: 0.0000e+00 - accuracy: 0.7317 - recall_57: 0.9643 - precision_54: 0.7297\n",
            "Use /tmp/tmpnkg63l03 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.318753. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.191741\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.0000e+00 - accuracy: 0.7805 - recall_58: 0.8929 - precision_55: 0.8065\n",
            "Use /tmp/tmpdq64d0_m as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.288352. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.166150\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.0000e+00 - accuracy: 0.7317 - recall_59: 0.9643 - precision_56: 0.7297\n",
            "Use /tmp/tmp5q7waytz as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.383449. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.194513\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 513ms/step - loss: 0.0000e+00 - accuracy: 0.8537 - recall_60: 1.0000 - precision_57: 0.8235\n",
            "Use /tmp/tmpsbw4i993 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.287891. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.173977\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 532ms/step - loss: 0.0000e+00 - accuracy: 0.8293 - recall_61: 0.9643 - precision_58: 0.8182\n",
            "Use /tmp/tmpwqzkp2b1 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.316235. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.185211\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0000e+00 - accuracy: 0.7805 - recall_62: 0.9286 - precision_59: 0.7879\n",
            "Use /tmp/tmpz5i5pbfs as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.345213. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.193279\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.0000e+00 - accuracy: 0.7317 - recall_63: 1.0000 - precision_60: 0.7179\n",
            "Use /tmp/tmptgvmtx2t as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.474964. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.318980\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.0000e+00 - accuracy: 0.7561 - recall_64: 0.8929 - precision_61: 0.7812\n",
            "Use /tmp/tmp_s1zq4u2 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.321747. Found 573 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.198583\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 530ms/step - loss: 0.0000e+00 - accuracy: 0.7805 - recall_65: 0.9286 - precision_62: 0.7879\n",
            "Use /tmp/tmp1d18wmtv as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.321279. Found 574 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.219152\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.0000e+00 - accuracy: 0.8250 - recall_66: 0.9286 - precision_63: 0.8387\n",
            "accuracy: 0.79158536195755\n",
            "recall: 0.9500820954640706\n",
            "precision 0.7915743430455525\n"
          ]
        }
      ],
      "source": [
        "gb15a = np.zeros(15)\n",
        "gb15r = np.zeros(15)\n",
        "gb15p = np.zeros(15)\n",
        "for i, (train_index, test_index) in enumerate(skf15.split(X, y)):\n",
        "  TrainDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[train_index], label = label)\n",
        "  TestDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[test_index], label = label)\n",
        "\n",
        "  GradientBoostk = tfdf.keras.GradientBoostedTreesModel()\n",
        "  GradientBoostk.fit(TrainDatak)\n",
        "  GradientBoostk.compile(metrics=[\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "  evaluation = GradientBoostk.evaluate(TestDatak)\n",
        "  gb15a[i] = evaluation[1]\n",
        "  gb15r[i] = evaluation[2]\n",
        "  gb15p[i] = evaluation[3]\n",
        "gb15accuracy = np.mean(gb15a)\n",
        "gb15recall = np.mean(gb15r)\n",
        "gb15precision= np.mean(gb15p)\n",
        "print(\"accuracy:\", gb15accuracy)\n",
        "print(\"recall:\", gb15recall)\n",
        "print(\"precision\", gb15precision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH4OfBxD06Vc"
      },
      "source": [
        "Now to compare the metrics between the models under each fold:\n",
        "\n",
        "For ease of comparison, Random Forest will be on the left, and Gradient Boost will be on the right\n",
        "\n",
        "K = 5:\n",
        "\n",
        "Accuracy: 0.7817406296730042 vs 0.7932026982307434, GB wins\n",
        "\n",
        "Recall: 0.931232488155365 vs 0.957366943359375, GB wins\n",
        "\n",
        "Precision: 0.7898211359977723 vs 0.7882573127746582, RF wins\n",
        "\n",
        "K = 10:\n",
        "\n",
        "Accuracy: 0.7932046532630921 vs 0.7930988848209382, RF wins\n",
        "\n",
        "Recall: 0.9501107335090637 vs 0.952491682767868, GB wins\n",
        "\n",
        "Precision: 0.7923055291175842 vs 0.7910798788070679, RF wins\n",
        "\n",
        "K = 15:\n",
        "\n",
        "Accuracy: 0.7997560977935791 vs 0.79158536195755, RF wins\n",
        "\n",
        "Recall: 0.9571428537368775 vs 0.9500820954640706, RF wins\n",
        "\n",
        "Precision: 0.7962838888168335 vs 0.7915743430455525, RF wins"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLvH52jF2b1i"
      },
      "source": [
        "The first observation is that RF always did better on precision, so if you want your positive predictions to be correct, it's the better model. As for accuracy and recall, GB did best at lower folds, but RF became better at higher folds. To be specific, GB won accuracy for K = 5, and lost at K = 10 or 15. GB also won Recall for K = 5, 10, but not for K = 15. This indicates that RF overall works better at a higher amount of folds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uDRKiqj3lal"
      },
      "source": [
        "**Task 3 (40 points): Compare the effectiveness of the three models implemented above. Analyze\n",
        "the results using the following:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVihlDX43pA9"
      },
      "source": [
        "**A confusion matrix for one selected test fold**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqxRDsHz3sGZ"
      },
      "source": [
        "The fold that I'm choosing for this is K = 5. I'll have to implement K-fold for CART, but that should pretty much be the same code as the other models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jut-PXiUfxqF"
      },
      "source": [
        "K-fold for CART:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUJxsJGxf7Oj",
        "outputId": "833357ca-7332-462e-9cf9-b267486c4313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmp4vbvxgyq as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:02.563109. Found 491 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.042274\n",
            "Compiling model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x7d0b96032d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x7d0b8861f1a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x7d0b95cea700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 483ms/step - loss: 0.0000e+00 - accuracy: 0.8537 - recall_5: 1.0000 - precision_5: 0.8252\n",
            "Use /tmp/tmpxcp_njom as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.320764. Found 491 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.049439\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.0000e+00 - accuracy: 0.7967 - recall_6: 0.9882 - precision_6: 0.7778\n",
            "Use /tmp/tmp9n2nwgxk as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.269699. Found 491 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.054048\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 594ms/step - loss: 0.0000e+00 - accuracy: 0.8130 - recall_7: 0.9762 - precision_7: 0.7961\n",
            "Use /tmp/tmppjt_nlml as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.531646. Found 491 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.129982\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 0.7317 - recall_8: 0.8571 - precision_8: 0.7742\n",
            "Use /tmp/tmpkaatntt0 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.568608. Found 492 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.087293\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.0000e+00 - accuracy: 0.8197 - recall_9: 0.9762 - precision_9: 0.8039\n",
            "accuracy: 0.8029588222503662\n",
            "recall: 0.9595518112182617\n",
            "precision 0.7954504251480102\n"
          ]
        }
      ],
      "source": [
        "CARTa = np.zeros(5)\n",
        "CARTr = np.zeros(5)\n",
        "CARTp = np.zeros(5)\n",
        "for i, (train_index, test_index) in enumerate(skf5.split(X, y)):\n",
        "  TrainDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[train_index], label = label)\n",
        "  TestDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[test_index], label = label)\n",
        "\n",
        "  Cartk = tfdf.keras.CartModel()\n",
        "  Cartk.fit(TrainDatak)\n",
        "  Cartk.compile(metrics=[\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "  evaluation = Cartk.evaluate(TestDatak)\n",
        "  CARTa[i] = evaluation[1]\n",
        "  CARTr[i] = evaluation[2]\n",
        "  CARTp[i] = evaluation[3]\n",
        "CARTaccuracy = np.mean(CARTa)\n",
        "CARTrecall = np.mean(CARTr)\n",
        "CARTprecision= np.mean(CARTp)\n",
        "print(\"accuracy:\", CARTaccuracy)\n",
        "print(\"recall:\", CARTrecall)\n",
        "print(\"precision\", CARTprecision)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The confusion matrix will be implemented on the 1st fold, since I can easily check for it using i % 5 = 0."
      ],
      "metadata": {
        "id": "SaZXH4uxgg-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Up first is the CART model."
      ],
      "metadata": {
        "id": "K-HF-yrAgzlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (train_index, test_index) in enumerate(skf5.split(X, y)):\n",
        "  if i % 5 == 0:\n",
        "    TrainDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[train_index], label = label)\n",
        "    TestDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[test_index], label = label)\n",
        "    Cartk = tfdf.keras.CartModel()\n",
        "    Cartk.fit(TrainDatak)\n",
        "    predictions = Cartk.predict(TestDatak)\n",
        "    print(tf.math.confusion_matrix(y[test_index], tf.round(predictions)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0Rgh3uXhAMd",
        "outputId": "4374598d-f48b-42c3-8be3-a26a39103573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpll2tc2hj as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.298955. Found 491 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.043846\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "tf.Tensor(\n",
            "[[20 18]\n",
            " [ 0 85]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the confusion matrix, the top left value is the number of true negatives, top right is false positives, bottom right is true positives and bottom left is false negatives. As we can see, the recall is perfect, but there's a slight inaccuracy with the precision."
      ],
      "metadata": {
        "id": "3bgWj5JvkdZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest:"
      ],
      "metadata": {
        "id": "ka6W35wslLQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (train_index, test_index) in enumerate(skf5.split(X, y)):\n",
        "  if i % 5 == 0:\n",
        "    TrainDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[train_index], label = label)\n",
        "    TestDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[test_index], label = label)\n",
        "    RandomForestk = tfdf.keras.RandomForestModel()\n",
        "    RandomForestk.fit(TrainDatak)\n",
        "    predictions = RandomForestk.predict(TestDatak)\n",
        "    print(tf.math.confusion_matrix(y[test_index], tf.round(predictions)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWJJLaHDlM4O",
        "outputId": "d1bfbbfd-ac06-4b96-dfba-bc4eb6555c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpdkoe38kr as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.278001. Found 491 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.489687\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "tf.Tensor(\n",
            "[[21 17]\n",
            " [ 5 80]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see that an extra negative was guessed correctly, but at the cost of incorrectly labeling 5 positives. The recall and precision are both less than the CART model, I don't think the extra correct negative was worth it."
      ],
      "metadata": {
        "id": "eS7jaDTKld27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, the Gradient Boost model:"
      ],
      "metadata": {
        "id": "ujTqHn-emF40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (train_index, test_index) in enumerate(skf5.split(X, y)):\n",
        "  if i % 5 == 0:\n",
        "    TrainDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[train_index], label = label)\n",
        "    TestDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[test_index], label = label)\n",
        "    GradientBoostk = tfdf.keras.GradientBoostedTreesModel()\n",
        "    GradientBoostk.fit(TrainDatak)\n",
        "    predictions = GradientBoostk.predict(TestDatak)\n",
        "    print(tf.math.confusion_matrix(y[test_index], tf.round(predictions)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgWXnE5_mNYk",
        "outputId": "2fc9a285-6a1c-4e90-fe1c-423fd33ef372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpw74u7j9c as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.269926. Found 491 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.330201\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "tf.Tensor(\n",
            "[[21 17]\n",
            " [ 6 79]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The negative values performed exactly the same as random forest, but another positive value was incorrectly identified. This was the worst performing of the algorithms in these circumstances."
      ],
      "metadata": {
        "id": "laMzUlgJmcrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A statistical test (e.g., paired t-test) to determine if differences between models are\n",
        "significant.**"
      ],
      "metadata": {
        "id": "4gvnKmc666Oq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will be using a paired t-test. This will be done on the same fold as the confusion matrix. To do this, I will start by getting the predicted values for each model. For each pair, I will then take the differences between the values, and get the average. To get the standard error, I will take the standard deviation of the dataset and divide it by the square root of the amount of examples. Finally, I'll divide the average by the standard error to get a t value. Comparing this t value to the t table will determine how different these models are. For this table I'll use the p-value of 0.05. I used this website to calculate the table t value: https://datatab.net/tutorial/t-distribution"
      ],
      "metadata": {
        "id": "qbHeWAEE683z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (train_index, test_index) in enumerate(skf5.split(X, y)):\n",
        "  if i % 5 == 0:\n",
        "    TrainDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[train_index], label = label)\n",
        "    TestDatak = tfdf.keras.pd_dataframe_to_tf_dataset(Database.loc[test_index], label = label)\n",
        "    GradientBoostk = tfdf.keras.GradientBoostedTreesModel()\n",
        "    GradientBoostk.fit(TrainDatak)\n",
        "    predictionsg = GradientBoostk.predict(TestDatak)\n",
        "    Cartk = tfdf.keras.CartModel()\n",
        "    Cartk.fit(TrainDatak)\n",
        "    predictionsc = Cartk.predict(TestDatak)\n",
        "    RandomForestk = tfdf.keras.RandomForestModel()\n",
        "    RandomForestk.fit(TrainDatak)\n",
        "    predictionsr = RandomForestk.predict(TestDatak)\n",
        "\n",
        "    GCdata = tf.round(predictionsg) - tf.round(predictionsc)\n",
        "    GCavg = np.mean(GCdata)\n",
        "    GCstd = np.std(GCdata)\n",
        "    GCsterr = GCstd / np.sqrt(len(GCdata))\n",
        "    print(\"Gradient Boost vs CART:\")\n",
        "    GCt = GCavg / GCsterr\n",
        "    print(GCt)\n",
        "\n",
        "    CRdata = tf.round(predictionsc) - tf.round(predictionsr)\n",
        "    CRavg = np.mean(CRdata)\n",
        "    CRstd = np.std(CRdata)\n",
        "    CRsterr = CRstd / np.sqrt(len(CRdata))\n",
        "    print(\"CART vs Random Forest:\")\n",
        "    CRt = CRavg / CRsterr\n",
        "    print(CRt)\n",
        "\n",
        "    RGdata = tf.round(predictionsr) - tf.round(predictionsg)\n",
        "    RGavg = np.mean(RGdata)\n",
        "    RGstd = np.std(RGdata)\n",
        "    RGsterr = CRstd / np.sqrt(len(RGdata))\n",
        "    print(\"Random Forest vs Gradient Boost:\")\n",
        "    RGt = RGavg / RGsterr\n",
        "    print(RGt)\n",
        "\n",
        "    print(\"table value: 2.228\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw_FLLgF-Jcy",
        "outputId": "ec7dab40-6dec-4388-89b4-cadf9d8d7fa3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpf3kd6bzr as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.264534. Found 491 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.309613\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "Use /tmp/tmp9q076p9h as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.248326. Found 491 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.042235\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Use /tmp/tmp3ci6p1bd as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.340303. Found 491 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.540723\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "Gradient Boost vs CART:\n",
            "-2.7244109165741417\n",
            "CART vs Random Forest:\n",
            "2.5115120318503403\n",
            "Random Forest vs Gradient Boost:\n",
            "0.41858533864172337\n",
            "table value: 2.228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The absolute value of the model differences is higher than the table value in the cases of Gradient Boost vs CART and CART vs Random Forest, so CART is significantly different from the other models. However, the t value is quite low for Random Forest vs Gradient Boost, so those models aren't significantly different."
      ],
      "metadata": {
        "id": "mxd8kzCcCCUl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A discussion on the trade-off between bias and variance for each model.**"
      ],
      "metadata": {
        "id": "DFMhO7rGI6ua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall the models were all similarly high on recall, and as such performed well with low bias. The worst performing was Random Forest at 5 folds, but that was still 93%, really good. This is also not the best for variance, as a high recall tends to correspond to a high variance. On the other hand, precision was around 80% for all the models, so that is a bit better for variance, and also better for bias. There's also the accuracy at a similar value and giving similar effects as precision. If I were to focus on one of the two to improve, it would be the variance, probably by adding more data points (if I had a way to collect them). It is likely another model type would be better for variance though, like a linear model."
      ],
      "metadata": {
        "id": "9yZM-91NHqVI"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD4D4BUK+MfFIJOuR8GuQT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}